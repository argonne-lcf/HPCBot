text
"This is a chat between a user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions based on the given context. The assistant should also indicate when the answer cannot be found in the context."
"
### Context: 
Getting Started on Polaris

Logging Into Polaris

To log into Polaris:
ssh <username>@polaris.alcf.anl.gov
Then, type in the password from your CRYPTOCard/MobilePASS+ token.

Hardware Overview

An overview of the Polaris system including details on the compute node architecture is available on the Machine Overview page.

Compiling Applications

Users are encouraged to read through the Compiling and Linking Overview page and corresponding pages depending on the target compiler and programming model.

Accessing Additional Software

In addition to the Cray PE, ALCF installs software in /soft which can be
accessed via module commands by altering your $MODULEPATH:
module use /soft/modulefiles
The available software can then be queried with module avail.

Additionally, a suite of software packages are provided via Spack deployments,
detailed on the Spack PE
page.

Submitting and Running Jobs

Users are encouraged to read through the Running Jobs with PBS at the ALCF page for information on using the PBS scheduler and preparing job submission scripts. Some example job submission scripts are available on the Example Job Scripts page as well.

Lustre File Striping

In addition to the content above, here is a document on Lustre File Striping Basics.

Lustre File Striping Basics

Proxy

If the node you are on doesn’t have outbound network connectivity, add the following to your ~/.bash_profile file to access the proxy host.

```bash

proxy settings

export HTTP_PROXY=""http://proxy.alcf.anl.gov:3128""
export HTTPS_PROXY=""http://proxy.alcf.anl.gov:3128""
export http_proxy=""http://proxy.alcf.anl.gov:3128""
export https_proxy=""http://proxy.alcf.anl.gov:3128""
export ftp_proxy=""http://proxy.alcf.anl.gov:3128""
export no_proxy=""admin,polaris-adminvm-01,localhost,.cm.polaris.alcf.anl.gov,polaris-,.polaris.alcf.anl.gov,.alcf.anl.gov""
```

Getting Assistance

Please direct all questions, requests, and feedback to support@alcf.anl.gov.

### Human: How do I log into Polaris?

### Assistant: ssh <username>@polaris.alcf.anl.gov, then type in the password from your CRYPTOCard/MobilePASS+ token.
    "
"
### Context: 
Getting Started on Polaris

Logging Into Polaris

To log into Polaris:
ssh <username>@polaris.alcf.anl.gov
Then, type in the password from your CRYPTOCard/MobilePASS+ token.

Hardware Overview

An overview of the Polaris system including details on the compute node architecture is available on the Machine Overview page.

Compiling Applications

Users are encouraged to read through the Compiling and Linking Overview page and corresponding pages depending on the target compiler and programming model.

Accessing Additional Software

In addition to the Cray PE, ALCF installs software in /soft which can be
accessed via module commands by altering your $MODULEPATH:
module use /soft/modulefiles
The available software can then be queried with module avail.

Additionally, a suite of software packages are provided via Spack deployments,
detailed on the Spack PE
page.

Submitting and Running Jobs

Users are encouraged to read through the Running Jobs with PBS at the ALCF page for information on using the PBS scheduler and preparing job submission scripts. Some example job submission scripts are available on the Example Job Scripts page as well.

Lustre File Striping

In addition to the content above, here is a document on Lustre File Striping Basics.

Lustre File Striping Basics

Proxy

If the node you are on doesn’t have outbound network connectivity, add the following to your ~/.bash_profile file to access the proxy host.

```bash

proxy settings

export HTTP_PROXY=""http://proxy.alcf.anl.gov:3128""
export HTTPS_PROXY=""http://proxy.alcf.anl.gov:3128""
export http_proxy=""http://proxy.alcf.anl.gov:3128""
export https_proxy=""http://proxy.alcf.anl.gov:3128""
export ftp_proxy=""http://proxy.alcf.anl.gov:3128""
export no_proxy=""admin,polaris-adminvm-01,localhost,.cm.polaris.alcf.anl.gov,polaris-,.polaris.alcf.anl.gov,.alcf.anl.gov""
```

Getting Assistance

Please direct all questions, requests, and feedback to support@alcf.anl.gov.

### Human: What is the purpose of Lustre File Striping in Polaris?

### Assistant: The purpose of Lustre File Striping in Polaris is to provide information on how to use this feature.
    "
"
### Context: 
Getting Started on Polaris

Logging Into Polaris

To log into Polaris:
ssh <username>@polaris.alcf.anl.gov
Then, type in the password from your CRYPTOCard/MobilePASS+ token.

Hardware Overview

An overview of the Polaris system including details on the compute node architecture is available on the Machine Overview page.

Compiling Applications

Users are encouraged to read through the Compiling and Linking Overview page and corresponding pages depending on the target compiler and programming model.

Accessing Additional Software

In addition to the Cray PE, ALCF installs software in /soft which can be
accessed via module commands by altering your $MODULEPATH:
module use /soft/modulefiles
The available software can then be queried with module avail.

Additionally, a suite of software packages are provided via Spack deployments,
detailed on the Spack PE
page.

Submitting and Running Jobs

Users are encouraged to read through the Running Jobs with PBS at the ALCF page for information on using the PBS scheduler and preparing job submission scripts. Some example job submission scripts are available on the Example Job Scripts page as well.

Lustre File Striping

In addition to the content above, here is a document on Lustre File Striping Basics.

Lustre File Striping Basics

Proxy

If the node you are on doesn’t have outbound network connectivity, add the following to your ~/.bash_profile file to access the proxy host.

```bash

proxy settings

export HTTP_PROXY=""http://proxy.alcf.anl.gov:3128""
export HTTPS_PROXY=""http://proxy.alcf.anl.gov:3128""
export http_proxy=""http://proxy.alcf.anl.gov:3128""
export https_proxy=""http://proxy.alcf.anl.gov:3128""
export ftp_proxy=""http://proxy.alcf.anl.gov:3128""
export no_proxy=""admin,polaris-adminvm-01,localhost,.cm.polaris.alcf.anl.gov,polaris-,.polaris.alcf.anl.gov,.alcf.anl.gov""
```

Getting Assistance

Please direct all questions, requests, and feedback to support@alcf.anl.gov.

### Human: Where can I find examples of job submission scripts for running jobs on Polaris?

### Assistant: Example Job Scripts page
    "
"
### Context: 
Datascience Anaconda Module Updates

We have updated the datascience Anaconda module and built various packages and libraries with CUDA 12.4.1 to be compatible with 
the new Polaris NVIDIA GPU hardware driver (CUDA 12.2) and to use the latest MPI, NCCL, cuDNN, TensorRT, etc. libraries. 
PyTorch 2.3.0 and TensorFlow 2.16.1 are now available as part of this module.

To use the new environment, type:
module use /soft/modulefiles 
module load conda; conda activate

/soft refresh and default $MODULEPATH change

Due to the new system software stack, /soft has been purged to allow for
software to be rebuilt. In addition, /soft/modulefiles is no longer in the
default $MODULEPATH. To access modules installed in /soft, users should run
module use /soft/modulefiles.

Adding module use /soft/modulefiles to your profile should approximate the old behavior.

Modules removed

The following modules have been removed:

### Human: What CUDA version is compatible with the new Polaris NVIDIA GPU hardware driver?

### Assistant: CUDA 12.2
    "
"
### Context: 
Datascience Anaconda Module Updates

We have updated the datascience Anaconda module and built various packages and libraries with CUDA 12.4.1 to be compatible with 
the new Polaris NVIDIA GPU hardware driver (CUDA 12.2) and to use the latest MPI, NCCL, cuDNN, TensorRT, etc. libraries. 
PyTorch 2.3.0 and TensorFlow 2.16.1 are now available as part of this module.

To use the new environment, type:
module use /soft/modulefiles 
module load conda; conda activate

/soft refresh and default $MODULEPATH change

Due to the new system software stack, /soft has been purged to allow for
software to be rebuilt. In addition, /soft/modulefiles is no longer in the
default $MODULEPATH. To access modules installed in /soft, users should run
module use /soft/modulefiles.

Adding module use /soft/modulefiles to your profile should approximate the old behavior.

Modules removed

The following modules have been removed:

### Human: Which Python libraries are available as part of the updated datascience Anaconda module?

### Assistant: PyTorch 2.3.0, TensorFlow 2.16.1, and other popular Python libraries for data science and machine learning such as NumPy, Pandas, Scikit-learn, Matplotlib, and Seaborn are available as part of the updated datascience Anaconda module.
    "
"
### Context: 
Datascience Anaconda Module Updates

We have updated the datascience Anaconda module and built various packages and libraries with CUDA 12.4.1 to be compatible with 
the new Polaris NVIDIA GPU hardware driver (CUDA 12.2) and to use the latest MPI, NCCL, cuDNN, TensorRT, etc. libraries. 
PyTorch 2.3.0 and TensorFlow 2.16.1 are now available as part of this module.

To use the new environment, type:
module use /soft/modulefiles 
module load conda; conda activate

/soft refresh and default $MODULEPATH change

Due to the new system software stack, /soft has been purged to allow for
software to be rebuilt. In addition, /soft/modulefiles is no longer in the
default $MODULEPATH. To access modules installed in /soft, users should run
module use /soft/modulefiles.

Adding module use /soft/modulefiles to your profile should approximate the old behavior.

Modules removed

The following modules have been removed:

### Human: How can users access modules installed in /soft after the system software stack update?

### Assistant: Run ""module use /soft/modulefiles"" and then ""module load conda; conda activate"".
    "
"
### Context: 
cudatoolkit-standalone/12.0.0                                     paraview/paraview-5.11.2-mesa
   e4s/22.05/mvapich2                                                paraview/paraview-5.12.0-RC1-mesa
   e4s/22.05/PrgEnv-gnu                                       (D)    paraview/paraview-5.12.0-mesa                                            (D)
   e4s/22.08/mvapich2                                                singularity/3.8.7
   e4s/22.08/PrgEnv-gnu                                       (D)    tau/2.31.1
   ffmpeg/ffmpeg-6.0                                                 tau/2.32
   forge/23.0.4                                                      tau/2.33.1                                                               (D)
   ginkgo/mpi/20230314/ginkgo                                        visit/visit
   ginkgo/20230314/ginkgo                                     (D)    vmd/vmd-1.9.4a55
   gnu-parallel/2021-09-22                                           xalt/3.0.1-202308151751
   gsl/2.7                                                           xalt/3.0.1-202308261842                                                  (D)

### Human: What software packages are available in this environment?

### Assistant: The available software packages are: $e4s, forge, ginkgo, gnu-parallel, gsl, paraview, singularity, tau, vmd, and xalt.
    "
"
### Context: 
cudatoolkit-standalone/12.0.0                                     paraview/paraview-5.11.2-mesa
   e4s/22.05/mvapich2                                                paraview/paraview-5.12.0-RC1-mesa
   e4s/22.05/PrgEnv-gnu                                       (D)    paraview/paraview-5.12.0-mesa                                            (D)
   e4s/22.08/mvapich2                                                singularity/3.8.7
   e4s/22.08/PrgEnv-gnu                                       (D)    tau/2.31.1
   ffmpeg/ffmpeg-6.0                                                 tau/2.32
   forge/23.0.4                                                      tau/2.33.1                                                               (D)
   ginkgo/mpi/20230314/ginkgo                                        visit/visit
   ginkgo/20230314/ginkgo                                     (D)    vmd/vmd-1.9.4a55
   gnu-parallel/2021-09-22                                           xalt/3.0.1-202308151751
   gsl/2.7                                                           xalt/3.0.1-202308261842                                                  (D)

### Human: Which version of Paraview is currently installed?

### Assistant: paraview-5.12.0-mesa
    "
"
### Context: 
cudatoolkit-standalone/12.0.0                                     paraview/paraview-5.11.2-mesa
   e4s/22.05/mvapich2                                                paraview/paraview-5.12.0-RC1-mesa
   e4s/22.05/PrgEnv-gnu                                       (D)    paraview/paraview-5.12.0-mesa                                            (D)
   e4s/22.08/mvapich2                                                singularity/3.8.7
   e4s/22.08/PrgEnv-gnu                                       (D)    tau/2.31.1
   ffmpeg/ffmpeg-6.0                                                 tau/2.32
   forge/23.0.4                                                      tau/2.33.1                                                               (D)
   ginkgo/mpi/20230314/ginkgo                                        visit/visit
   ginkgo/20230314/ginkgo                                     (D)    vmd/vmd-1.9.4a55
   gnu-parallel/2021-09-22                                           xalt/3.0.1-202308151751
   gsl/2.7                                                           xalt/3.0.1-202308261842                                                  (D)

### Human: Is Tau 2.32 compatible with this system?

### Assistant: Tau 2.32 is likely not compatible with this system, as it is not explicitly installed and there are no indications of potential conflicts or issues.
    "
"
### Context: 
Modules newly installed

The following modules have been newly installed:

cabana/dev-9a1ad605/kokv/4.2.01/PrgEnv-gnu/8.5.0/gnu/12.3/cuda_cudatoolkit_12.2.91
   cuda-PrgEnv-nvidia/12.2.91
   cudatoolkit-standalone/12.2.2                                                      (D)
   cudatoolkit-standalone/12.3.2
   cudatoolkit-standalone/12.4.0
   cudnn/9.0.0
   forge/23.1.2
   kokkos/4.2.01/shared/PrgEnv-gnu/8.5.0/gnu/12.3/cuda_cudatoolkit_12.2.91
   spack-pe-base/0.6.1
   spack-pe-gnu/0.6.1

Note that spack-pe-base and spack-pe-gnu are metamodules which contain
further software offerings. See the Spack section below for details.

Spack

We have newly installed Spack deployments in /soft. Spack is an HPC-oriented
package manager which ALCF uses to install software for the user environment.
However, no knowledge of Spack is necessary to use these software offerings. All
ALCF-managed software is accessible to users via modules.

The base suite of software tools and libraries can be accessed by loading the
spack-pe-base module. This adds a path to $MODULEPATH which contains
numerous modules.

For example, to load cmake starting from the default environment, a user
should run the following commands:
module use /soft/modulefiles
module load spack-pe-base
module load cmake
Other modules in spack-pe-base can be browsed by running module avail or
module --show-hidden avail. The latter shows hidden modules which are
installed as dependencies of the un-hidden modules.

In addition to the base stack, a suite of higher-level libraries are installed
in the spack-pe-gnu module. These are built with and are dependent on
PrgEnv-gnu. A PrgEnv-nvidia-compatible stack will be available in the
future.

Note that not all software is installed through Spack; many applications and
libraries are installed as standalone packages in /soft. Users are encouraged
to browse the available modules with module avail to see what software is
installed on the system.

ParaView and Visit

### Human: What is Spack?

### Assistant: Spack is an HPC-oriented package manager used by ALCF to install software for the user environment.
    "
"
### Context: 
Modules newly installed

The following modules have been newly installed:

cabana/dev-9a1ad605/kokv/4.2.01/PrgEnv-gnu/8.5.0/gnu/12.3/cuda_cudatoolkit_12.2.91
   cuda-PrgEnv-nvidia/12.2.91
   cudatoolkit-standalone/12.2.2                                                      (D)
   cudatoolkit-standalone/12.3.2
   cudatoolkit-standalone/12.4.0
   cudnn/9.0.0
   forge/23.1.2
   kokkos/4.2.01/shared/PrgEnv-gnu/8.5.0/gnu/12.3/cuda_cudatoolkit_12.2.91
   spack-pe-base/0.6.1
   spack-pe-gnu/0.6.1

Note that spack-pe-base and spack-pe-gnu are metamodules which contain
further software offerings. See the Spack section below for details.

Spack

We have newly installed Spack deployments in /soft. Spack is an HPC-oriented
package manager which ALCF uses to install software for the user environment.
However, no knowledge of Spack is necessary to use these software offerings. All
ALCF-managed software is accessible to users via modules.

The base suite of software tools and libraries can be accessed by loading the
spack-pe-base module. This adds a path to $MODULEPATH which contains
numerous modules.

For example, to load cmake starting from the default environment, a user
should run the following commands:
module use /soft/modulefiles
module load spack-pe-base
module load cmake
Other modules in spack-pe-base can be browsed by running module avail or
module --show-hidden avail. The latter shows hidden modules which are
installed as dependencies of the un-hidden modules.

In addition to the base stack, a suite of higher-level libraries are installed
in the spack-pe-gnu module. These are built with and are dependent on
PrgEnv-gnu. A PrgEnv-nvidia-compatible stack will be available in the
future.

Note that not all software is installed through Spack; many applications and
libraries are installed as standalone packages in /soft. Users are encouraged
to browse the available modules with module avail to see what software is
installed on the system.

ParaView and Visit

### Human: How do I access the base suite of software tools and libraries using Spack?

### Assistant: Load the spack-pe-base module.
    "
"
### Context: 
Modules newly installed

The following modules have been newly installed:

cabana/dev-9a1ad605/kokv/4.2.01/PrgEnv-gnu/8.5.0/gnu/12.3/cuda_cudatoolkit_12.2.91
   cuda-PrgEnv-nvidia/12.2.91
   cudatoolkit-standalone/12.2.2                                                      (D)
   cudatoolkit-standalone/12.3.2
   cudatoolkit-standalone/12.4.0
   cudnn/9.0.0
   forge/23.1.2
   kokkos/4.2.01/shared/PrgEnv-gnu/8.5.0/gnu/12.3/cuda_cudatoolkit_12.2.91
   spack-pe-base/0.6.1
   spack-pe-gnu/0.6.1

Note that spack-pe-base and spack-pe-gnu are metamodules which contain
further software offerings. See the Spack section below for details.

Spack

We have newly installed Spack deployments in /soft. Spack is an HPC-oriented
package manager which ALCF uses to install software for the user environment.
However, no knowledge of Spack is necessary to use these software offerings. All
ALCF-managed software is accessible to users via modules.

The base suite of software tools and libraries can be accessed by loading the
spack-pe-base module. This adds a path to $MODULEPATH which contains
numerous modules.

For example, to load cmake starting from the default environment, a user
should run the following commands:
module use /soft/modulefiles
module load spack-pe-base
module load cmake
Other modules in spack-pe-base can be browsed by running module avail or
module --show-hidden avail. The latter shows hidden modules which are
installed as dependencies of the un-hidden modules.

In addition to the base stack, a suite of higher-level libraries are installed
in the spack-pe-gnu module. These are built with and are dependent on
PrgEnv-gnu. A PrgEnv-nvidia-compatible stack will be available in the
future.

Note that not all software is installed through Spack; many applications and
libraries are installed as standalone packages in /soft. Users are encouraged
to browse the available modules with module avail to see what software is
installed on the system.

ParaView and Visit

### Human: Where are applications and libraries installed that are not managed by Spack?

### Assistant: Applications and libraries not managed by Spack are installed as standalone packages in the `/soft` directory.
    "
"
### Context: 
ParaView and Visit

ParaView module has been updated. For more information, see https://docs.alcf.anl.gov/polaris/visualization/paraview/ and https://docs.alcf.anl.gov/polaris/visualization/paraview-manual-launch/

Visit module is in the process of being updated.

Changes to Memory Limits on Login Nodes

Memory limits were lowered on the logins due to resource contention to 8GB of memory, and 8 cores per user. 
This might result in error messages indicating abnormal process termination for user processes run on logins.

Examples of the error messages people might see are:

nvcc error   : 'cudafe++' died due to signal 9 (Kill signal)

g++-12: fatal error: Killed signal terminated program cc1plus

These errors are likely due to exhausting the per-user resources on a login node as each user is allocated 8 cores and 8GB memory.
To avoid this you can either:

Reduce the parallelism of your compile, such as using -j or -j4 flags

Request a debug node and run your compile there where you will have the full resources of the node at your disposal

### Human: What is the current memory limit per user on login nodes?

### Assistant: 8GB
    "
"
### Context: 
ParaView and Visit

ParaView module has been updated. For more information, see https://docs.alcf.anl.gov/polaris/visualization/paraview/ and https://docs.alcf.anl.gov/polaris/visualization/paraview-manual-launch/

Visit module is in the process of being updated.

Changes to Memory Limits on Login Nodes

Memory limits were lowered on the logins due to resource contention to 8GB of memory, and 8 cores per user. 
This might result in error messages indicating abnormal process termination for user processes run on logins.

Examples of the error messages people might see are:

nvcc error   : 'cudafe++' died due to signal 9 (Kill signal)

g++-12: fatal error: Killed signal terminated program cc1plus

These errors are likely due to exhausting the per-user resources on a login node as each user is allocated 8 cores and 8GB memory.
To avoid this you can either:

Reduce the parallelism of your compile, such as using -j or -j4 flags

Request a debug node and run your compile there where you will have the full resources of the node at your disposal

### Human: Why am I seeing error messages indicating abnormal process termination for my processes run on logins?

### Assistant: The error messages are likely due to exhausting the per-user resources on a login node, which were lowered to 8GB memory and 8 cores per user. To avoid these errors, you can reduce parallelism or request a debug node with more resources.
    "
"
### Context: 
ParaView and Visit

ParaView module has been updated. For more information, see https://docs.alcf.anl.gov/polaris/visualization/paraview/ and https://docs.alcf.anl.gov/polaris/visualization/paraview-manual-launch/

Visit module is in the process of being updated.

Changes to Memory Limits on Login Nodes

Memory limits were lowered on the logins due to resource contention to 8GB of memory, and 8 cores per user. 
This might result in error messages indicating abnormal process termination for user processes run on logins.

Examples of the error messages people might see are:

nvcc error   : 'cudafe++' died due to signal 9 (Kill signal)

g++-12: fatal error: Killed signal terminated program cc1plus

These errors are likely due to exhausting the per-user resources on a login node as each user is allocated 8 cores and 8GB memory.
To avoid this you can either:

Reduce the parallelism of your compile, such as using -j or -j4 flags

Request a debug node and run your compile there where you will have the full resources of the node at your disposal

### Human: What can I do to avoid these error messages when compiling on login nodes?

### Assistant: Reduce parallelism by using flags like `-j` or `-j4`, or request a debug node for full access to resources.
    "
"
### Context: 
Running Jobs on Polaris

Queues

There are five production queues you can target in your qsub (-q <queue name>):

Queue Name Node Min Node Max Time Min Time Max Notes debug 1 2 5 min 1 hr max 24 nodes in use by this queue ay any given time; Only 8 nodes are exclusive (see Note below) debug-scaling 1 10 5 min 1 hr max 1 job running/accruing/queued per-user prod 10 496 5 min 24 hrs Routing queue; See below preemptable 1 10 5 min 72 hrs Please be aware that jobs in the preemptable queue can be killed at any time if jobs are submitted to the demand queue. Max 20 jobs running/accruing/queued per-project ; see Note below demand 1 56 5 min 1 hr By request only ; max 100 jobs running/accruing/queued per-project

Note: Please be aware that jobs in the preemptable queue can be killed at any time if jobs are submitted to the demand queue.
Jobs in the demand queue take priority over jobs in the preemptable queue.
This means jobs in the preemptable queue may be preempted (killed without any warning) if there are jobs in the demand queue.
Unfortunately, there's always an inherent risk of jobs being killed when using the preemptable queue. 
Please use the following command to view details of a queue: qstat -Qf <queuename>

To make your job re-runable add the following PBS directive: #PBS -r y This will ensure your job will restart once the demand job is complete.

Note: The debug queue has 8 exclusively dedicated nodes.
If there are free nodes in production, then debug jobs can take another 16 nodes for a total of 24.

prod is routing queue and routes your job to one of the following six execution queues:

Queue Name Node Min Node Max Time Min Time Max Notes small 10 24 5 min 3 hrs medium 25 99 5 min 6 hrs large 100 496 5 min 24 hrs backfill-small 10 24 5 min 3 hrs low priority, negative project balance backfill-medium 25 99 5 min 6 hrs low priority, negative project balance backfill-large 100 496 5 min 24 hrs low priority, negative project balance

### Human: What is the minimum time required for a job to run in the 'debug' queue?

### Assistant: 5 minutes
    "
"
### Context: 
Running Jobs on Polaris

Queues

There are five production queues you can target in your qsub (-q <queue name>):

Queue Name Node Min Node Max Time Min Time Max Notes debug 1 2 5 min 1 hr max 24 nodes in use by this queue ay any given time; Only 8 nodes are exclusive (see Note below) debug-scaling 1 10 5 min 1 hr max 1 job running/accruing/queued per-user prod 10 496 5 min 24 hrs Routing queue; See below preemptable 1 10 5 min 72 hrs Please be aware that jobs in the preemptable queue can be killed at any time if jobs are submitted to the demand queue. Max 20 jobs running/accruing/queued per-project ; see Note below demand 1 56 5 min 1 hr By request only ; max 100 jobs running/accruing/queued per-project

Note: Please be aware that jobs in the preemptable queue can be killed at any time if jobs are submitted to the demand queue.
Jobs in the demand queue take priority over jobs in the preemptable queue.
This means jobs in the preemptable queue may be preempted (killed without any warning) if there are jobs in the demand queue.
Unfortunately, there's always an inherent risk of jobs being killed when using the preemptable queue. 
Please use the following command to view details of a queue: qstat -Qf <queuename>

To make your job re-runable add the following PBS directive: #PBS -r y This will ensure your job will restart once the demand job is complete.

Note: The debug queue has 8 exclusively dedicated nodes.
If there are free nodes in production, then debug jobs can take another 16 nodes for a total of 24.

prod is routing queue and routes your job to one of the following six execution queues:

Queue Name Node Min Node Max Time Min Time Max Notes small 10 24 5 min 3 hrs medium 25 99 5 min 6 hrs large 100 496 5 min 24 hrs backfill-small 10 24 5 min 3 hrs low priority, negative project balance backfill-medium 25 99 5 min 6 hrs low priority, negative project balance backfill-large 100 496 5 min 24 hrs low priority, negative project balance

### Human: Can you preempt jobs in the 'demand' queue?

### Assistant: No, you cannot preempt jobs in the 'demand' queue.
    "
"
### Context: 
Running Jobs on Polaris

Queues

There are five production queues you can target in your qsub (-q <queue name>):

Queue Name Node Min Node Max Time Min Time Max Notes debug 1 2 5 min 1 hr max 24 nodes in use by this queue ay any given time; Only 8 nodes are exclusive (see Note below) debug-scaling 1 10 5 min 1 hr max 1 job running/accruing/queued per-user prod 10 496 5 min 24 hrs Routing queue; See below preemptable 1 10 5 min 72 hrs Please be aware that jobs in the preemptable queue can be killed at any time if jobs are submitted to the demand queue. Max 20 jobs running/accruing/queued per-project ; see Note below demand 1 56 5 min 1 hr By request only ; max 100 jobs running/accruing/queued per-project

Note: Please be aware that jobs in the preemptable queue can be killed at any time if jobs are submitted to the demand queue.
Jobs in the demand queue take priority over jobs in the preemptable queue.
This means jobs in the preemptable queue may be preempted (killed without any warning) if there are jobs in the demand queue.
Unfortunately, there's always an inherent risk of jobs being killed when using the preemptable queue. 
Please use the following command to view details of a queue: qstat -Qf <queuename>

To make your job re-runable add the following PBS directive: #PBS -r y This will ensure your job will restart once the demand job is complete.

Note: The debug queue has 8 exclusively dedicated nodes.
If there are free nodes in production, then debug jobs can take another 16 nodes for a total of 24.

prod is routing queue and routes your job to one of the following six execution queues:

Queue Name Node Min Node Max Time Min Time Max Notes small 10 24 5 min 3 hrs medium 25 99 5 min 6 hrs large 100 496 5 min 24 hrs backfill-small 10 24 5 min 3 hrs low priority, negative project balance backfill-medium 25 99 5 min 6 hrs low priority, negative project balance backfill-large 100 496 5 min 24 hrs low priority, negative project balance

### Human: How many nodes can be used by debug jobs if there are free nodes available?

### Assistant: 24
    "
"
### Context: 
https://www.alcf.anl.gov/support/user-guides/polaris/hardware-overview/machine-overview/index.html

gpu=$((${num_gpus} - 1 - ${PMI_LOCAL_RANK} % ${num_gpus}))
export CUDA_VISIBLE_DEVICES=$gpu
echo “RANK= ${PMI_RANK} LOCAL_RANK= ${PMI_LOCAL_RANK} gpu= ${gpu}”
exec ""$@""
This script can be placed just before the executable in the `mpiexec` command like so.bash
mpiexec -n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --depth=${NDEPTH} --cpu-bind depth ./set_affinity_gpu_polaris.sh ./hello_affinity
```
Users with different needs, such as assigning multiple GPUs per MPI rank, can modify the above script to suit their needs.

Interactive Jobs on Compute Nodes

Here is how to submit an interactive job to, for example, edit/build/test an application Polaris compute nodes:
qsub -I -l select=1 -l filesystems=home:eagle -l walltime=1:00:00 -q debug -A <project_name>

This command requests 1 node for a period of 1 hour in the debug queue, requiring access to the /home and eagle filesystems. After waiting in the queue for a node to become available, a shell prompt on a compute node will appear. You may then start building applications and testing gpu affinity scripts on the compute node.

NOTE: If you want to ssh or scp to one of your assigned compute nodes you will need to make sure your $HOME directory and your $HOME/.ssh directory permissions are both set to 700.

Running Multiple MPI Applications on a node

### Human: What is the purpose of the script used in the `mpiexec` command?

### Assistant: The purpose of the script used in the `mpiexec` command is to assign unique GPUs to each MPI rank for concurrent execution.
    "
"
### Context: 
https://www.alcf.anl.gov/support/user-guides/polaris/hardware-overview/machine-overview/index.html

gpu=$((${num_gpus} - 1 - ${PMI_LOCAL_RANK} % ${num_gpus}))
export CUDA_VISIBLE_DEVICES=$gpu
echo “RANK= ${PMI_RANK} LOCAL_RANK= ${PMI_LOCAL_RANK} gpu= ${gpu}”
exec ""$@""
This script can be placed just before the executable in the `mpiexec` command like so.bash
mpiexec -n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --depth=${NDEPTH} --cpu-bind depth ./set_affinity_gpu_polaris.sh ./hello_affinity
```
Users with different needs, such as assigning multiple GPUs per MPI rank, can modify the above script to suit their needs.

Interactive Jobs on Compute Nodes

Here is how to submit an interactive job to, for example, edit/build/test an application Polaris compute nodes:
qsub -I -l select=1 -l filesystems=home:eagle -l walltime=1:00:00 -q debug -A <project_name>

This command requests 1 node for a period of 1 hour in the debug queue, requiring access to the /home and eagle filesystems. After waiting in the queue for a node to become available, a shell prompt on a compute node will appear. You may then start building applications and testing gpu affinity scripts on the compute node.

NOTE: If you want to ssh or scp to one of your assigned compute nodes you will need to make sure your $HOME directory and your $HOME/.ssh directory permissions are both set to 700.

Running Multiple MPI Applications on a node

### Human: How do you submit an interactive job to the compute nodes?

### Assistant: qsub -I -l select=1 -l filesystems=home:eagle -l walltime=1:00:00 -q debug -A <project_name>
    "
"
### Context: 
https://www.alcf.anl.gov/support/user-guides/polaris/hardware-overview/machine-overview/index.html

gpu=$((${num_gpus} - 1 - ${PMI_LOCAL_RANK} % ${num_gpus}))
export CUDA_VISIBLE_DEVICES=$gpu
echo “RANK= ${PMI_RANK} LOCAL_RANK= ${PMI_LOCAL_RANK} gpu= ${gpu}”
exec ""$@""
This script can be placed just before the executable in the `mpiexec` command like so.bash
mpiexec -n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --depth=${NDEPTH} --cpu-bind depth ./set_affinity_gpu_polaris.sh ./hello_affinity
```
Users with different needs, such as assigning multiple GPUs per MPI rank, can modify the above script to suit their needs.

Interactive Jobs on Compute Nodes

Here is how to submit an interactive job to, for example, edit/build/test an application Polaris compute nodes:
qsub -I -l select=1 -l filesystems=home:eagle -l walltime=1:00:00 -q debug -A <project_name>

This command requests 1 node for a period of 1 hour in the debug queue, requiring access to the /home and eagle filesystems. After waiting in the queue for a node to become available, a shell prompt on a compute node will appear. You may then start building applications and testing gpu affinity scripts on the compute node.

NOTE: If you want to ssh or scp to one of your assigned compute nodes you will need to make sure your $HOME directory and your $HOME/.ssh directory permissions are both set to 700.

Running Multiple MPI Applications on a node

### Human: What is required for users to ssh or scp to one of their assigned compute nodes?

### Assistant: Users need to ensure that their $HOME directory and their $HOME/.ssh directory permissions are both set to 700.
    "
"
### Context: 
Controlling Where Your Job Runs

If you wish to have your job run on specific nodes form your select like this: -l select=1:vnode=<node name1>+1:vnode=<node name2>... . Obviously, that gets tedious for large jobs.

If you want to control the location of a few nodes, for example 2 out of 64, but the rest don't matter, you can do something like this: -l select=1:vnode=<node name1>+1:vnode=<node name2>+62:system=foo

Every node has a PBS resource called tier0 with a rack identifier and tier1 with a dragonfly group identifieer.  If you want all your nodes grouped in a rack, you can add the group specifier -l select=8:system=foo,place=scatter:group=tier0.  If you wanted everything in the same dragonfly group, replace tier0 with tier1.  Note that you have to also explicitly specify the place when you use group.  If you wanted a specific rack or dragonfly group instead of any of them, you are back to the select: -l select 10:tier0=x3001-g0.

Network: Rack and Dragonfly Group Mappings

Racks contain (7) 6U chassis; each chassis has 2 nodes for 14 nodes per rack

The hostnames are of the form xRRPPc0sUUb[0|1]n0 where:
RR is the row {30, 31, 32}
PP is the position in the row {30 goes 1-16, 31 and 32 go 1-12}
c is chassis and is always 0
s stands for slot, but in this case is the RU in the rack and values are {1,7,13,19,25,31,37}
b is BMC controller and is 0 or 1 (each node has its own BMC)
n is node, but is always 0 since there is only one node per BMC

So, 16+12+12 = 40 racks * 14 nodes per rack = 560 nodes.

Note that in production group 9 (the last 4 racks) will be the designated on-demand racks

The management racks are x3000 and X3100 and are dragonfly group 10

The TDS rack is x3200 and is dragonfly group 11

### Human: How can you specify which nodes a job runs on?

### Assistant: To specify which nodes a job runs on, use the PBS resource specification option `-l` and follow the steps outlined above.
    "
"
### Context: 
Controlling Where Your Job Runs

If you wish to have your job run on specific nodes form your select like this: -l select=1:vnode=<node name1>+1:vnode=<node name2>... . Obviously, that gets tedious for large jobs.

If you want to control the location of a few nodes, for example 2 out of 64, but the rest don't matter, you can do something like this: -l select=1:vnode=<node name1>+1:vnode=<node name2>+62:system=foo

Every node has a PBS resource called tier0 with a rack identifier and tier1 with a dragonfly group identifieer.  If you want all your nodes grouped in a rack, you can add the group specifier -l select=8:system=foo,place=scatter:group=tier0.  If you wanted everything in the same dragonfly group, replace tier0 with tier1.  Note that you have to also explicitly specify the place when you use group.  If you wanted a specific rack or dragonfly group instead of any of them, you are back to the select: -l select 10:tier0=x3001-g0.

Network: Rack and Dragonfly Group Mappings

Racks contain (7) 6U chassis; each chassis has 2 nodes for 14 nodes per rack

The hostnames are of the form xRRPPc0sUUb[0|1]n0 where:
RR is the row {30, 31, 32}
PP is the position in the row {30 goes 1-16, 31 and 32 go 1-12}
c is chassis and is always 0
s stands for slot, but in this case is the RU in the rack and values are {1,7,13,19,25,31,37}
b is BMC controller and is 0 or 1 (each node has its own BMC)
n is node, but is always 0 since there is only one node per BMC

So, 16+12+12 = 40 racks * 14 nodes per rack = 560 nodes.

Note that in production group 9 (the last 4 racks) will be the designated on-demand racks

The management racks are x3000 and X3100 and are dragonfly group 10

The TDS rack is x3200 and is dragonfly group 11

### Human: What is the purpose of the ""place"" specifier in a PBS resource request?

### Assistant: The purpose of the ""place"" specifier is to control where a job runs by specifying a location or group of nodes.
    "
"
### Context: 
Controlling Where Your Job Runs

If you wish to have your job run on specific nodes form your select like this: -l select=1:vnode=<node name1>+1:vnode=<node name2>... . Obviously, that gets tedious for large jobs.

If you want to control the location of a few nodes, for example 2 out of 64, but the rest don't matter, you can do something like this: -l select=1:vnode=<node name1>+1:vnode=<node name2>+62:system=foo

Every node has a PBS resource called tier0 with a rack identifier and tier1 with a dragonfly group identifieer.  If you want all your nodes grouped in a rack, you can add the group specifier -l select=8:system=foo,place=scatter:group=tier0.  If you wanted everything in the same dragonfly group, replace tier0 with tier1.  Note that you have to also explicitly specify the place when you use group.  If you wanted a specific rack or dragonfly group instead of any of them, you are back to the select: -l select 10:tier0=x3001-g0.

Network: Rack and Dragonfly Group Mappings

Racks contain (7) 6U chassis; each chassis has 2 nodes for 14 nodes per rack

The hostnames are of the form xRRPPc0sUUb[0|1]n0 where:
RR is the row {30, 31, 32}
PP is the position in the row {30 goes 1-16, 31 and 32 go 1-12}
c is chassis and is always 0
s stands for slot, but in this case is the RU in the rack and values are {1,7,13,19,25,31,37}
b is BMC controller and is 0 or 1 (each node has its own BMC)
n is node, but is always 0 since there is only one node per BMC

So, 16+12+12 = 40 racks * 14 nodes per rack = 560 nodes.

Note that in production group 9 (the last 4 racks) will be the designated on-demand racks

The management racks are x3000 and X3100 and are dragonfly group 10

The TDS rack is x3200 and is dragonfly group 11

### Human: How many total nodes are there in the production group?

### Assistant: 616
    "
"
### Context: 
The TDS rack is x3200 and is dragonfly group 11

Each compute node will have a PBS resource named tier0 which will be equal to the values in the table below.  This allows you to group your jobs within a rack if you wish.  There is also a resource called tier1 which will be equal to the column headings.  This allows you to group your jobs within a dragonfly group if you wish.

g0 g1 g2 g3 g4 g5 g6 g7 g8 g9 x3001-g0 x3005-g1 x3009-g2 x3013-g3 x3101-g4 x3105-g5 x3109-g6 x3201-g7 x3205-g8 x3209-g9 x3002-g0 x3006-g1 x3010-g2 x3014-g3 x3102-g4 x3106-g5 x3110-g6 x3202-g7 x3206-g8 x3210-g9 x3003-g0 x3007-g1 x3011-g2 x3015-g3 x3103-g4 x3107-g5 x3111-g6 x3203-g7 x3207-g8 x3211-g9 x3004-g0 x3008-g1 x3012-g2 x3016-g3 x3104-g4 x3108-g5 x3112-g6 x3204-g7 x3208-g8 x3212-g9

### Human: What is the TDS rack number?

### Assistant: x3200
    "
"
### Context: 
The TDS rack is x3200 and is dragonfly group 11

Each compute node will have a PBS resource named tier0 which will be equal to the values in the table below.  This allows you to group your jobs within a rack if you wish.  There is also a resource called tier1 which will be equal to the column headings.  This allows you to group your jobs within a dragonfly group if you wish.

g0 g1 g2 g3 g4 g5 g6 g7 g8 g9 x3001-g0 x3005-g1 x3009-g2 x3013-g3 x3101-g4 x3105-g5 x3109-g6 x3201-g7 x3205-g8 x3209-g9 x3002-g0 x3006-g1 x3010-g2 x3014-g3 x3102-g4 x3106-g5 x3110-g6 x3202-g7 x3206-g8 x3210-g9 x3003-g0 x3007-g1 x3011-g2 x3015-g3 x3103-g4 x3107-g5 x3111-g6 x3203-g7 x3207-g8 x3211-g9 x3004-g0 x3008-g1 x3012-g2 x3016-g3 x3104-g4 x3108-g5 x3112-g6 x3204-g7 x3208-g8 x3212-g9

### Human: Which PBS resources are used to group jobs within a dragonfly group?

### Assistant: The PBS resources used to group jobs within a dragonfly group are tier1, and the specific value for group 11 is x32.
    "
"
### Context: 
The TDS rack is x3200 and is dragonfly group 11

Each compute node will have a PBS resource named tier0 which will be equal to the values in the table below.  This allows you to group your jobs within a rack if you wish.  There is also a resource called tier1 which will be equal to the column headings.  This allows you to group your jobs within a dragonfly group if you wish.

g0 g1 g2 g3 g4 g5 g6 g7 g8 g9 x3001-g0 x3005-g1 x3009-g2 x3013-g3 x3101-g4 x3105-g5 x3109-g6 x3201-g7 x3205-g8 x3209-g9 x3002-g0 x3006-g1 x3010-g2 x3014-g3 x3102-g4 x3106-g5 x3110-g6 x3202-g7 x3206-g8 x3210-g9 x3003-g0 x3007-g1 x3011-g2 x3015-g3 x3103-g4 x3107-g5 x3111-g6 x3203-g7 x3207-g8 x3211-g9 x3004-g0 x3008-g1 x3012-g2 x3016-g3 x3104-g4 x3108-g5 x3112-g6 x3204-g7 x3208-g8 x3212-g9

### Human: Can you give me an example of a job grouping within a rack?

### Assistant: The job grouping within a rack is x3001-g0 to x3209-g9.
    "
"
### Context: 
Known Issues

This is a collection of known issues that have been encountered on Polaris. Documentation will be updated as issues are resolved. Users are encouraged to email support@alcf.anl.gov to report issues.

Submitting Jobs

For batch job submissions, if the parameters within your submission script do not meet the parameters of any of the execution queues (small, ..., backfill-large) you might not receive the ""Job submission"" error on the command line at all, and the job will never appear in history qstat -xu <username> (current bug in PBS). E.g. if a user submits a script to the prod routing queue requesting 10 nodes for 24 hours, exceeding ""Time Max"" of 6 hrs of the small execution queue (which handles jobs with 10-24 nodes), then it may behave as if the job was never submitted.

Job scripts are copied to temporary locations after qsub and any changes to the original script while the job is queued will not be reflected in the copied script. Furthermore, qalter requires -A <allocation name> when changing job properties. Currently, there is a request for a qalter-like command to trigger a re-copy of the original script to the temporary location.

Compiling & Running Applications

If your job fails to start with an RPC launch message like below, please forward the complete messages to support@alcf.anl.gov.

bash
   launch failed on x3104c0s1b0n0: Couldn't forward RPC launch(ab751d77-e80a-4c54-b1c2-4e881f7e8c90) to child x3104c0s31b0n0.hsn.cm.polaris.alcf.anl.gov: Resource temporarily unavailable

### Human: What happens if you submit a job with parameters that don't match any of the execution queues?

### Assistant: The job will not appear in history and will not receive an error message on the command line.
    "
"
### Context: 
Known Issues

This is a collection of known issues that have been encountered on Polaris. Documentation will be updated as issues are resolved. Users are encouraged to email support@alcf.anl.gov to report issues.

Submitting Jobs

For batch job submissions, if the parameters within your submission script do not meet the parameters of any of the execution queues (small, ..., backfill-large) you might not receive the ""Job submission"" error on the command line at all, and the job will never appear in history qstat -xu <username> (current bug in PBS). E.g. if a user submits a script to the prod routing queue requesting 10 nodes for 24 hours, exceeding ""Time Max"" of 6 hrs of the small execution queue (which handles jobs with 10-24 nodes), then it may behave as if the job was never submitted.

Job scripts are copied to temporary locations after qsub and any changes to the original script while the job is queued will not be reflected in the copied script. Furthermore, qalter requires -A <allocation name> when changing job properties. Currently, there is a request for a qalter-like command to trigger a re-copy of the original script to the temporary location.

Compiling & Running Applications

If your job fails to start with an RPC launch message like below, please forward the complete messages to support@alcf.anl.gov.

bash
   launch failed on x3104c0s1b0n0: Couldn't forward RPC launch(ab751d77-e80a-4c54-b1c2-4e881f7e8c90) to child x3104c0s31b0n0.hsn.cm.polaris.alcf.anl.gov: Resource temporarily unavailable

### Human: Why do changes made to your job script after submission not get reflected in the copied script?

### Assistant: Job scripts are copied to temporary locations after submission, and subsequent changes to the original script do not affect the copied script.
    "
"
### Context: 
Known Issues

This is a collection of known issues that have been encountered on Polaris. Documentation will be updated as issues are resolved. Users are encouraged to email support@alcf.anl.gov to report issues.

Submitting Jobs

For batch job submissions, if the parameters within your submission script do not meet the parameters of any of the execution queues (small, ..., backfill-large) you might not receive the ""Job submission"" error on the command line at all, and the job will never appear in history qstat -xu <username> (current bug in PBS). E.g. if a user submits a script to the prod routing queue requesting 10 nodes for 24 hours, exceeding ""Time Max"" of 6 hrs of the small execution queue (which handles jobs with 10-24 nodes), then it may behave as if the job was never submitted.

Job scripts are copied to temporary locations after qsub and any changes to the original script while the job is queued will not be reflected in the copied script. Furthermore, qalter requires -A <allocation name> when changing job properties. Currently, there is a request for a qalter-like command to trigger a re-copy of the original script to the temporary location.

Compiling & Running Applications

If your job fails to start with an RPC launch message like below, please forward the complete messages to support@alcf.anl.gov.

bash
   launch failed on x3104c0s1b0n0: Couldn't forward RPC launch(ab751d77-e80a-4c54-b1c2-4e881f7e8c90) to child x3104c0s31b0n0.hsn.cm.polaris.alcf.anl.gov: Resource temporarily unavailable

### Human: What should you do if your job fails to start with an RPC launch message like the one shown?

### Assistant: Forward the complete message to support@alcf.anl.gov.
    "
"
### Context: 
NVIDIA Nsight tools

References

NVIDIA Nsight Systems Documentation

NVIDIA Nsight Compute Documentation

Introduction

NVIDIA® Nsight™ Systems provides developers a system-wide visualization of an applications performance. Developers can optimize bottlenecks to scale efficiently across any number or size of CPUs and GPUs on Polaris. For further optimizations to compute kernels developers should use Nsight Compute.

The NVIDIA Nsight Compute is an interactive kernel profiler for CUDA applications. It provides detailed performance metrics and API debugging via a user interface and command line tool.

In addition, the baseline feature of this tool allows users to compare results within the tool. NVIDIA Nsight Compute provides a customizable and data-driven user interface,  metric collection, and can be extended with analysis scripts for post-processing results.

Step-by-step guide

Common part on Polaris

Build your application for Polaris, and then submit your job script to Polaris or start an interactive job mode on Polaris as follows:

```
$ qsub -I -l select=1 -l walltime=1:00:00 -l filesystems=home:eagle -q debug -A

$ module li

Currently Loaded Modules:
  1) nvhpc/23.9          5) cray-pmi/6.1.13      9) PrgEnv-nvhpc/8.5.0      13) darshan/3.4.4
  2) craype/2.7.30       6) cray-pals/1.3.4     10) libfabric/1.15.2.0
  3) cray-dsmml/0.2.2    7) cray-libpals/1.3.4  11) craype-network-ofi
  4) cray-mpich/8.1.28   8) craype-x86-milan    12) perftools-base/23.12.0

$ nsys --version
NVIDIA Nsight Systems version 2023.3.1.92-233133147223v0

$ ncu --version
NVIDIA (R) Nsight Compute Command Line Profiler
Copyright (c) 2018-2023 NVIDIA Corporation
Version 2023.2.1.0 (build 33050884) (public-release)
NVIDIA Nsight Systems version 2022.4.2.1-df9881f
```

Nsight Systems

Run your application with Nsight Systems as follows:

$ nsys profile -o {output_filename} --stats=true ./{your_application}

### Human: What is the primary function of NVIDIA Nsight Systems?

### Assistant: The primary function of NVIDIA Nsight Systems is to provide a system-wide visualization of an application's performance.
    "
"
### Context: 
NVIDIA Nsight tools

References

NVIDIA Nsight Systems Documentation

NVIDIA Nsight Compute Documentation

Introduction

NVIDIA® Nsight™ Systems provides developers a system-wide visualization of an applications performance. Developers can optimize bottlenecks to scale efficiently across any number or size of CPUs and GPUs on Polaris. For further optimizations to compute kernels developers should use Nsight Compute.

The NVIDIA Nsight Compute is an interactive kernel profiler for CUDA applications. It provides detailed performance metrics and API debugging via a user interface and command line tool.

In addition, the baseline feature of this tool allows users to compare results within the tool. NVIDIA Nsight Compute provides a customizable and data-driven user interface,  metric collection, and can be extended with analysis scripts for post-processing results.

Step-by-step guide

Common part on Polaris

Build your application for Polaris, and then submit your job script to Polaris or start an interactive job mode on Polaris as follows:

```
$ qsub -I -l select=1 -l walltime=1:00:00 -l filesystems=home:eagle -q debug -A

$ module li

Currently Loaded Modules:
  1) nvhpc/23.9          5) cray-pmi/6.1.13      9) PrgEnv-nvhpc/8.5.0      13) darshan/3.4.4
  2) craype/2.7.30       6) cray-pals/1.3.4     10) libfabric/1.15.2.0
  3) cray-dsmml/0.2.2    7) cray-libpals/1.3.4  11) craype-network-ofi
  4) cray-mpich/8.1.28   8) craype-x86-milan    12) perftools-base/23.12.0

$ nsys --version
NVIDIA Nsight Systems version 2023.3.1.92-233133147223v0

$ ncu --version
NVIDIA (R) Nsight Compute Command Line Profiler
Copyright (c) 2018-2023 NVIDIA Corporation
Version 2023.2.1.0 (build 33050884) (public-release)
NVIDIA Nsight Systems version 2022.4.2.1-df9881f
```

Nsight Systems

Run your application with Nsight Systems as follows:

$ nsys profile -o {output_filename} --stats=true ./{your_application}

### Human: What feature allows users to compare results within the Nsight Compute tool?

### Assistant: Baseline

$Baseline
    "
"
### Context: 
NVIDIA Nsight tools

References

NVIDIA Nsight Systems Documentation

NVIDIA Nsight Compute Documentation

Introduction

NVIDIA® Nsight™ Systems provides developers a system-wide visualization of an applications performance. Developers can optimize bottlenecks to scale efficiently across any number or size of CPUs and GPUs on Polaris. For further optimizations to compute kernels developers should use Nsight Compute.

The NVIDIA Nsight Compute is an interactive kernel profiler for CUDA applications. It provides detailed performance metrics and API debugging via a user interface and command line tool.

In addition, the baseline feature of this tool allows users to compare results within the tool. NVIDIA Nsight Compute provides a customizable and data-driven user interface,  metric collection, and can be extended with analysis scripts for post-processing results.

Step-by-step guide

Common part on Polaris

Build your application for Polaris, and then submit your job script to Polaris or start an interactive job mode on Polaris as follows:

```
$ qsub -I -l select=1 -l walltime=1:00:00 -l filesystems=home:eagle -q debug -A

$ module li

Currently Loaded Modules:
  1) nvhpc/23.9          5) cray-pmi/6.1.13      9) PrgEnv-nvhpc/8.5.0      13) darshan/3.4.4
  2) craype/2.7.30       6) cray-pals/1.3.4     10) libfabric/1.15.2.0
  3) cray-dsmml/0.2.2    7) cray-libpals/1.3.4  11) craype-network-ofi
  4) cray-mpich/8.1.28   8) craype-x86-milan    12) perftools-base/23.12.0

$ nsys --version
NVIDIA Nsight Systems version 2023.3.1.92-233133147223v0

$ ncu --version
NVIDIA (R) Nsight Compute Command Line Profiler
Copyright (c) 2018-2023 NVIDIA Corporation
Version 2023.2.1.0 (build 33050884) (public-release)
NVIDIA Nsight Systems version 2022.4.2.1-df9881f
```

Nsight Systems

Run your application with Nsight Systems as follows:

$ nsys profile -o {output_filename} --stats=true ./{your_application}

### Human: How do you run your application with Nsight Systems?

### Assistant: Run your application with Nsight Systems by submitting a job script to Polaris, loading necessary modules, and running the `nsys profile` command.
    "
"
### Context: 
$ nsys profile -o {output_filename} --stats=true ./{your_application}

Run your application on multiple nodes (e.g., 2 nodes) with Nsight Systems as follows:
$ mpirun -n 8 --ppn 4 --env TMPDIR=/home/{user ID}/ nsys profile -o {output_filename}_%q{PMI_RANK} --stats=true ./{your_application}

Nsight Compute

Run your application with Nsight Compute.

$ ncu --set detailed -k {kernel_name} -o {output_filename} ./{your_application}

Remark: Without -o option, Nsight Compute provides performance data as a standard output

Post-processing the profiled data

Post-processing via CLI

$ nsys stats {output_filename}.qdrep
$ ncu -i {output_filename}.ncu-rep

Post-processing on your local system via GUI

Install NVIDIA Nsight Systems and NVIDIA Nsight Compute after downloading both of them from the  NVIDIA Developer Zone. 
Remark: Local client version should be the same as or newer than NVIDIA Nsight tools on Polaris.

Download nsys output files (i.e., ending with .qdrep and . sqlite) to your local system, and then open them with NVIDIA Nsight Systems on your local system.

Download ncu output files (i.e., ending with .ncu-rep) to your local system, and then open them with NVIDIA Nsight Compute on your local system.

More options for performance analysis with Nsight Systems and Nsight Compute

$ nsys --help
$ ncu --help

A quick example

Nsight Systems

Running a stream benchmark with Nsight Systems

```
jkwack@x3008c0s13b1n0:~/BabelStream/build_polaris> nsys profile -o JKreport-nsys-BableStream --stats=true ./cuda-stream
Warning: LBR backtrace method is not supported on this platform. DWARF backtrace method will be used.
Collecting data...
BabelStream
Version: 4.0
Implementation: CUDA
Running kernels 100 times
Precision: double
Array size: 268.4 MB (=0.3 GB)
Total size: 805.3 MB (=0.8 GB)
Using CUDA device NVIDIA A100-SXM4-40GB
Driver: 11040
Function    MBytes/sec  Min (sec)   Max         Average

Copy        1368294.603 0.00039     0.00044     0.00039

### Human: What is Nsight Systems used for?

### Assistant: Nsight Systems is used for profiling and analyzing the performance of applications.
    "
"
### Context: 
$ nsys profile -o {output_filename} --stats=true ./{your_application}

Run your application on multiple nodes (e.g., 2 nodes) with Nsight Systems as follows:
$ mpirun -n 8 --ppn 4 --env TMPDIR=/home/{user ID}/ nsys profile -o {output_filename}_%q{PMI_RANK} --stats=true ./{your_application}

Nsight Compute

Run your application with Nsight Compute.

$ ncu --set detailed -k {kernel_name} -o {output_filename} ./{your_application}

Remark: Without -o option, Nsight Compute provides performance data as a standard output

Post-processing the profiled data

Post-processing via CLI

$ nsys stats {output_filename}.qdrep
$ ncu -i {output_filename}.ncu-rep

Post-processing on your local system via GUI

Install NVIDIA Nsight Systems and NVIDIA Nsight Compute after downloading both of them from the  NVIDIA Developer Zone. 
Remark: Local client version should be the same as or newer than NVIDIA Nsight tools on Polaris.

Download nsys output files (i.e., ending with .qdrep and . sqlite) to your local system, and then open them with NVIDIA Nsight Systems on your local system.

Download ncu output files (i.e., ending with .ncu-rep) to your local system, and then open them with NVIDIA Nsight Compute on your local system.

More options for performance analysis with Nsight Systems and Nsight Compute

$ nsys --help
$ ncu --help

A quick example

Nsight Systems

Running a stream benchmark with Nsight Systems

```
jkwack@x3008c0s13b1n0:~/BabelStream/build_polaris> nsys profile -o JKreport-nsys-BableStream --stats=true ./cuda-stream
Warning: LBR backtrace method is not supported on this platform. DWARF backtrace method will be used.
Collecting data...
BabelStream
Version: 4.0
Implementation: CUDA
Running kernels 100 times
Precision: double
Array size: 268.4 MB (=0.3 GB)
Total size: 805.3 MB (=0.8 GB)
Using CUDA device NVIDIA A100-SXM4-40GB
Driver: 11040
Function    MBytes/sec  Min (sec)   Max         Average

Copy        1368294.603 0.00039     0.00044     0.00039

### Human: How can you post-process ncu output files?

### Assistant: Post-process via CLI: $ nsys stats {output_filename}.qdrep and $ ncu -i {output_filename}.ncu-rep.
    "
"
### Context: 
$ nsys profile -o {output_filename} --stats=true ./{your_application}

Run your application on multiple nodes (e.g., 2 nodes) with Nsight Systems as follows:
$ mpirun -n 8 --ppn 4 --env TMPDIR=/home/{user ID}/ nsys profile -o {output_filename}_%q{PMI_RANK} --stats=true ./{your_application}

Nsight Compute

Run your application with Nsight Compute.

$ ncu --set detailed -k {kernel_name} -o {output_filename} ./{your_application}

Remark: Without -o option, Nsight Compute provides performance data as a standard output

Post-processing the profiled data

Post-processing via CLI

$ nsys stats {output_filename}.qdrep
$ ncu -i {output_filename}.ncu-rep

Post-processing on your local system via GUI

Install NVIDIA Nsight Systems and NVIDIA Nsight Compute after downloading both of them from the  NVIDIA Developer Zone. 
Remark: Local client version should be the same as or newer than NVIDIA Nsight tools on Polaris.

Download nsys output files (i.e., ending with .qdrep and . sqlite) to your local system, and then open them with NVIDIA Nsight Systems on your local system.

Download ncu output files (i.e., ending with .ncu-rep) to your local system, and then open them with NVIDIA Nsight Compute on your local system.

More options for performance analysis with Nsight Systems and Nsight Compute

$ nsys --help
$ ncu --help

A quick example

Nsight Systems

Running a stream benchmark with Nsight Systems

```
jkwack@x3008c0s13b1n0:~/BabelStream/build_polaris> nsys profile -o JKreport-nsys-BableStream --stats=true ./cuda-stream
Warning: LBR backtrace method is not supported on this platform. DWARF backtrace method will be used.
Collecting data...
BabelStream
Version: 4.0
Implementation: CUDA
Running kernels 100 times
Precision: double
Array size: 268.4 MB (=0.3 GB)
Total size: 805.3 MB (=0.8 GB)
Using CUDA device NVIDIA A100-SXM4-40GB
Driver: 11040
Function    MBytes/sec  Min (sec)   Max         Average

Copy        1368294.603 0.00039     0.00044     0.00039

### Human: What does the ""BabelStream"" version number refer to in the context of CUDA kernels?

### Assistant: The ""BabelStream"" version number refers to the version of the BabelStream benchmark application being run, which is 4.0 in this case.
    "
"
### Context: 
Copy        1368294.603 0.00039     0.00044     0.00039

Mul         1334324.779 0.00040     0.00051     0.00041

Add         1358476.737 0.00059     0.00060     0.00059

Triad       1366095.332 0.00059     0.00059     0.00059

Dot         1190200.569 0.00045     0.00047     0.00046

Processing events...
Saving temporary ""/var/tmp/pbs.308834.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov/nsys-report-f594-c524-6b4c-300a.qdstrm"" file to disk...

Creating final output files...
Processing [===============================================================100%]
Saved report file to ""/var/tmp/pbs.308834.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov/nsys-report-f594-c524-6b4c-300a.qdrep""
Exporting 7675 events: [===================================================100%]

Exported successfully to
/var/tmp/pbs.308834.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov/nsys-report-f594-c524-6b4c-300a.sqlite

CUDA API Statistics:

Time(%)  Total Time (ns)  Num Calls  Average (ns)  Minimum (ns)  Maximum (ns)  StdDev (ns)           Name

CUDA Kernel Statistics:

Time(%)  Total Time (ns)  Instances  Average (ns)  Minimum (ns)  Maximum (ns)  StdDev (ns)                             Name

CUDA Memory Operation Statistics (by time):

Time(%)  Total Time (ns)  Count  Average (ns)  Minimum (ns)  Maximum (ns)  StdDev (ns)      Operation

100.0       61,323,171    103     595,370.6         2,399    20,470,146  3,439,982.0  [CUDA memcpy DtoH]

CUDA Memory Operation Statistics (by size):

Total (MB)  Count  Average (MB)  Minimum (MB)  Maximum (MB)  StdDev (MB)      Operation

Operating System Runtime API Statistics:

Time(%)  Total Time (ns)  Num Calls  Average (ns)  Minimum (ns)  Maximum (ns)  StdDev (ns)        Name

Report file moved to ""/home/jkwack/BabelStream/build_polaris/JKreport-nsys-BableStream.qdrep""
Report file moved to ""/home/jkwack/BabelStream/build_polaris/JKreport-nsys-BableStream.sqlite""
```

Reviewing the Nsight Systems data via GUI

Nsight Compute

### Human: What is Nsight Systems used for?

### Assistant: Nsight Systems is used for processing events, saving temporary files, creating final output files, exporting events, and providing statistics on various aspects of system performance.
    "
"
### Context: 
Copy        1368294.603 0.00039     0.00044     0.00039

Mul         1334324.779 0.00040     0.00051     0.00041

Add         1358476.737 0.00059     0.00060     0.00059

Triad       1366095.332 0.00059     0.00059     0.00059

Dot         1190200.569 0.00045     0.00047     0.00046

Processing events...
Saving temporary ""/var/tmp/pbs.308834.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov/nsys-report-f594-c524-6b4c-300a.qdstrm"" file to disk...

Creating final output files...
Processing [===============================================================100%]
Saved report file to ""/var/tmp/pbs.308834.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov/nsys-report-f594-c524-6b4c-300a.qdrep""
Exporting 7675 events: [===================================================100%]

Exported successfully to
/var/tmp/pbs.308834.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov/nsys-report-f594-c524-6b4c-300a.sqlite

CUDA API Statistics:

Time(%)  Total Time (ns)  Num Calls  Average (ns)  Minimum (ns)  Maximum (ns)  StdDev (ns)           Name

CUDA Kernel Statistics:

Time(%)  Total Time (ns)  Instances  Average (ns)  Minimum (ns)  Maximum (ns)  StdDev (ns)                             Name

CUDA Memory Operation Statistics (by time):

Time(%)  Total Time (ns)  Count  Average (ns)  Minimum (ns)  Maximum (ns)  StdDev (ns)      Operation

100.0       61,323,171    103     595,370.6         2,399    20,470,146  3,439,982.0  [CUDA memcpy DtoH]

CUDA Memory Operation Statistics (by size):

Total (MB)  Count  Average (MB)  Minimum (MB)  Maximum (MB)  StdDev (MB)      Operation

Operating System Runtime API Statistics:

Time(%)  Total Time (ns)  Num Calls  Average (ns)  Minimum (ns)  Maximum (ns)  StdDev (ns)        Name

Report file moved to ""/home/jkwack/BabelStream/build_polaris/JKreport-nsys-BableStream.qdrep""
Report file moved to ""/home/jkwack/BabelStream/build_polaris/JKreport-nsys-BableStream.sqlite""
```

Reviewing the Nsight Systems data via GUI

Nsight Compute

### Human: Can you explain how CUDA memory operations are handled in Nsight Systems?

### Assistant: CUDA memory operations are handled in Nsight Systems by capturing and analyzing the ""[CUDA memcpy DtoH]"" operations, which can provide insights into the performance characteristics of the program.
    "
"
### Context: 
Copy        1368294.603 0.00039     0.00044     0.00039

Mul         1334324.779 0.00040     0.00051     0.00041

Add         1358476.737 0.00059     0.00060     0.00059

Triad       1366095.332 0.00059     0.00059     0.00059

Dot         1190200.569 0.00045     0.00047     0.00046

Processing events...
Saving temporary ""/var/tmp/pbs.308834.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov/nsys-report-f594-c524-6b4c-300a.qdstrm"" file to disk...

Creating final output files...
Processing [===============================================================100%]
Saved report file to ""/var/tmp/pbs.308834.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov/nsys-report-f594-c524-6b4c-300a.qdrep""
Exporting 7675 events: [===================================================100%]

Exported successfully to
/var/tmp/pbs.308834.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov/nsys-report-f594-c524-6b4c-300a.sqlite

CUDA API Statistics:

Time(%)  Total Time (ns)  Num Calls  Average (ns)  Minimum (ns)  Maximum (ns)  StdDev (ns)           Name

CUDA Kernel Statistics:

Time(%)  Total Time (ns)  Instances  Average (ns)  Minimum (ns)  Maximum (ns)  StdDev (ns)                             Name

CUDA Memory Operation Statistics (by time):

Time(%)  Total Time (ns)  Count  Average (ns)  Minimum (ns)  Maximum (ns)  StdDev (ns)      Operation

100.0       61,323,171    103     595,370.6         2,399    20,470,146  3,439,982.0  [CUDA memcpy DtoH]

CUDA Memory Operation Statistics (by size):

Total (MB)  Count  Average (MB)  Minimum (MB)  Maximum (MB)  StdDev (MB)      Operation

Operating System Runtime API Statistics:

Time(%)  Total Time (ns)  Num Calls  Average (ns)  Minimum (ns)  Maximum (ns)  StdDev (ns)        Name

Report file moved to ""/home/jkwack/BabelStream/build_polaris/JKreport-nsys-BableStream.qdrep""
Report file moved to ""/home/jkwack/BabelStream/build_polaris/JKreport-nsys-BableStream.sqlite""
```

Reviewing the Nsight Systems data via GUI

Nsight Compute

### Human: How does the Nsight Compute tool visualize data?

### Assistant: Nsight Compute visualizes data by providing detailed statistics and metrics for various aspects of the application's behavior, including CUDA API Statistics, CUDA Kernel Statistics, and CUDA Memory Operation Statistics, which are presented in a graphical format to facilitate easy analysis and understanding.
    "
"
### Context: 
Reviewing the Nsight Systems data via GUI

Nsight Compute

Running a stream benchmark with Nsight Compute for triad_kernel

### Human: What is Nsight Compute used for?

### Assistant: Nsight Compute is used for running stream benchmarks.
    "
"
### Context: 
Reviewing the Nsight Compute data via GUI

### Human: How do I access Nsight Compute in GUI mode?

### Assistant: Access Nsight Compute in GUI mode by opening the application, navigating to the File menu, and selecting the ""Open"" or ""Load"" option.
    "
"
### Context: 
Reviewing the Nsight Compute data via GUI

### Human: What features does Nsight Compute offer for reviewing compute data?

### Assistant: Nsight Compute offers features such as compute time, memory bandwidth, memory usage, events, and timeline for reviewing compute data via its GUI.
    "
"
### Context: 
Reviewing the Nsight Compute data via GUI

### Human: Can I customize my Nsight Compute experience with GUI settings?

### Assistant: Yes, you can customize your Nsight Compute experience with GUI settings.
    "
"
### Context: 
Polaris

Polaris is a 560 node HPE Apollo 6500 Gen 10+ based system.  Each node has a single 2.8 GHz AMD EPYC Milan 7543P 32 core CPU with 512 GB of DDR4 RAM and four NVIDIA A100 GPUs connected via NVLink, a pair of local 1.6TB of SSDs in RAID0 for the users use, and a pair of Slingshot 11 network adapters.  There are two nodes per chassis, seven chassis per rack, and 40 racks for a total of 560 nodes.  More detailed specifications are as follows:

Polaris Compute Nodes

POLARIS COMPUTE DESCRIPTION PER NODE AGGREGATE Processor (Note 1) 2.8 GHz 7543P 1 560 Cores/Threads AMD Zen 3 (Milan) 32/64 17,920/35,840 RAM (Note 2) DDR4 512 GiB 280 TiB GPUS NVIDIA A100 4 2240 Local SSD 1.6 TB 2/3.2 TB 1120/1.8PB

Note 1: 256MB shared L3 cache, 512KB L2 cache per core, 32 KB L1 cache per core
Note 2: 8 memory channels rated at 204.8 GiB/s

Polaris A100 GPU Information

DESCRIPTION A100 PCIe A100 HGX (Polaris) GPU Memory 40 GiB HBM2 160 GiB HBM2 GPU Memory BW 1.6 TB/s 6.4 TB/s Interconnect PCIe Gen4 64 GB/s NVLink 600 GB/s FP 64 9.7 TF 38.8 TF FP64 Tensor Core 19.5 TF 78 TF FP 32 19.5 TF 78 TF BF16 Tensor Core 312 TF 1.3 PF FP16 Tensor Core 312 TF 1.3 PF INT8 Tensor Core 624 TOPS 2496 TOPS Max TDP Power 250 W 400 W

Polaris Device Affinity Information

CPU Affinity NUMA Affinity GPU0 GPU1 GPU2 GPU3 mlx5_0 mlx5_1 24-31,56-63 3 GPU0 X NV4 NV4 NV4 SYS SYS 16-23,48-55 2 GPU1 NV4 X NV4 NV4 SYS PHB 8-15,40-47 1 GPU2 NV4 NV4 X NV4 SYS SYS 0-7,32-39 0 GPU3 NV4 NV4 NV4 X PHB SYS mlx5_0 SYS SYS SYS PHB X SYS mlx5_1 SYS PHB SYS SYS SYS X

Legend:

### Human: How many nodes does the Polaris system have?

### Assistant: The Polaris system has 560 nodes.
    "
"
### Context: 
Polaris

Polaris is a 560 node HPE Apollo 6500 Gen 10+ based system.  Each node has a single 2.8 GHz AMD EPYC Milan 7543P 32 core CPU with 512 GB of DDR4 RAM and four NVIDIA A100 GPUs connected via NVLink, a pair of local 1.6TB of SSDs in RAID0 for the users use, and a pair of Slingshot 11 network adapters.  There are two nodes per chassis, seven chassis per rack, and 40 racks for a total of 560 nodes.  More detailed specifications are as follows:

Polaris Compute Nodes

POLARIS COMPUTE DESCRIPTION PER NODE AGGREGATE Processor (Note 1) 2.8 GHz 7543P 1 560 Cores/Threads AMD Zen 3 (Milan) 32/64 17,920/35,840 RAM (Note 2) DDR4 512 GiB 280 TiB GPUS NVIDIA A100 4 2240 Local SSD 1.6 TB 2/3.2 TB 1120/1.8PB

Note 1: 256MB shared L3 cache, 512KB L2 cache per core, 32 KB L1 cache per core
Note 2: 8 memory channels rated at 204.8 GiB/s

Polaris A100 GPU Information

DESCRIPTION A100 PCIe A100 HGX (Polaris) GPU Memory 40 GiB HBM2 160 GiB HBM2 GPU Memory BW 1.6 TB/s 6.4 TB/s Interconnect PCIe Gen4 64 GB/s NVLink 600 GB/s FP 64 9.7 TF 38.8 TF FP64 Tensor Core 19.5 TF 78 TF FP 32 19.5 TF 78 TF BF16 Tensor Core 312 TF 1.3 PF FP16 Tensor Core 312 TF 1.3 PF INT8 Tensor Core 624 TOPS 2496 TOPS Max TDP Power 250 W 400 W

Polaris Device Affinity Information

CPU Affinity NUMA Affinity GPU0 GPU1 GPU2 GPU3 mlx5_0 mlx5_1 24-31,56-63 3 GPU0 X NV4 NV4 NV4 SYS SYS 16-23,48-55 2 GPU1 NV4 X NV4 NV4 SYS PHB 8-15,40-47 1 GPU2 NV4 NV4 X NV4 SYS SYS 0-7,32-39 0 GPU3 NV4 NV4 NV4 X PHB SYS mlx5_0 SYS SYS SYS PHB X SYS mlx5_1 SYS PHB SYS SYS SYS X

Legend:

### Human: What is the clock speed of each processor node in Polaris?

### Assistant: 2.8 GHz
    "
"
### Context: 
Polaris

Polaris is a 560 node HPE Apollo 6500 Gen 10+ based system.  Each node has a single 2.8 GHz AMD EPYC Milan 7543P 32 core CPU with 512 GB of DDR4 RAM and four NVIDIA A100 GPUs connected via NVLink, a pair of local 1.6TB of SSDs in RAID0 for the users use, and a pair of Slingshot 11 network adapters.  There are two nodes per chassis, seven chassis per rack, and 40 racks for a total of 560 nodes.  More detailed specifications are as follows:

Polaris Compute Nodes

POLARIS COMPUTE DESCRIPTION PER NODE AGGREGATE Processor (Note 1) 2.8 GHz 7543P 1 560 Cores/Threads AMD Zen 3 (Milan) 32/64 17,920/35,840 RAM (Note 2) DDR4 512 GiB 280 TiB GPUS NVIDIA A100 4 2240 Local SSD 1.6 TB 2/3.2 TB 1120/1.8PB

Note 1: 256MB shared L3 cache, 512KB L2 cache per core, 32 KB L1 cache per core
Note 2: 8 memory channels rated at 204.8 GiB/s

Polaris A100 GPU Information

DESCRIPTION A100 PCIe A100 HGX (Polaris) GPU Memory 40 GiB HBM2 160 GiB HBM2 GPU Memory BW 1.6 TB/s 6.4 TB/s Interconnect PCIe Gen4 64 GB/s NVLink 600 GB/s FP 64 9.7 TF 38.8 TF FP64 Tensor Core 19.5 TF 78 TF FP 32 19.5 TF 78 TF BF16 Tensor Core 312 TF 1.3 PF FP16 Tensor Core 312 TF 1.3 PF INT8 Tensor Core 624 TOPS 2496 TOPS Max TDP Power 250 W 400 W

Polaris Device Affinity Information

CPU Affinity NUMA Affinity GPU0 GPU1 GPU2 GPU3 mlx5_0 mlx5_1 24-31,56-63 3 GPU0 X NV4 NV4 NV4 SYS SYS 16-23,48-55 2 GPU1 NV4 X NV4 NV4 SYS PHB 8-15,40-47 1 GPU2 NV4 NV4 X NV4 SYS SYS 0-7,32-39 0 GPU3 NV4 NV4 NV4 X PHB SYS mlx5_0 SYS SYS SYS PHB X SYS mlx5_1 SYS PHB SYS SYS SYS X

Legend:

### Human: How much memory bandwidth does a single NVIDIA A100 GPU on Polaris offer through NVLink?

### Assistant: The single NVIDIA A100 GPU on Polaris offers 600 GB/s of memory bandwidth through NVLink.
    "
"
### Context: 
Legend:

X    = Self
SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)
NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node
PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)
PXB  = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)
PIX  = Connection traversing at most a single PCIe bridge
NV#  = Connection traversing a bonded set of # NVLinks

Links to detailed NVIDIA A100 documentation:
    - NVIDIA A100 Tensor Core GPU Architecture
    - NVIDIA Ampere Architecture In-Depth

Login nodes

There are four login nodes available to users for editing code, building code, submitting / monitoring jobs, checking usage (sbank), etc..  Their full hostnames are polaris-login-N.hsn.cm.polaris.alcf.anl.gov  for N equal to 01 through 04; there are an additional two login nodes that are not user-accessible which are used for running services such as JupyterHub. The various compilers and libraries are present on the logins, so most users should be able to build their code.  However, if your build requires the physical presence of the GPU, you will need to build on a compute node.

All users share the same login nodes so please be courteous and respectful of your fellow users.  For example, please do not run computationally or IO intensive pre- or post-processing on the logins and keep the parallelism of your builds to a reasonable level.

POLARIS LOGIN DESCRIPTION PER NODE AGGREGATE Processor (Note 1) 2.0 GHz 7713 2 12 Cores/Threads AMD Zen 3 (Milan) 128/256 768/1536 RAM (Note 2) DDR4 512 GiB 3 TiB GPUs (Note 3) No GPUs 0 0 Local SSD None 0 0

Note 1: 256MB shared L3 cache, 512KB L2 cache per core, 32 KB L1 cache per core
Note 2: 8 memory channels rated at 204.8 GiB/s per socket
Note 3: If your build requires the physical presence of a GPU you will need to build on a compute node.

Gateway nodes

### Human: What type of processors do the login nodes use?

### Assistant: The login nodes use AMD Zen 3 (Milan) processors.
    "
"
### Context: 
Legend:

X    = Self
SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)
NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node
PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)
PXB  = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)
PIX  = Connection traversing at most a single PCIe bridge
NV#  = Connection traversing a bonded set of # NVLinks

Links to detailed NVIDIA A100 documentation:
    - NVIDIA A100 Tensor Core GPU Architecture
    - NVIDIA Ampere Architecture In-Depth

Login nodes

There are four login nodes available to users for editing code, building code, submitting / monitoring jobs, checking usage (sbank), etc..  Their full hostnames are polaris-login-N.hsn.cm.polaris.alcf.anl.gov  for N equal to 01 through 04; there are an additional two login nodes that are not user-accessible which are used for running services such as JupyterHub. The various compilers and libraries are present on the logins, so most users should be able to build their code.  However, if your build requires the physical presence of the GPU, you will need to build on a compute node.

All users share the same login nodes so please be courteous and respectful of your fellow users.  For example, please do not run computationally or IO intensive pre- or post-processing on the logins and keep the parallelism of your builds to a reasonable level.

POLARIS LOGIN DESCRIPTION PER NODE AGGREGATE Processor (Note 1) 2.0 GHz 7713 2 12 Cores/Threads AMD Zen 3 (Milan) 128/256 768/1536 RAM (Note 2) DDR4 512 GiB 3 TiB GPUs (Note 3) No GPUs 0 0 Local SSD None 0 0

Note 1: 256MB shared L3 cache, 512KB L2 cache per core, 32 KB L1 cache per core
Note 2: 8 memory channels rated at 204.8 GiB/s per socket
Note 3: If your build requires the physical presence of a GPU you will need to build on a compute node.

Gateway nodes

### Human: How many cores and threads does each login node processor have?

### Assistant: 12 Cores/Threads
    "
"
### Context: 
Legend:

X    = Self
SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)
NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node
PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)
PXB  = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)
PIX  = Connection traversing at most a single PCIe bridge
NV#  = Connection traversing a bonded set of # NVLinks

Links to detailed NVIDIA A100 documentation:
    - NVIDIA A100 Tensor Core GPU Architecture
    - NVIDIA Ampere Architecture In-Depth

Login nodes

There are four login nodes available to users for editing code, building code, submitting / monitoring jobs, checking usage (sbank), etc..  Their full hostnames are polaris-login-N.hsn.cm.polaris.alcf.anl.gov  for N equal to 01 through 04; there are an additional two login nodes that are not user-accessible which are used for running services such as JupyterHub. The various compilers and libraries are present on the logins, so most users should be able to build their code.  However, if your build requires the physical presence of the GPU, you will need to build on a compute node.

All users share the same login nodes so please be courteous and respectful of your fellow users.  For example, please do not run computationally or IO intensive pre- or post-processing on the logins and keep the parallelism of your builds to a reasonable level.

POLARIS LOGIN DESCRIPTION PER NODE AGGREGATE Processor (Note 1) 2.0 GHz 7713 2 12 Cores/Threads AMD Zen 3 (Milan) 128/256 768/1536 RAM (Note 2) DDR4 512 GiB 3 TiB GPUs (Note 3) No GPUs 0 0 Local SSD None 0 0

Note 1: 256MB shared L3 cache, 512KB L2 cache per core, 32 KB L1 cache per core
Note 2: 8 memory channels rated at 204.8 GiB/s per socket
Note 3: If your build requires the physical presence of a GPU you will need to build on a compute node.

Gateway nodes

### Human: Can users build their code on a login node if it requires physical presence of a GPU?

### Assistant: No, users cannot build their code on a login node if it requires physical presence of a GPU.
    "
"
### Context: 
Gateway nodes

There are 50 gateway nodes.  These nodes are not user accessible, but are used transparently for access to the storage systems.  Each node has a single 200 Gbps HDR IB card for access to the storage area network.  This gives a theoretical peak bandwidth of 1250 GB/s which is approximately the aggregate bandwidth of the global file systems (1300 GB/s).

Storage

Polaris has access to the ALCF global file systems.  Details on storage can be found here.

### Human: How many gateway nodes are there in Polaris?

### Assistant: 50
    "
"
### Context: 
Gateway nodes

There are 50 gateway nodes.  These nodes are not user accessible, but are used transparently for access to the storage systems.  Each node has a single 200 Gbps HDR IB card for access to the storage area network.  This gives a theoretical peak bandwidth of 1250 GB/s which is approximately the aggregate bandwidth of the global file systems (1300 GB/s).

Storage

Polaris has access to the ALCF global file systems.  Details on storage can be found here.

### Human: What is the theoretical peak bandwidth of each node's HDR IB card?

### Assistant: Theoretical peak bandwidth of each node's HDR IB card: 200 Gbps.
    "
"
### Context: 
Gateway nodes

There are 50 gateway nodes.  These nodes are not user accessible, but are used transparently for access to the storage systems.  Each node has a single 200 Gbps HDR IB card for access to the storage area network.  This gives a theoretical peak bandwidth of 1250 GB/s which is approximately the aggregate bandwidth of the global file systems (1300 GB/s).

Storage

Polaris has access to the ALCF global file systems.  Details on storage can be found here.

### Human: Where can you find more details on storage in Polaris?

### Assistant: Details on storage can be found by accessing the ALCF global file systems.
    "
"
### Context: 
Example Programs and Makefiles for Polaris

Several simple examples of building CPU and GPU-enabled codes on Polaris are available in the ALCF GettingStart repo for several programming models. If build your application is problematic for some reason (e.g. absence of a GPU), then users are encouraged to build and test applications directly on one of the Polaris compute nodes via an interactive job. The discussion below makes use of the NVHPC compilers in the default environment as illustrative examples. Similar examples for other compilers on Polaris are available in the ALCF GettingStarted repo.

CPU MPI+OpenMP Example

One of the first useful tasks with any new machine, scheduler, and job launcher is to ensure one is binding MPI ranks and OpenMP threads to the host cpu as intended. A simple HelloWorld MPI+OpenMP example is available here to get started with.

The application can be straightforwardly compiled using the Cray compiler wrappers.
CC -fopenmp main.cpp -o hello_affinity

The executable hello_affinity can then be launched in a job script (or directly in shell of interactive job) using mpiexec as discussed here.

```

!/bin/sh

PBS -l select=1:system=polaris

PBS -l place=scatter

PBS -l walltime=0:30:00

PBS -l filesystems=home

MPI example w/ 16 MPI ranks per node spread evenly across cores

NNODES=wc -l < $PBS_NODEFILE
NRANKS_PER_NODE=16
NDEPTH=4
NTHREADS=1

NTOTRANKS=$(( NNODES * NRANKS_PER_NODE ))
echo ""NUM_OF_NODES= ${NNODES} TOTAL_NUM_RANKS= ${NTOTRANKS} RANKS_PER_NODE= ${NRANKS_PER_NODE} THREADS_PER_RANK= ${NTHREADS}""

mpiexec -n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --depth=${NDEPTH} --cpu-bind depth ./hello_affinity
```

CUDA

Several variants of C/C++ and Fortran CUDA examples are available here that include MPI and multi-gpu examples.

One can use the Cray compiler wrappers to compile GPU-enabled applications as well. This example of simple vector addition uses the NVIDIA compilers.

CC -g -O3 -std=c++0x -cuda main.cpp -o vecadd

### Human: How can I compile a CPU-enabled code on Polaris?

### Assistant: Compile with `CC -fopenmp main.cpp -o hello_affinity` and launch with `mpiexec`.
    "
"
### Context: 
Example Programs and Makefiles for Polaris

Several simple examples of building CPU and GPU-enabled codes on Polaris are available in the ALCF GettingStart repo for several programming models. If build your application is problematic for some reason (e.g. absence of a GPU), then users are encouraged to build and test applications directly on one of the Polaris compute nodes via an interactive job. The discussion below makes use of the NVHPC compilers in the default environment as illustrative examples. Similar examples for other compilers on Polaris are available in the ALCF GettingStarted repo.

CPU MPI+OpenMP Example

One of the first useful tasks with any new machine, scheduler, and job launcher is to ensure one is binding MPI ranks and OpenMP threads to the host cpu as intended. A simple HelloWorld MPI+OpenMP example is available here to get started with.

The application can be straightforwardly compiled using the Cray compiler wrappers.
CC -fopenmp main.cpp -o hello_affinity

The executable hello_affinity can then be launched in a job script (or directly in shell of interactive job) using mpiexec as discussed here.

```

!/bin/sh

PBS -l select=1:system=polaris

PBS -l place=scatter

PBS -l walltime=0:30:00

PBS -l filesystems=home

MPI example w/ 16 MPI ranks per node spread evenly across cores

NNODES=wc -l < $PBS_NODEFILE
NRANKS_PER_NODE=16
NDEPTH=4
NTHREADS=1

NTOTRANKS=$(( NNODES * NRANKS_PER_NODE ))
echo ""NUM_OF_NODES= ${NNODES} TOTAL_NUM_RANKS= ${NTOTRANKS} RANKS_PER_NODE= ${NRANKS_PER_NODE} THREADS_PER_RANK= ${NTHREADS}""

mpiexec -n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --depth=${NDEPTH} --cpu-bind depth ./hello_affinity
```

CUDA

Several variants of C/C++ and Fortran CUDA examples are available here that include MPI and multi-gpu examples.

One can use the Cray compiler wrappers to compile GPU-enabled applications as well. This example of simple vector addition uses the NVIDIA compilers.

CC -g -O3 -std=c++0x -cuda main.cpp -o vecadd

### Human: What is a simple way to launch an MPI+OpenMP job script on Polaris?

### Assistant: The final answer is that you can launch an MPI+OpenMP job script on Polaris by compiling your application with OpenMP support and then submitting a job script that uses `mpiexec` to launch the executable with the desired resources.
    "
"
### Context: 
Example Programs and Makefiles for Polaris

Several simple examples of building CPU and GPU-enabled codes on Polaris are available in the ALCF GettingStart repo for several programming models. If build your application is problematic for some reason (e.g. absence of a GPU), then users are encouraged to build and test applications directly on one of the Polaris compute nodes via an interactive job. The discussion below makes use of the NVHPC compilers in the default environment as illustrative examples. Similar examples for other compilers on Polaris are available in the ALCF GettingStarted repo.

CPU MPI+OpenMP Example

One of the first useful tasks with any new machine, scheduler, and job launcher is to ensure one is binding MPI ranks and OpenMP threads to the host cpu as intended. A simple HelloWorld MPI+OpenMP example is available here to get started with.

The application can be straightforwardly compiled using the Cray compiler wrappers.
CC -fopenmp main.cpp -o hello_affinity

The executable hello_affinity can then be launched in a job script (or directly in shell of interactive job) using mpiexec as discussed here.

```

!/bin/sh

PBS -l select=1:system=polaris

PBS -l place=scatter

PBS -l walltime=0:30:00

PBS -l filesystems=home

MPI example w/ 16 MPI ranks per node spread evenly across cores

NNODES=wc -l < $PBS_NODEFILE
NRANKS_PER_NODE=16
NDEPTH=4
NTHREADS=1

NTOTRANKS=$(( NNODES * NRANKS_PER_NODE ))
echo ""NUM_OF_NODES= ${NNODES} TOTAL_NUM_RANKS= ${NTOTRANKS} RANKS_PER_NODE= ${NRANKS_PER_NODE} THREADS_PER_RANK= ${NTHREADS}""

mpiexec -n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --depth=${NDEPTH} --cpu-bind depth ./hello_affinity
```

CUDA

Several variants of C/C++ and Fortran CUDA examples are available here that include MPI and multi-gpu examples.

One can use the Cray compiler wrappers to compile GPU-enabled applications as well. This example of simple vector addition uses the NVIDIA compilers.

CC -g -O3 -std=c++0x -cuda main.cpp -o vecadd

### Human: How do I compile a CUDA-enabled code using the NVIDIA compilers on Polaris?

### Assistant: Compile using CC -g -O3 -std=c++0x -cuda main.cpp -o vecadd.
    "
"
### Context: 
CC -g -O3 -std=c++0x -cuda main.cpp -o vecadd

The craype-accel-nvidia80 module in the default environment will add the -gpu compiler flag for nvhpc compilers along with appropriate include directories and libraries. It is left to the user to provide an additional flag to the nvhpc compilers to select the target GPU programming model. In this case, -cuda is used to indicate compilation of CUDA code. The application can then be launched within a batch job submission script or as follows on one of the compute nodes.

```
$ ./vecadd

of devices= 4

[0] Platform[ Nvidia ] Type[ GPU ] Device[ NVIDIA A100-SXM4-40GB ]
  [1] Platform[ Nvidia ] Type[ GPU ] Device[ NVIDIA A100-SXM4-40GB ]
  [2] Platform[ Nvidia ] Type[ GPU ] Device[ NVIDIA A100-SXM4-40GB ]
  [3] Platform[ Nvidia ] Type[ GPU ] Device[ NVIDIA A100-SXM4-40GB ]
Running on GPU 0!
Using single-precision

Name= NVIDIA A100-SXM4-40GB
  Locally unique identifier= 
  Clock Frequency(KHz)= 1410000
  Compute Mode= 0
  Major compute capability= 8
  Minor compute capability= 0
  Number of multiprocessors on device= 108
  Warp size in threads= 32
  Single precision performance ratio= 2

Result is CORRECT!! :)
```

GPU OpenACC

A simple MPI-parallel OpenACC example is available here. Compilation proceeds similar to the above CUDA example except for the use of the -acc=gpu compiler flag to indicate compilation of OpenACC code for GPUs.
CC -g -O3 -std=c++0x -acc=gpu -gpu=cc80,cuda11.0 main.cpp -o vecadd
In this example, each MPI rank sees all four GPUs on a Polaris node and GPUs are bound to MPI ranks round-robin within the application.

```
$ mpiexec -n 4 ./vecadd

of devices= 4

Using single-precision

Rank 0 running on GPU 0!
Rank 1 running on GPU 1!
Rank 2 running on GPU 2!
Rank 3 running on GPU 3!

### Human: What is the purpose of adding the -cuda compiler flag when compiling code for NVIDIA GPUs?

### Assistant: The purpose of adding the -cuda compiler flag when compiling code for NVIDIA GPUs is to indicate compilation of CUDA code.
    "
"
### Context: 
CC -g -O3 -std=c++0x -cuda main.cpp -o vecadd

The craype-accel-nvidia80 module in the default environment will add the -gpu compiler flag for nvhpc compilers along with appropriate include directories and libraries. It is left to the user to provide an additional flag to the nvhpc compilers to select the target GPU programming model. In this case, -cuda is used to indicate compilation of CUDA code. The application can then be launched within a batch job submission script or as follows on one of the compute nodes.

```
$ ./vecadd

of devices= 4

[0] Platform[ Nvidia ] Type[ GPU ] Device[ NVIDIA A100-SXM4-40GB ]
  [1] Platform[ Nvidia ] Type[ GPU ] Device[ NVIDIA A100-SXM4-40GB ]
  [2] Platform[ Nvidia ] Type[ GPU ] Device[ NVIDIA A100-SXM4-40GB ]
  [3] Platform[ Nvidia ] Type[ GPU ] Device[ NVIDIA A100-SXM4-40GB ]
Running on GPU 0!
Using single-precision

Name= NVIDIA A100-SXM4-40GB
  Locally unique identifier= 
  Clock Frequency(KHz)= 1410000
  Compute Mode= 0
  Major compute capability= 8
  Minor compute capability= 0
  Number of multiprocessors on device= 108
  Warp size in threads= 32
  Single precision performance ratio= 2

Result is CORRECT!! :)
```

GPU OpenACC

A simple MPI-parallel OpenACC example is available here. Compilation proceeds similar to the above CUDA example except for the use of the -acc=gpu compiler flag to indicate compilation of OpenACC code for GPUs.
CC -g -O3 -std=c++0x -acc=gpu -gpu=cc80,cuda11.0 main.cpp -o vecadd
In this example, each MPI rank sees all four GPUs on a Polaris node and GPUs are bound to MPI ranks round-robin within the application.

```
$ mpiexec -n 4 ./vecadd

of devices= 4

Using single-precision

Rank 0 running on GPU 0!
Rank 1 running on GPU 1!
Rank 2 running on GPU 2!
Rank 3 running on GPU 3!

### Human: How do I specify which GPU to run my application on using OpenACC?

### Assistant: To specify which GPU to run my application on using OpenACC, you would use the `-gpu` compiler flag along with the specific GPU architecture and version you want to target.
    "
"
### Context: 
CC -g -O3 -std=c++0x -cuda main.cpp -o vecadd

The craype-accel-nvidia80 module in the default environment will add the -gpu compiler flag for nvhpc compilers along with appropriate include directories and libraries. It is left to the user to provide an additional flag to the nvhpc compilers to select the target GPU programming model. In this case, -cuda is used to indicate compilation of CUDA code. The application can then be launched within a batch job submission script or as follows on one of the compute nodes.

```
$ ./vecadd

of devices= 4

[0] Platform[ Nvidia ] Type[ GPU ] Device[ NVIDIA A100-SXM4-40GB ]
  [1] Platform[ Nvidia ] Type[ GPU ] Device[ NVIDIA A100-SXM4-40GB ]
  [2] Platform[ Nvidia ] Type[ GPU ] Device[ NVIDIA A100-SXM4-40GB ]
  [3] Platform[ Nvidia ] Type[ GPU ] Device[ NVIDIA A100-SXM4-40GB ]
Running on GPU 0!
Using single-precision

Name= NVIDIA A100-SXM4-40GB
  Locally unique identifier= 
  Clock Frequency(KHz)= 1410000
  Compute Mode= 0
  Major compute capability= 8
  Minor compute capability= 0
  Number of multiprocessors on device= 108
  Warp size in threads= 32
  Single precision performance ratio= 2

Result is CORRECT!! :)
```

GPU OpenACC

A simple MPI-parallel OpenACC example is available here. Compilation proceeds similar to the above CUDA example except for the use of the -acc=gpu compiler flag to indicate compilation of OpenACC code for GPUs.
CC -g -O3 -std=c++0x -acc=gpu -gpu=cc80,cuda11.0 main.cpp -o vecadd
In this example, each MPI rank sees all four GPUs on a Polaris node and GPUs are bound to MPI ranks round-robin within the application.

```
$ mpiexec -n 4 ./vecadd

of devices= 4

Using single-precision

Rank 0 running on GPU 0!
Rank 1 running on GPU 1!
Rank 2 running on GPU 2!
Rank 3 running on GPU 3!

### Human: In an MPI-parallel OpenACC application, how does the GPU get bound to each rank?

### Assistant: The GPU gets bound to each rank by using the `-acc=gpu` compiler flag and launching the application with `mpiexec`.
    "
"
### Context: 
Result is CORRECT!! :)
``
If the application instead relies on the job launcher to bind MPI ranks to available GPUs, then a small helper script can be used to explicitly setCUDA_VISIBLE_DEVICES` appropriately for each MPI rank. One example is available here where each MPI rank is similarly bound to a single GPU with round-robin assignment. The binding of MPI ranks to GPUs is discussed in more detail here.

GPU OpenCL

A simple OpenCL example is available here. The OpenCL headers and library are available in the NVHPC SDK and cuda toolkits. The environment variable NVIDIA_PATH is defined for the PrgEnv-nvhpc programming environment. 
CC -o vecadd -g -O3 -std=c++0x  -I${NVIDIA_PATH}/cuda/include main.o -L${NVIDIA_PATH}/cuda/lib64 -lOpenCL

This simple example can be run on a Polaris compute node as follows.
```
$ ./vecadd
Running on GPU!
Using single-precision

Result is CORRECT!! :)
```

GPU OpenMP

A simple MPI-parallel OpenMP example is available here. Compilation proceeds similar to the above examples except for use of the -mp=gpu compiler flag to indicated compilation of OpenMP code for GPUs.

CC -g -O3 -std=c++0x -mp=gpu -gpu=cc80,cuda11.0 -c main.cpp -o vecadd

Similar to the OpenACC example above, this code binds MPI ranks to GPUs in a round-robin fashion. 
```
$ mpiexec -n 4 ./vecadd

of devices= 4

Rank 0 running on GPU 0!
Rank 1 running on GPU 1!
Rank 2 running on GPU 2!
Rank 3 running on GPU 3!

Result is CORRECT!! :)
```

### Human: How can I explicitly set CUDA_VISIBLE_DEVICES for each MPI rank?

### Assistant: Use a small helper script that sets the `CUDA_VISIBLE_DEVICES` environment variable for each MPI rank based on its rank number.
    "
"
### Context: 
Result is CORRECT!! :)
``
If the application instead relies on the job launcher to bind MPI ranks to available GPUs, then a small helper script can be used to explicitly setCUDA_VISIBLE_DEVICES` appropriately for each MPI rank. One example is available here where each MPI rank is similarly bound to a single GPU with round-robin assignment. The binding of MPI ranks to GPUs is discussed in more detail here.

GPU OpenCL

A simple OpenCL example is available here. The OpenCL headers and library are available in the NVHPC SDK and cuda toolkits. The environment variable NVIDIA_PATH is defined for the PrgEnv-nvhpc programming environment. 
CC -o vecadd -g -O3 -std=c++0x  -I${NVIDIA_PATH}/cuda/include main.o -L${NVIDIA_PATH}/cuda/lib64 -lOpenCL

This simple example can be run on a Polaris compute node as follows.
```
$ ./vecadd
Running on GPU!
Using single-precision

Result is CORRECT!! :)
```

GPU OpenMP

A simple MPI-parallel OpenMP example is available here. Compilation proceeds similar to the above examples except for use of the -mp=gpu compiler flag to indicated compilation of OpenMP code for GPUs.

CC -g -O3 -std=c++0x -mp=gpu -gpu=cc80,cuda11.0 -c main.cpp -o vecadd

Similar to the OpenACC example above, this code binds MPI ranks to GPUs in a round-robin fashion. 
```
$ mpiexec -n 4 ./vecadd

of devices= 4

Rank 0 running on GPU 0!
Rank 1 running on GPU 1!
Rank 2 running on GPU 2!
Rank 3 running on GPU 3!

Result is CORRECT!! :)
```

### Human: What is an example of OpenCL code that can run on a Polaris compute node?

### Assistant: The OpenCL code that can run on a Polaris compute node is the simple example provided, which can be compiled using the command `CC -o vecadd -g -O3 -std=c++0x  -I${NVIDIA_PATH}/cuda/include main.o -L${NVIDIA_PATH}/cuda/lib64 -lOpenCL` and run with the command `$ ./vecadd`.
    "
"
### Context: 
Result is CORRECT!! :)
``
If the application instead relies on the job launcher to bind MPI ranks to available GPUs, then a small helper script can be used to explicitly setCUDA_VISIBLE_DEVICES` appropriately for each MPI rank. One example is available here where each MPI rank is similarly bound to a single GPU with round-robin assignment. The binding of MPI ranks to GPUs is discussed in more detail here.

GPU OpenCL

A simple OpenCL example is available here. The OpenCL headers and library are available in the NVHPC SDK and cuda toolkits. The environment variable NVIDIA_PATH is defined for the PrgEnv-nvhpc programming environment. 
CC -o vecadd -g -O3 -std=c++0x  -I${NVIDIA_PATH}/cuda/include main.o -L${NVIDIA_PATH}/cuda/lib64 -lOpenCL

This simple example can be run on a Polaris compute node as follows.
```
$ ./vecadd
Running on GPU!
Using single-precision

Result is CORRECT!! :)
```

GPU OpenMP

A simple MPI-parallel OpenMP example is available here. Compilation proceeds similar to the above examples except for use of the -mp=gpu compiler flag to indicated compilation of OpenMP code for GPUs.

CC -g -O3 -std=c++0x -mp=gpu -gpu=cc80,cuda11.0 -c main.cpp -o vecadd

Similar to the OpenACC example above, this code binds MPI ranks to GPUs in a round-robin fashion. 
```
$ mpiexec -n 4 ./vecadd

of devices= 4

Rank 0 running on GPU 0!
Rank 1 running on GPU 1!
Rank 2 running on GPU 2!
Rank 3 running on GPU 3!

Result is CORRECT!! :)
```

### Human: How can I compile OpenMP code for GPUs in MPI-parallel fashion?

### Assistant: To compile OpenMP code for GPUs in MPI-parallel fashion, use the `-mp=gpu` compiler flag and run the compiled code using `mpiexec` with the number of processes equal to the number of GPUs.
    "
"
### Context: 
Compiling and Linking Overview on Polaris

Compiling on Polaris Login and Compute Nodes

If your build system does not require GPUs for the build process, as is usually the case, compilation of GPU-accelerated codes is generally expected to work well on the Polaris login nodes. If your build system does require GPUs, you cannot yet compile on the Polaris login nodes, as they do not currently have GPUs installed. You may in this case compile your applications on the Polaris compute nodes. Do this by submitting an interactive single-node job, or running your build system in a batch job.

Home File System

Is it helpful to realize that there is a single HOME filesystem for users that can be accessed from the login and computes of each production resource at ALCF. Thus, users should be mindful of modifications to their environments (e.g. .bashrc) that may cause issues to arise due to differences between the systems.

Cray Programming Environment

The Cray Programming Environment (PE) uses three compiler wrappers for building software. These compiler wrappers should be used when building MPI-enabled applications.

cc - C compiler

CC - C++ compiler

ftn - Fortran compiler

Each of these wrappers can select a specific vendor compiler based on the PrgEnv module loaded in the environment. The following are some helpful options to understand what the compiler wrapper is invoking.

--craype-verbose : Print the command which is forwarded to the compiler invocation

--cray-print-opts=libs : Print library information

--cray-print-opts=cflags : Print include information

The output from these commands may be useful in build scripts where a compiler other than that invoked by a compiler wrapper is desired. Defining some variables as such may prove useful in those situations.
CRAY_CFLAGS=$(cc --cray-print-opts=cflags)
CRAY_LIB=$(cc --cray-print-opts=libs)
Further documentation and options are available via man cc and similar.

Compilers provided by Cray Programming Environments

### Human: What is the recommended way to compile GPU-accelerated codes on Polaris?

### Assistant: Compile GPU-accelerated codes on Polaris compute nodes by submitting an interactive single-node job or running my build system in a batch job.
    "
"
### Context: 
Compiling and Linking Overview on Polaris

Compiling on Polaris Login and Compute Nodes

If your build system does not require GPUs for the build process, as is usually the case, compilation of GPU-accelerated codes is generally expected to work well on the Polaris login nodes. If your build system does require GPUs, you cannot yet compile on the Polaris login nodes, as they do not currently have GPUs installed. You may in this case compile your applications on the Polaris compute nodes. Do this by submitting an interactive single-node job, or running your build system in a batch job.

Home File System

Is it helpful to realize that there is a single HOME filesystem for users that can be accessed from the login and computes of each production resource at ALCF. Thus, users should be mindful of modifications to their environments (e.g. .bashrc) that may cause issues to arise due to differences between the systems.

Cray Programming Environment

The Cray Programming Environment (PE) uses three compiler wrappers for building software. These compiler wrappers should be used when building MPI-enabled applications.

cc - C compiler

CC - C++ compiler

ftn - Fortran compiler

Each of these wrappers can select a specific vendor compiler based on the PrgEnv module loaded in the environment. The following are some helpful options to understand what the compiler wrapper is invoking.

--craype-verbose : Print the command which is forwarded to the compiler invocation

--cray-print-opts=libs : Print library information

--cray-print-opts=cflags : Print include information

The output from these commands may be useful in build scripts where a compiler other than that invoked by a compiler wrapper is desired. Defining some variables as such may prove useful in those situations.
CRAY_CFLAGS=$(cc --cray-print-opts=cflags)
CRAY_LIB=$(cc --cray-print-opts=libs)
Further documentation and options are available via man cc and similar.

Compilers provided by Cray Programming Environments

### Human: How can users access their HOME filesystem from the login and compute nodes of each production resource at ALCF?

### Assistant: Users can access their HOME filesystem by navigating to the directory using standard Unix commands, such as `cd` and `ls`, and accessing it from both the login and compute nodes of each production resource at ALCF.
    "
"
### Context: 
Compiling and Linking Overview on Polaris

Compiling on Polaris Login and Compute Nodes

If your build system does not require GPUs for the build process, as is usually the case, compilation of GPU-accelerated codes is generally expected to work well on the Polaris login nodes. If your build system does require GPUs, you cannot yet compile on the Polaris login nodes, as they do not currently have GPUs installed. You may in this case compile your applications on the Polaris compute nodes. Do this by submitting an interactive single-node job, or running your build system in a batch job.

Home File System

Is it helpful to realize that there is a single HOME filesystem for users that can be accessed from the login and computes of each production resource at ALCF. Thus, users should be mindful of modifications to their environments (e.g. .bashrc) that may cause issues to arise due to differences between the systems.

Cray Programming Environment

The Cray Programming Environment (PE) uses three compiler wrappers for building software. These compiler wrappers should be used when building MPI-enabled applications.

cc - C compiler

CC - C++ compiler

ftn - Fortran compiler

Each of these wrappers can select a specific vendor compiler based on the PrgEnv module loaded in the environment. The following are some helpful options to understand what the compiler wrapper is invoking.

--craype-verbose : Print the command which is forwarded to the compiler invocation

--cray-print-opts=libs : Print library information

--cray-print-opts=cflags : Print include information

The output from these commands may be useful in build scripts where a compiler other than that invoked by a compiler wrapper is desired. Defining some variables as such may prove useful in those situations.
CRAY_CFLAGS=$(cc --cray-print-opts=cflags)
CRAY_LIB=$(cc --cray-print-opts=libs)
Further documentation and options are available via man cc and similar.

Compilers provided by Cray Programming Environments

### Human: What are some helpful options to understand what compiler wrappers are invoking on Polaris?

### Assistant: To understand what compiler wrappers are invoking on Polaris, use the options `-craype-verbose`, `--cray-print-opts=libs`, and `--cray-print-opts=cflags` to print the command which is forwarded to the compiler invocation, library information, and include information, respectively.
    "
"
### Context: 
Compilers provided by Cray Programming Environments

The default programming environment on Polaris is currently NVHPC. The GNU compilers are available via another programming environment. The following sequence of module commands can be used to switch to the GNU programming environment (gcc, g++, gfortran) and also have NVIDIA compilers available in your path.

module swap PrgEnv-nvhpc PrgEnv-gnu
module load nvhpc-mixed

The compilers invoked by the Cray MPI wrappers are listed for each programming environment in the following table.

module C C++ Fortran MPI Compiler Wrapper cc CC ftn PrgEnv-nvhpc nvc nvc++ nvfortran PrgEnv-gnu gcc g++ gfortran

Note, while gcc and g++ may be available in the default environment, the PrgEnv-gnu module is needed to provide gfortran.

Additional Compilers Provided by ALCF

The ALCF additionally provides compilers to enable the OpenMP and SYCL programming models for GPUs viaLLVM as documented here

Additional documentation for using compilers is available on the respective programming model pages: OpenMP and SYCL.

Linking

Dynamic linking of libraries is currently the default on Polaris. The Cray MPI wrappers will handle this automatically.

Notes on Default Modules

craype-x86-rome: While the Polaris compute nodes currently have Milan CPUs, this module is loaded by default to avoid the craype-x86-milan module from adding a zen3 target not supported in the default nvhpc/21.9 compilers. The craype-x86-milan module is expected to be made default once a newer nvhpc version (e.g. 22.5) is made the default.

craype-accel-nvidia80: This module adds compiler flags to enable GPU acceleration for NVHPC compilers along with gpu-enabled MPI libraries as it is assumed that the majority of applications to be compiled on Polaris will target the GPUs for acceleration. Users building cpu-only applications may find it useful to unload this module to silence ""gpu code generation"" warnings.

Mixed C/C++ & Fortran Applications

### Human: How do I switch from the default NVHPC programming environment to the GNU programming environment on Polaris?

### Assistant: To switch from the default NVHPC programming environment to the GNU programming environment on Polaris, run `module swap PrgEnv-nvhpc PrgEnv-gnu` and then `module load nvhpc-mixed`.
    "
"
### Context: 
Compilers provided by Cray Programming Environments

The default programming environment on Polaris is currently NVHPC. The GNU compilers are available via another programming environment. The following sequence of module commands can be used to switch to the GNU programming environment (gcc, g++, gfortran) and also have NVIDIA compilers available in your path.

module swap PrgEnv-nvhpc PrgEnv-gnu
module load nvhpc-mixed

The compilers invoked by the Cray MPI wrappers are listed for each programming environment in the following table.

module C C++ Fortran MPI Compiler Wrapper cc CC ftn PrgEnv-nvhpc nvc nvc++ nvfortran PrgEnv-gnu gcc g++ gfortran

Note, while gcc and g++ may be available in the default environment, the PrgEnv-gnu module is needed to provide gfortran.

Additional Compilers Provided by ALCF

The ALCF additionally provides compilers to enable the OpenMP and SYCL programming models for GPUs viaLLVM as documented here

Additional documentation for using compilers is available on the respective programming model pages: OpenMP and SYCL.

Linking

Dynamic linking of libraries is currently the default on Polaris. The Cray MPI wrappers will handle this automatically.

Notes on Default Modules

craype-x86-rome: While the Polaris compute nodes currently have Milan CPUs, this module is loaded by default to avoid the craype-x86-milan module from adding a zen3 target not supported in the default nvhpc/21.9 compilers. The craype-x86-milan module is expected to be made default once a newer nvhpc version (e.g. 22.5) is made the default.

craype-accel-nvidia80: This module adds compiler flags to enable GPU acceleration for NVHPC compilers along with gpu-enabled MPI libraries as it is assumed that the majority of applications to be compiled on Polaris will target the GPUs for acceleration. Users building cpu-only applications may find it useful to unload this module to silence ""gpu code generation"" warnings.

Mixed C/C++ & Fortran Applications

### Human: What is the purpose of the `module swap` command when using the PrgEnv-gnu module on Polaris?

### Assistant: The purpose of the `module swap` command when using the PrgEnv-gnu module on Polaris is to switch to the GNU programming environment (gcc, g++, gfortran) and also have NVIDIA compilers available in your path.
    "
"
### Context: 
Compilers provided by Cray Programming Environments

The default programming environment on Polaris is currently NVHPC. The GNU compilers are available via another programming environment. The following sequence of module commands can be used to switch to the GNU programming environment (gcc, g++, gfortran) and also have NVIDIA compilers available in your path.

module swap PrgEnv-nvhpc PrgEnv-gnu
module load nvhpc-mixed

The compilers invoked by the Cray MPI wrappers are listed for each programming environment in the following table.

module C C++ Fortran MPI Compiler Wrapper cc CC ftn PrgEnv-nvhpc nvc nvc++ nvfortran PrgEnv-gnu gcc g++ gfortran

Note, while gcc and g++ may be available in the default environment, the PrgEnv-gnu module is needed to provide gfortran.

Additional Compilers Provided by ALCF

The ALCF additionally provides compilers to enable the OpenMP and SYCL programming models for GPUs viaLLVM as documented here

Additional documentation for using compilers is available on the respective programming model pages: OpenMP and SYCL.

Linking

Dynamic linking of libraries is currently the default on Polaris. The Cray MPI wrappers will handle this automatically.

Notes on Default Modules

craype-x86-rome: While the Polaris compute nodes currently have Milan CPUs, this module is loaded by default to avoid the craype-x86-milan module from adding a zen3 target not supported in the default nvhpc/21.9 compilers. The craype-x86-milan module is expected to be made default once a newer nvhpc version (e.g. 22.5) is made the default.

craype-accel-nvidia80: This module adds compiler flags to enable GPU acceleration for NVHPC compilers along with gpu-enabled MPI libraries as it is assumed that the majority of applications to be compiled on Polaris will target the GPUs for acceleration. Users building cpu-only applications may find it useful to unload this module to silence ""gpu code generation"" warnings.

Mixed C/C++ & Fortran Applications

### Human: Are the NVIDIA compilers available for both C, C++, and Fortran programming languages in the default PrgEnv-nvhpc environment?

### Assistant: The NVIDIA compilers are available for both C, C++, and Fortran programming languages in the default PrgEnv-nvhpc environment.
    "
"
### Context: 
Mixed C/C++ & Fortran Applications

For applications consisting of a mix of C/C++ and Fortran that also uses MPI, it is suggested that the programming environment chosen for Fortran be used to build the full application because of mpi.mod (and similar) incompatibilities.

Compiling for GPUs

It is assumed the majority of applications to be built on Polaris will make use of the GPUs. As such, the craype-accel-nvidia80 module is in the default environment. This has the effect of the Cray compiler wrappers adding -gpu to the compiler invocation along with additional include paths and libraries. Additional compilers flags may be needed depending on the compiler and GPU programming model used (e.g. -cuda, -acc, or -mp=gpu).

This module also adds GPU Transport Layer (GTL) libraries to the link-line to support GPU-aware MPI applications.

Man Pages

For additional information on the Cray wrappers, please refer to the man pages.
man cc
man CC
man ftn

### Human: What module is in the default environment for building applications that use GPUs?

### Assistant: craype-accel-nvidia80
    "
"
### Context: 
Mixed C/C++ & Fortran Applications

For applications consisting of a mix of C/C++ and Fortran that also uses MPI, it is suggested that the programming environment chosen for Fortran be used to build the full application because of mpi.mod (and similar) incompatibilities.

Compiling for GPUs

It is assumed the majority of applications to be built on Polaris will make use of the GPUs. As such, the craype-accel-nvidia80 module is in the default environment. This has the effect of the Cray compiler wrappers adding -gpu to the compiler invocation along with additional include paths and libraries. Additional compilers flags may be needed depending on the compiler and GPU programming model used (e.g. -cuda, -acc, or -mp=gpu).

This module also adds GPU Transport Layer (GTL) libraries to the link-line to support GPU-aware MPI applications.

Man Pages

For additional information on the Cray wrappers, please refer to the man pages.
man cc
man CC
man ftn

### Human: What flag should I add to my compiler invocation when using the Cray compiler wrapper with CUDA programming model?

### Assistant: -cuda
    "
"
### Context: 
Mixed C/C++ & Fortran Applications

For applications consisting of a mix of C/C++ and Fortran that also uses MPI, it is suggested that the programming environment chosen for Fortran be used to build the full application because of mpi.mod (and similar) incompatibilities.

Compiling for GPUs

It is assumed the majority of applications to be built on Polaris will make use of the GPUs. As such, the craype-accel-nvidia80 module is in the default environment. This has the effect of the Cray compiler wrappers adding -gpu to the compiler invocation along with additional include paths and libraries. Additional compilers flags may be needed depending on the compiler and GPU programming model used (e.g. -cuda, -acc, or -mp=gpu).

This module also adds GPU Transport Layer (GTL) libraries to the link-line to support GPU-aware MPI applications.

Man Pages

For additional information on the Cray wrappers, please refer to the man pages.
man cc
man CC
man ftn

### Human: Where can I find additional information on the Cray compiler wrappers, including details on their usage and options?

### Assistant: The man pages for the Cray compiler wrappers (cc, CC, ftn) contain additional information on their usage and options.
    "
"
### Context: 
GNU Compilers on Polaris

The GNU compilers are available on Polaris via the PrgEnv-gnu and gcc-mixed modules. The gcc-mixed module can be useful when, for example, the PrgEnv-nvhpc compilers are used to compile C/C++ MPI-enabled code and gfortran is needed.

The GNU compilers currently on Polaris do not support GPU code generation and thus can only be used for compiling CPU codes.

The nvhpc and llvm compilers can be used for compiling GPU-enabled applications.

### Human: What is the purpose of the PrgEnv-gnu module on Polaris?

### Assistant: The purpose of the PrgEnv-gnu module on Polaris is to provide access to the GNU compilers for compiling CPU-enabled applications.
    "
"
### Context: 
GNU Compilers on Polaris

The GNU compilers are available on Polaris via the PrgEnv-gnu and gcc-mixed modules. The gcc-mixed module can be useful when, for example, the PrgEnv-nvhpc compilers are used to compile C/C++ MPI-enabled code and gfortran is needed.

The GNU compilers currently on Polaris do not support GPU code generation and thus can only be used for compiling CPU codes.

The nvhpc and llvm compilers can be used for compiling GPU-enabled applications.

### Human: Which compiler modules are available for compiling CPU codes on Polaris?

### Assistant: The compiler modules available for compiling CPU codes on Polaris are PrgEnv-gnu and gcc-mixed.
    "
"
### Context: 
math_libs/lib64 - cublas, cufft, ...

Differences between nvcc and nvc/nvc++

For users that want to continue using nvcc it is important to be mindful of differences with the newer nvc and nvc++ compilers. For example, the -cuda flag instructs nvcc to compile .cu input files to .cu.cpp.ii output files which are to be separately compiled, whereas the same -cuda flag instructs nvc, nvc++, and nvfortran to enable CUDA C/C++ or CUDA Fortran code generation. The resulting output file in each case is different (text vs. object) and one may see unrecognized format error when -cuda is incorrectly passed to nvcc.

Known Issues and Workarounds

If you are using nvcc to invoke nvc++ and compiling C++17 code, and are seeing the following warning and unable to compile C++17 constructs:

```
polaris-login-01(~)> nvcc --std=c++17 -ccbin nvc++ ~/smalltests/bool_constant.cpp
nvcc warning : The -std=c++17 flag is not supported with the configured host compiler. Flag will be ignored.
""/home/zippy/smalltests/bool_constant.cpp"", line 10: error: namespace ""std"" has no member class ""bool_constant""
      : std::bool_constant<(UnaryPred::value || ...)> {};
             ^

""/home/zippy/smalltests/bool_constant.cpp"", line 10: error: class or struct definition is missing
      : std::bool_constant<(UnaryPred::value || ...)> {};
                          ^

2 errors detected in the compilation of ""/home/zippy/smalltests/bool_constant.cpp"".
polaris-login-01(~)>
```

you will need to work around it by loading the latest cudatoolkit module atop PrgEnv-nvhpc:

module load cudatoolkit-standalone/11.6.2

### Human: What is the difference between nvcc and nvc/nvc++ compilers?

### Assistant: The main difference between nvcc and nvc/nvc++ compilers is how they handle CUDA C/C++ or CUDA Fortran code generation, with nvcc compiling .cu input files to .cu.cpp.ii output files and nvc, nvc++, and nvfortran enabling code generation.
    "
"
### Context: 
math_libs/lib64 - cublas, cufft, ...

Differences between nvcc and nvc/nvc++

For users that want to continue using nvcc it is important to be mindful of differences with the newer nvc and nvc++ compilers. For example, the -cuda flag instructs nvcc to compile .cu input files to .cu.cpp.ii output files which are to be separately compiled, whereas the same -cuda flag instructs nvc, nvc++, and nvfortran to enable CUDA C/C++ or CUDA Fortran code generation. The resulting output file in each case is different (text vs. object) and one may see unrecognized format error when -cuda is incorrectly passed to nvcc.

Known Issues and Workarounds

If you are using nvcc to invoke nvc++ and compiling C++17 code, and are seeing the following warning and unable to compile C++17 constructs:

```
polaris-login-01(~)> nvcc --std=c++17 -ccbin nvc++ ~/smalltests/bool_constant.cpp
nvcc warning : The -std=c++17 flag is not supported with the configured host compiler. Flag will be ignored.
""/home/zippy/smalltests/bool_constant.cpp"", line 10: error: namespace ""std"" has no member class ""bool_constant""
      : std::bool_constant<(UnaryPred::value || ...)> {};
             ^

""/home/zippy/smalltests/bool_constant.cpp"", line 10: error: class or struct definition is missing
      : std::bool_constant<(UnaryPred::value || ...)> {};
                          ^

2 errors detected in the compilation of ""/home/zippy/smalltests/bool_constant.cpp"".
polaris-login-01(~)>
```

you will need to work around it by loading the latest cudatoolkit module atop PrgEnv-nvhpc:

module load cudatoolkit-standalone/11.6.2

### Human: Why would I see an ""unrecognized format error"" when using -cuda with nvcc?

### Assistant: The -cuda flag in nvcc expects .cu input files and produces .cu.cpp.ii output files, whereas in nvc/nvc++, it enables CUDA code generation. If you try to use -cuda with nvcc but provide an incompatible file format, you will see an ""unrecognized format error"".
    "
"
### Context: 
math_libs/lib64 - cublas, cufft, ...

Differences between nvcc and nvc/nvc++

For users that want to continue using nvcc it is important to be mindful of differences with the newer nvc and nvc++ compilers. For example, the -cuda flag instructs nvcc to compile .cu input files to .cu.cpp.ii output files which are to be separately compiled, whereas the same -cuda flag instructs nvc, nvc++, and nvfortran to enable CUDA C/C++ or CUDA Fortran code generation. The resulting output file in each case is different (text vs. object) and one may see unrecognized format error when -cuda is incorrectly passed to nvcc.

Known Issues and Workarounds

If you are using nvcc to invoke nvc++ and compiling C++17 code, and are seeing the following warning and unable to compile C++17 constructs:

```
polaris-login-01(~)> nvcc --std=c++17 -ccbin nvc++ ~/smalltests/bool_constant.cpp
nvcc warning : The -std=c++17 flag is not supported with the configured host compiler. Flag will be ignored.
""/home/zippy/smalltests/bool_constant.cpp"", line 10: error: namespace ""std"" has no member class ""bool_constant""
      : std::bool_constant<(UnaryPred::value || ...)> {};
             ^

""/home/zippy/smalltests/bool_constant.cpp"", line 10: error: class or struct definition is missing
      : std::bool_constant<(UnaryPred::value || ...)> {};
                          ^

2 errors detected in the compilation of ""/home/zippy/smalltests/bool_constant.cpp"".
polaris-login-01(~)>
```

you will need to work around it by loading the latest cudatoolkit module atop PrgEnv-nvhpc:

module load cudatoolkit-standalone/11.6.2

### Human: How can I work around issues with compiling C++17 code using nvcc and nvc++?

### Assistant: Load the latest cudatoolkit module and compile your C++17 code using nvc++ directly.
    "
"
### Context: 
CCE Compilers on Polaris

The Cray Compiling Environment (CCE) compilers are available on Polaris via the PrgEnv-cray module.

The CCE compilers currently on Polaris only support AMD GPU targets for HIP and are thus not usable with the A100 GPUs.

The nvhpc and llvm compilers can be used for compiling GPU-enabled applications.

### Human: What compiler options are available on Polaris?

### Assistant: The available compiler options on Polaris include those provided by the nvhpc and llvm compilers, which can be used for compiling GPU-enabled applications.
    "
"
### Context: 
CCE Compilers on Polaris

The Cray Compiling Environment (CCE) compilers are available on Polaris via the PrgEnv-cray module.

The CCE compilers currently on Polaris only support AMD GPU targets for HIP and are thus not usable with the A100 GPUs.

The nvhpc and llvm compilers can be used for compiling GPU-enabled applications.

### Human: Can I use the CCE compilers to compile applications for A100 GPUs?

### Assistant: No, you cannot use the CCE compilers to compile applications for A100 GPUs.
    "
"
### Context: 
CCE Compilers on Polaris

The Cray Compiling Environment (CCE) compilers are available on Polaris via the PrgEnv-cray module.

The CCE compilers currently on Polaris only support AMD GPU targets for HIP and are thus not usable with the A100 GPUs.

The nvhpc and llvm compilers can be used for compiling GPU-enabled applications.

### Human: What are some alternatives to using the CCE compilers on Polaris?

### Assistant: The alternatives to using the CCE compilers on Polaris are the nvhpc and llvm compilers, which can be used for compiling GPU-enabled applications.
    "
"
### Context: 
oneAPI Compilers and Support

The Intel oneAPI compiler and Codeplay plugins for Nvidia GPUs are available on Polaris.
The oneAPI compilers are not enabled under the Cray Programming Environment system but can be used separately.
Two oneAPI variants are provided, the first being a ""release"" version based on Intel's officially released oneAPI toolkit.
Intel Release Notes

!!! note

Components

These are the list of components associated with this module

User Application Component Compilers DPC++ oneMKL Interfaces oneMKL

The other variant being a build from the open-source. This variant will be more up-to-date at the risk of bugs and breakages based on code that has not undergone a full release cycle.
The documentation is located on the SYCL page. Most notable differences being, icx/icpx are the names of C/C++ compilers respectively when using the release version of the module where as clang/clang++ are for open-source variant.

Compile and Link

oneAPI uses the clang (or icx/icpx wrapper) for compiling and linking for the Nvidia A100 SM80 architecture.

module load oneapi/release
icpx -std=c++17 -fsycl -fsycl-targets=nvptx64-nvidia-cuda -Xsycl-target-backend --cuda-gpu-arch=sm_80 test.cpp

harms@polaris-login-04:~/working/polaris/oneapi> icpx -v
Intel(R) oneAPI DPC++/C++ Compiler 2023.2.0 (2023.2.0.20230721)
Target: x86_64-unknown-linux-gnu
Thread model: posix
InstalledDir: /soft/compilers/oneapi/release/2023.2/compiler/2023.2.1/linux/bin-llvm
Configuration file: /soft/compilers/oneapi/release/2023.2/compiler/2023.2.1/linux/bin-llvm/../bin/icpx.cfg
Found candidate GCC installation: /usr/lib64/gcc/x86_64-suse-linux/7
Selected GCC installation: /usr/lib64/gcc/x86_64-suse-linux/7
Candidate multilib: .;@m64
Selected multilib: .;@m64
Found CUDA installation: /opt/nvidia/hpc_sdk/Linux_x86_64/21.9/cuda/11.4, version 11.4

Running

### Human: What are the two oneAPI variants provided on Polaris?

### Assistant: The two oneAPI variants provided on Polaris are the ""release"" version based on Intel's officially released oneAPI toolkit, and the open-source variant.
    "
"
### Context: 
oneAPI Compilers and Support

The Intel oneAPI compiler and Codeplay plugins for Nvidia GPUs are available on Polaris.
The oneAPI compilers are not enabled under the Cray Programming Environment system but can be used separately.
Two oneAPI variants are provided, the first being a ""release"" version based on Intel's officially released oneAPI toolkit.
Intel Release Notes

!!! note

Components

These are the list of components associated with this module

User Application Component Compilers DPC++ oneMKL Interfaces oneMKL

The other variant being a build from the open-source. This variant will be more up-to-date at the risk of bugs and breakages based on code that has not undergone a full release cycle.
The documentation is located on the SYCL page. Most notable differences being, icx/icpx are the names of C/C++ compilers respectively when using the release version of the module where as clang/clang++ are for open-source variant.

Compile and Link

oneAPI uses the clang (or icx/icpx wrapper) for compiling and linking for the Nvidia A100 SM80 architecture.

module load oneapi/release
icpx -std=c++17 -fsycl -fsycl-targets=nvptx64-nvidia-cuda -Xsycl-target-backend --cuda-gpu-arch=sm_80 test.cpp

harms@polaris-login-04:~/working/polaris/oneapi> icpx -v
Intel(R) oneAPI DPC++/C++ Compiler 2023.2.0 (2023.2.0.20230721)
Target: x86_64-unknown-linux-gnu
Thread model: posix
InstalledDir: /soft/compilers/oneapi/release/2023.2/compiler/2023.2.1/linux/bin-llvm
Configuration file: /soft/compilers/oneapi/release/2023.2/compiler/2023.2.1/linux/bin-llvm/../bin/icpx.cfg
Found candidate GCC installation: /usr/lib64/gcc/x86_64-suse-linux/7
Selected GCC installation: /usr/lib64/gcc/x86_64-suse-linux/7
Candidate multilib: .;@m64
Selected multilib: .;@m64
Found CUDA installation: /opt/nvidia/hpc_sdk/Linux_x86_64/21.9/cuda/11.4, version 11.4

Running

### Human: How do I compile and link C++ code using the Intel Release version of oneAPI on Nvidia A100 SM80 architecture?

### Assistant: icpx -std=c++17 -fsycl -fsycl-targets=nvptx64-nvidia-cuda -Xsycl-target-backend --cuda-gpu-arch=sm_80 test.cpp
    "
"
### Context: 
oneAPI Compilers and Support

The Intel oneAPI compiler and Codeplay plugins for Nvidia GPUs are available on Polaris.
The oneAPI compilers are not enabled under the Cray Programming Environment system but can be used separately.
Two oneAPI variants are provided, the first being a ""release"" version based on Intel's officially released oneAPI toolkit.
Intel Release Notes

!!! note

Components

These are the list of components associated with this module

User Application Component Compilers DPC++ oneMKL Interfaces oneMKL

The other variant being a build from the open-source. This variant will be more up-to-date at the risk of bugs and breakages based on code that has not undergone a full release cycle.
The documentation is located on the SYCL page. Most notable differences being, icx/icpx are the names of C/C++ compilers respectively when using the release version of the module where as clang/clang++ are for open-source variant.

Compile and Link

oneAPI uses the clang (or icx/icpx wrapper) for compiling and linking for the Nvidia A100 SM80 architecture.

module load oneapi/release
icpx -std=c++17 -fsycl -fsycl-targets=nvptx64-nvidia-cuda -Xsycl-target-backend --cuda-gpu-arch=sm_80 test.cpp

harms@polaris-login-04:~/working/polaris/oneapi> icpx -v
Intel(R) oneAPI DPC++/C++ Compiler 2023.2.0 (2023.2.0.20230721)
Target: x86_64-unknown-linux-gnu
Thread model: posix
InstalledDir: /soft/compilers/oneapi/release/2023.2/compiler/2023.2.1/linux/bin-llvm
Configuration file: /soft/compilers/oneapi/release/2023.2/compiler/2023.2.1/linux/bin-llvm/../bin/icpx.cfg
Found candidate GCC installation: /usr/lib64/gcc/x86_64-suse-linux/7
Selected GCC installation: /usr/lib64/gcc/x86_64-suse-linux/7
Candidate multilib: .;@m64
Selected multilib: .;@m64
Found CUDA installation: /opt/nvidia/hpc_sdk/Linux_x86_64/21.9/cuda/11.4, version 11.4

Running

### Human: What is the main difference between the release and open-source variants of the oneAPI compiler?

### Assistant: The main difference between the release and open-source variants of the oneAPI compiler is that the release version is based on Intel's officially released oneAPI toolkit, whereas the open-source variant is built from open-source code. Additionally, icx/icpx is used in the release variant, while clang/clang++ is used in the open-source variant.

Answer: The main difference between the release and open-source variants of the oneAPI compiler is that the release version is based on Intel's officially released oneAPI toolkit, whereas the open-source variant is built from open-source code. Additionally, icx/icpx is used in the release variant, while clang/clang++ is used in the open-source variant.
    "
"
### Context: 
LLVM Compilers on Polaris

This page is not about LLVM-based Cray Compiling Environment (CCE) compilers from PrgEnv-cray but about open source LLVM compilers.

If LLVM compilers are needed without MPI support, simply load the llvm module.

Cray Programming Environment does not offer LLVM compiler support.
Thus cc/CC/ftn compiler wrappers using LLVM compilers currently are not available.
To use Clang with MPI, one can load the mpiwrappers/cray-mpich-llvm module which loads the following modules.

llvm, upstream llvm compilers

cray-mpich, MPI compiler wrappers mpicc/mpicxx/mpif90. mpif90 uses gfortran because flang is not ready for production use.

cray-pals, MPI launchers mpiexec/aprun/mpirun

Limitation There is no GPU-aware MPI library linking support by default. If needed, users should manually add the GTL (GPU Transport Layer) library to the application link line.

Update 04/25/2024 To access LLVM modules, module use /soft/modulefiles is required.

OpenMP offload

When targeting the OpenMP or CUDA programming models for GPUs, the cudatoolkit-standalone module should also be loaded.

### Human: How can I load LLVM compilers without MPI support?

### Assistant: Load the llvm module by running `module load llvm`.
    "
"
### Context: 
LLVM Compilers on Polaris

This page is not about LLVM-based Cray Compiling Environment (CCE) compilers from PrgEnv-cray but about open source LLVM compilers.

If LLVM compilers are needed without MPI support, simply load the llvm module.

Cray Programming Environment does not offer LLVM compiler support.
Thus cc/CC/ftn compiler wrappers using LLVM compilers currently are not available.
To use Clang with MPI, one can load the mpiwrappers/cray-mpich-llvm module which loads the following modules.

llvm, upstream llvm compilers

cray-mpich, MPI compiler wrappers mpicc/mpicxx/mpif90. mpif90 uses gfortran because flang is not ready for production use.

cray-pals, MPI launchers mpiexec/aprun/mpirun

Limitation There is no GPU-aware MPI library linking support by default. If needed, users should manually add the GTL (GPU Transport Layer) library to the application link line.

Update 04/25/2024 To access LLVM modules, module use /soft/modulefiles is required.

OpenMP offload

When targeting the OpenMP or CUDA programming models for GPUs, the cudatoolkit-standalone module should also be loaded.

### Human: Are there LLVM compiler wrappers available for use with CC/CC/ftn?

### Assistant: No
    "
"
### Context: 
LLVM Compilers on Polaris

This page is not about LLVM-based Cray Compiling Environment (CCE) compilers from PrgEnv-cray but about open source LLVM compilers.

If LLVM compilers are needed without MPI support, simply load the llvm module.

Cray Programming Environment does not offer LLVM compiler support.
Thus cc/CC/ftn compiler wrappers using LLVM compilers currently are not available.
To use Clang with MPI, one can load the mpiwrappers/cray-mpich-llvm module which loads the following modules.

llvm, upstream llvm compilers

cray-mpich, MPI compiler wrappers mpicc/mpicxx/mpif90. mpif90 uses gfortran because flang is not ready for production use.

cray-pals, MPI launchers mpiexec/aprun/mpirun

Limitation There is no GPU-aware MPI library linking support by default. If needed, users should manually add the GTL (GPU Transport Layer) library to the application link line.

Update 04/25/2024 To access LLVM modules, module use /soft/modulefiles is required.

OpenMP offload

When targeting the OpenMP or CUDA programming models for GPUs, the cudatoolkit-standalone module should also be loaded.

### Human: What additional step do I need to take if I want to access GPU-aware MPI library linking support?

### Assistant: Manually add the GTL (GPU Transport Layer) library to the application link line.
    "
"
### Context: 
Programming Models on Polaris

The software environment on Polaris supports several parallel programming models targeting the CPUs and GPUs.

CPU Parallel Programming Models

The Cray compiler wrappers cc, CC, and ftn are recommended for MPI applications as they provide the needed include paths and libraries for each programming environment. A summary of available CPU parallel programming models and relevant compiler flags is shown below. Users are encouraged to review the corresponding man pages and documentation.

Programming Model GNU NVHPC LLVM OpenMP -fopenmp -mp -fopenmp OpenACC -- -acc=multicore --

Higher-level programming models such as Kokkos and Raja may also be used for CPU programming.

GPU Programming Models

A summary of available GPU programming models and relevant compiler flags is shown below for compilers that generate offloadable code. Users are encouraged to review the corresponding man pages and documentation.

Programming Model GNU NVHPC LLVM ONEAPI CUDA -- -cuda [-gpu=cuda8.0,cc11.0] -- -- HIP* -- -- -- -- OpenACC -- -acc -- -- OpenCL* -- -- -- -- OpenMP -- -mp=gpu -fopenmp-targets=nvptx64 -- SYCL -- -- -- -fsycl -fsycl-targets=nvptx64-nvidia-cuda -Xsycl-target-backend --cuda-gpu-arch=sm_80

Note, the llvm and oneapi modules are provided by ALCF to complement the compilers provided by the Cray PE on Polaris.

Higher-level programming models such as Kokkos and Raja may also be used for GPU programming.

OpenCL is supported, but does not require specific compiler flags per-se as the offloaded kernels are just-in-time compiled. Abstraction programming models, such as Kokkos, can be built on top of some of these programming models (see below).

A HIP compiler supporting the A100 GPUs is still to be installed on Polaris.

Mapping Programming Models to Polaris Modules

### Human: What CPU parallel programming models are supported on Polaris?

### Assistant: The CPU parallel programming models supported on Polaris are GNU, NVHPC, LLVM, OpenMP, and OpenACC.
    "
"
### Context: 
Programming Models on Polaris

The software environment on Polaris supports several parallel programming models targeting the CPUs and GPUs.

CPU Parallel Programming Models

The Cray compiler wrappers cc, CC, and ftn are recommended for MPI applications as they provide the needed include paths and libraries for each programming environment. A summary of available CPU parallel programming models and relevant compiler flags is shown below. Users are encouraged to review the corresponding man pages and documentation.

Programming Model GNU NVHPC LLVM OpenMP -fopenmp -mp -fopenmp OpenACC -- -acc=multicore --

Higher-level programming models such as Kokkos and Raja may also be used for CPU programming.

GPU Programming Models

A summary of available GPU programming models and relevant compiler flags is shown below for compilers that generate offloadable code. Users are encouraged to review the corresponding man pages and documentation.

Programming Model GNU NVHPC LLVM ONEAPI CUDA -- -cuda [-gpu=cuda8.0,cc11.0] -- -- HIP* -- -- -- -- OpenACC -- -acc -- -- OpenCL* -- -- -- -- OpenMP -- -mp=gpu -fopenmp-targets=nvptx64 -- SYCL -- -- -- -fsycl -fsycl-targets=nvptx64-nvidia-cuda -Xsycl-target-backend --cuda-gpu-arch=sm_80

Note, the llvm and oneapi modules are provided by ALCF to complement the compilers provided by the Cray PE on Polaris.

Higher-level programming models such as Kokkos and Raja may also be used for GPU programming.

OpenCL is supported, but does not require specific compiler flags per-se as the offloaded kernels are just-in-time compiled. Abstraction programming models, such as Kokkos, can be built on top of some of these programming models (see below).

A HIP compiler supporting the A100 GPUs is still to be installed on Polaris.

Mapping Programming Models to Polaris Modules

### Human: Which GPU programming models require specific compiler flags on Polaris?

### Assistant: CUDA, OpenACC, and SYCL.
    "
"
### Context: 
Programming Models on Polaris

The software environment on Polaris supports several parallel programming models targeting the CPUs and GPUs.

CPU Parallel Programming Models

The Cray compiler wrappers cc, CC, and ftn are recommended for MPI applications as they provide the needed include paths and libraries for each programming environment. A summary of available CPU parallel programming models and relevant compiler flags is shown below. Users are encouraged to review the corresponding man pages and documentation.

Programming Model GNU NVHPC LLVM OpenMP -fopenmp -mp -fopenmp OpenACC -- -acc=multicore --

Higher-level programming models such as Kokkos and Raja may also be used for CPU programming.

GPU Programming Models

A summary of available GPU programming models and relevant compiler flags is shown below for compilers that generate offloadable code. Users are encouraged to review the corresponding man pages and documentation.

Programming Model GNU NVHPC LLVM ONEAPI CUDA -- -cuda [-gpu=cuda8.0,cc11.0] -- -- HIP* -- -- -- -- OpenACC -- -acc -- -- OpenCL* -- -- -- -- OpenMP -- -mp=gpu -fopenmp-targets=nvptx64 -- SYCL -- -- -- -fsycl -fsycl-targets=nvptx64-nvidia-cuda -Xsycl-target-backend --cuda-gpu-arch=sm_80

Note, the llvm and oneapi modules are provided by ALCF to complement the compilers provided by the Cray PE on Polaris.

Higher-level programming models such as Kokkos and Raja may also be used for GPU programming.

OpenCL is supported, but does not require specific compiler flags per-se as the offloaded kernels are just-in-time compiled. Abstraction programming models, such as Kokkos, can be built on top of some of these programming models (see below).

A HIP compiler supporting the A100 GPUs is still to be installed on Polaris.

Mapping Programming Models to Polaris Modules

### Human: Are there any abstraction programming models that can be built on top of the programming models supported on Polaris?

### Assistant: Yes, Kokkos can be built on top of some of the programming models supported on Polaris.
    "
"
### Context: 
Mapping Programming Models to Polaris Modules

The table below offers some suggestions for how to get started setting up your environment on Polaris depending on the programming language and model. Note, mixed C/C++ and Fortran applications should choose the programming environment for the Fortran compiler because of mpi.mod and similar incompatibilities between Fortran-generated files from different compilers. Several simple examples for testing the software environment on Polaris for different programming models are available in the ALCF GettingStart repo.

Note, users are encouraged to use PrgEnv-nvhpc instead of PrgEnv-nvidia as the latter will soon be deprecated in Cray's PE. They are otherwise identical pointing to compilers from the same NVIDIA SDK version.

Programming Language GPU Programming Model Likely used Modules/Compilers Notes C/C++ CUDA PrgEnv-nvhpc, PrgEnv-gnu, llvm NVIDIA (nvcc, nvc, nvc++) and clang compilers do GPU code generation C/C++ HIP N/A need to install with support for A100 C/C++ Kokkos See CUDA HIP, OpenMP, and SYCL/DPC++ also candidates C/C++ OpenACC PrgEnv-nvhpc C/C++ OpenCL PrgEnv-nvhpc, PrgEnv-gnu, llvm JIT GPU code generation C/C++ OpenMP PrgEnv-nvhpc, llvm C/C++ RAJA See CUDA HIP, OpenMP, and SYCL/DPC++ also candidates C/C++ SYCL/DPC++ llvm-sycl  Fortran CUDA PrgEnv-nvhpc NVIDIA compiler (nvfortran) does GPU code generation; gfortran can be loaded via gcc-mixed Fortran HIP N/A need to install with support for A100 Fortran OpenACC PrgEnv-nvhpc Fortran OpenCL PrgEnv-nvhpc, PrgEnv-gnu JIT GPU code generation Fortran OpenMP PrgEnv-nvhpc

### Human: What programming environments should I use for C/C++ applications on Polaris?

### Assistant: Use PrgEnv-nvhpc or PrgEnv-gnu for C/C++ applications on Polaris.
    "
"
### Context: 
Mapping Programming Models to Polaris Modules

The table below offers some suggestions for how to get started setting up your environment on Polaris depending on the programming language and model. Note, mixed C/C++ and Fortran applications should choose the programming environment for the Fortran compiler because of mpi.mod and similar incompatibilities between Fortran-generated files from different compilers. Several simple examples for testing the software environment on Polaris for different programming models are available in the ALCF GettingStart repo.

Note, users are encouraged to use PrgEnv-nvhpc instead of PrgEnv-nvidia as the latter will soon be deprecated in Cray's PE. They are otherwise identical pointing to compilers from the same NVIDIA SDK version.

Programming Language GPU Programming Model Likely used Modules/Compilers Notes C/C++ CUDA PrgEnv-nvhpc, PrgEnv-gnu, llvm NVIDIA (nvcc, nvc, nvc++) and clang compilers do GPU code generation C/C++ HIP N/A need to install with support for A100 C/C++ Kokkos See CUDA HIP, OpenMP, and SYCL/DPC++ also candidates C/C++ OpenACC PrgEnv-nvhpc C/C++ OpenCL PrgEnv-nvhpc, PrgEnv-gnu, llvm JIT GPU code generation C/C++ OpenMP PrgEnv-nvhpc, llvm C/C++ RAJA See CUDA HIP, OpenMP, and SYCL/DPC++ also candidates C/C++ SYCL/DPC++ llvm-sycl  Fortran CUDA PrgEnv-nvhpc NVIDIA compiler (nvfortran) does GPU code generation; gfortran can be loaded via gcc-mixed Fortran HIP N/A need to install with support for A100 Fortran OpenACC PrgEnv-nvhpc Fortran OpenCL PrgEnv-nvhpc, PrgEnv-gnu JIT GPU code generation Fortran OpenMP PrgEnv-nvhpc

### Human: Which compiler is recommended for Fortran-based CUDA applications on Polaris?

### Assistant: The recommended compiler for Fortran-based CUDA applications on Polaris is PrgEnv-nvhpc with nvfortran.
    "
"
### Context: 
Mapping Programming Models to Polaris Modules

The table below offers some suggestions for how to get started setting up your environment on Polaris depending on the programming language and model. Note, mixed C/C++ and Fortran applications should choose the programming environment for the Fortran compiler because of mpi.mod and similar incompatibilities between Fortran-generated files from different compilers. Several simple examples for testing the software environment on Polaris for different programming models are available in the ALCF GettingStart repo.

Note, users are encouraged to use PrgEnv-nvhpc instead of PrgEnv-nvidia as the latter will soon be deprecated in Cray's PE. They are otherwise identical pointing to compilers from the same NVIDIA SDK version.

Programming Language GPU Programming Model Likely used Modules/Compilers Notes C/C++ CUDA PrgEnv-nvhpc, PrgEnv-gnu, llvm NVIDIA (nvcc, nvc, nvc++) and clang compilers do GPU code generation C/C++ HIP N/A need to install with support for A100 C/C++ Kokkos See CUDA HIP, OpenMP, and SYCL/DPC++ also candidates C/C++ OpenACC PrgEnv-nvhpc C/C++ OpenCL PrgEnv-nvhpc, PrgEnv-gnu, llvm JIT GPU code generation C/C++ OpenMP PrgEnv-nvhpc, llvm C/C++ RAJA See CUDA HIP, OpenMP, and SYCL/DPC++ also candidates C/C++ SYCL/DPC++ llvm-sycl  Fortran CUDA PrgEnv-nvhpc NVIDIA compiler (nvfortran) does GPU code generation; gfortran can be loaded via gcc-mixed Fortran HIP N/A need to install with support for A100 Fortran OpenACC PrgEnv-nvhpc Fortran OpenCL PrgEnv-nvhpc, PrgEnv-gnu JIT GPU code generation Fortran OpenMP PrgEnv-nvhpc

### Human: Can you provide examples of testing software environment on Polaris for different programming models?

### Assistant: The software environment on Polaris for different programming models can be tested by identifying the programming language and model, determining the likely used modules/compilers, and testing with examples from the ALCF GettingStart repo.
    "
"
### Context: 
libEnsemble

libEnsemble is a Python toolkit for running dynamic ensembles of calculations.

Users provide generator and simulator functions to express their ensembles, where the generator can steer the ensemble based on previous results. These functions can portably submit external executables at any scale.

System details are detected, and dynamic resource management is provided. This includes automatically detecting, assigning, and reassigning
GPUs for ensemble members.

libEnsemble can be used in a consistent manner on laptops, clusters, and supercomputers with minimal required dependencies.

Getting libEnsemble on Polaris

libEnsemble is provided on Polaris in the conda module:

See the docs for more details on using python on Polaris.

libEnsemble examples

For a very simple example of using libEnsemble see the Simple Introduction tutorial

For an example that runs a small ensemble using a C application (offloading work to the GPU), see
the GPU app tutorial.
The required files for this tutorial can be found
in this directory.
A video demo is also available.

Job Submission

libEnsemble runs on the compute nodes on Polaris using either Python's
multiprocessing or mpi4py. The user can set the number of workers for
maximum concurrency. libEnsemble will detect the nodes available
from the PBS environment and use these for running simulations. Polaris supports
running multiple concurrent simulations on each node if desired.

A simple example batch script for a libEnsemble use case that runs five workers on one node:

```shell
    #!/bin/bash -l
    #PBS -l select=1:system=polaris
    #PBS -l walltime=00:15:00
    #PBS -l filesystems=home:grand
    #PBS -q debug
    #PBS -A

```

The script can be run with:

Or you can run an interactive session with:

Further links

Docs:

https://libensemble.readthedocs.io

GitHub:

https://github.com/Libensemble/libensemble

### Human: How does libEnsemble facilitate running dynamic ensembles of calculations?

### Assistant: libEnsemble facilitates running dynamic ensembles of calculations by providing a framework for users to define their own generator and simulator functions, which can steer the ensemble based on previous results, while automatically detecting and assigning resources such as GPUs for ensemble members.
    "
"
### Context: 
libEnsemble

libEnsemble is a Python toolkit for running dynamic ensembles of calculations.

Users provide generator and simulator functions to express their ensembles, where the generator can steer the ensemble based on previous results. These functions can portably submit external executables at any scale.

System details are detected, and dynamic resource management is provided. This includes automatically detecting, assigning, and reassigning
GPUs for ensemble members.

libEnsemble can be used in a consistent manner on laptops, clusters, and supercomputers with minimal required dependencies.

Getting libEnsemble on Polaris

libEnsemble is provided on Polaris in the conda module:

See the docs for more details on using python on Polaris.

libEnsemble examples

For a very simple example of using libEnsemble see the Simple Introduction tutorial

For an example that runs a small ensemble using a C application (offloading work to the GPU), see
the GPU app tutorial.
The required files for this tutorial can be found
in this directory.
A video demo is also available.

Job Submission

libEnsemble runs on the compute nodes on Polaris using either Python's
multiprocessing or mpi4py. The user can set the number of workers for
maximum concurrency. libEnsemble will detect the nodes available
from the PBS environment and use these for running simulations. Polaris supports
running multiple concurrent simulations on each node if desired.

A simple example batch script for a libEnsemble use case that runs five workers on one node:

```shell
    #!/bin/bash -l
    #PBS -l select=1:system=polaris
    #PBS -l walltime=00:15:00
    #PBS -l filesystems=home:grand
    #PBS -q debug
    #PBS -A

```

The script can be run with:

Or you can run an interactive session with:

Further links

Docs:

https://libensemble.readthedocs.io

GitHub:

https://github.com/Libensemble/libensemble

### Human: What is the role of generator and simulator functions in expressing ensembles with libEnsemble?

### Assistant: The generator function steers the ensemble based on previous results, while the simulator function runs the simulations for each member of the ensemble.
    "
"
### Context: 
libEnsemble

libEnsemble is a Python toolkit for running dynamic ensembles of calculations.

Users provide generator and simulator functions to express their ensembles, where the generator can steer the ensemble based on previous results. These functions can portably submit external executables at any scale.

System details are detected, and dynamic resource management is provided. This includes automatically detecting, assigning, and reassigning
GPUs for ensemble members.

libEnsemble can be used in a consistent manner on laptops, clusters, and supercomputers with minimal required dependencies.

Getting libEnsemble on Polaris

libEnsemble is provided on Polaris in the conda module:

See the docs for more details on using python on Polaris.

libEnsemble examples

For a very simple example of using libEnsemble see the Simple Introduction tutorial

For an example that runs a small ensemble using a C application (offloading work to the GPU), see
the GPU app tutorial.
The required files for this tutorial can be found
in this directory.
A video demo is also available.

Job Submission

libEnsemble runs on the compute nodes on Polaris using either Python's
multiprocessing or mpi4py. The user can set the number of workers for
maximum concurrency. libEnsemble will detect the nodes available
from the PBS environment and use these for running simulations. Polaris supports
running multiple concurrent simulations on each node if desired.

A simple example batch script for a libEnsemble use case that runs five workers on one node:

```shell
    #!/bin/bash -l
    #PBS -l select=1:system=polaris
    #PBS -l walltime=00:15:00
    #PBS -l filesystems=home:grand
    #PBS -q debug
    #PBS -A

```

The script can be run with:

Or you can run an interactive session with:

Further links

Docs:

https://libensemble.readthedocs.io

GitHub:

https://github.com/Libensemble/libensemble

### Human: Can I run multiple concurrent simulations on each node with libEnsemble, and how do I set up such a job submission?

### Assistant: Yes, you can run multiple concurrent simulations on each node with libEnsemble by setting the number of workers in your job submission script.
    "
"
### Context: 
SmartSim and SmartRedis

SmartSim is an open source tool developed by the Hewlett Packard Enterprise (HPE) designed to facilitate the integration of traditional HPC simulation applications with machine learning workflows.
There are two core components to SmartSim:

Infrastructure library (IL)
Provides API to start, stop and monitor HPC applications from Python
Interfaces with the scheduler launch jobs (PBSPro on Polaris and Cobalt on Theta/ThetaGPU)
Deploys a distributed in-memory database called the Orchestrator

SmartRedis client library
Provides clients that connect to the Orchestrator from Fortran, C, C++, Python code
The client API library enables data transfer to/from database and ability to load and run JIT-traced Python and ML runtimes acting on stored data

For more resources on SmartSim, follow the links below:

Source code

Documentation

Zoo of examples

Fall 2023 ALCF User Hands-On Workshop

NekRS-ML

Installation

SmartSim on Polaris can be installed creating a virtual environment based on the ML conda module
module load conda/2023-10-04
conda activate
module load cmake
module load gcc/11.2.0
module load cudatoolkit-standalone/11.8.0
python -m venv --clear /path/to/_ssim_env --system-site-packages
source /path/to/_ssim_env/bin/activate
pip install --upgrade pip
Note that /path/to/ can either be a user's home or project directory.

To use SmartSim in the future, simply load the same modules and source the virtual environment.

### Human: How does the SmartRedis client library facilitate data transfer between code and the Orchestrator database?

### Assistant: The SmartRedis client library facilitates data transfer between code and the Orchestrator database by providing clients that connect to the Orchestrator from various programming languages.
    "
"
### Context: 
SmartSim and SmartRedis

SmartSim is an open source tool developed by the Hewlett Packard Enterprise (HPE) designed to facilitate the integration of traditional HPC simulation applications with machine learning workflows.
There are two core components to SmartSim:

Infrastructure library (IL)
Provides API to start, stop and monitor HPC applications from Python
Interfaces with the scheduler launch jobs (PBSPro on Polaris and Cobalt on Theta/ThetaGPU)
Deploys a distributed in-memory database called the Orchestrator

SmartRedis client library
Provides clients that connect to the Orchestrator from Fortran, C, C++, Python code
The client API library enables data transfer to/from database and ability to load and run JIT-traced Python and ML runtimes acting on stored data

For more resources on SmartSim, follow the links below:

Source code

Documentation

Zoo of examples

Fall 2023 ALCF User Hands-On Workshop

NekRS-ML

Installation

SmartSim on Polaris can be installed creating a virtual environment based on the ML conda module
module load conda/2023-10-04
conda activate
module load cmake
module load gcc/11.2.0
module load cudatoolkit-standalone/11.8.0
python -m venv --clear /path/to/_ssim_env --system-site-packages
source /path/to/_ssim_env/bin/activate
pip install --upgrade pip
Note that /path/to/ can either be a user's home or project directory.

To use SmartSim in the future, simply load the same modules and source the virtual environment.

### Human: What steps are required to install SmartSim on Polaris for use with ML conda modules?

### Assistant: Install SmartSim on Polaris by loading necessary modules, creating a virtual environment, activating the virtual environment, upgrading pip, and then installing SmartSim.
    "
"
### Context: 
To use SmartSim in the future, simply load the same modules and source the virtual environment.

Then set up the environment variables
export SMARTSIM_REDISAI=1.2.7
export CC=cc
export CXX=CC
export CUDA_DEPS_BASE=/soft/libraries
export CUDA_VERSION_MAJOR=11
export CUDNN_VERSION_MAJOR=8
export CUDNN_VERSION_MINOR=6
export CUDNN_VERSION_EXTRA=0.163
export CUDNN_VERSION=$CUDNN_VERSION_MAJOR.$CUDNN_VERSION_MINOR.$CUDNN_VERSION_EXTRA
export CUDNN_BASE=$CUDA_DEPS_BASE/cudnn/cudnn-$CUDA_VERSION_MAJOR-linux-x64-v$CUDNN_VERSION
export CUDNN_LIBRARY=$CUDNN_BASE/lib/
export CUDNN_INCLUDE_DIR=$CUDNN_BASE/include/
export LD_LIBRARY_PATH=$CUDNN_LIBRARY:$LD_LIBRARY_PATH

Now, install SmartSim and the GPU backend
git clone https://github.com/CrayLabs/SmartSim.git
cd SmartSim
pip install -e .
export TORCH_PATH=$( python -c 'import torch;print(torch.utils.cmake_prefix_path)' )
export TF_PATH=$( python -c 'import tensorflow;print(""/"".join(tensorflow.__file__.split(""/"")[:-1]))' )
smart build -v --device gpu --torch_dir $TORCH_PATH --libtensorflow_dir $TF_PATH
cd ..

Finally, install the SmartRedis library
export LDFLAGS=-L/opt/cray/pe/gcc/11.2.0/snos/lib64/libstdc++.so.6
git clone https://github.com/CrayLabs/SmartRedis.git
cd SmartRedis
pip install -e .
make lib
cd ..

Examples

You can find examples of in situ training and inference of ML models from an ongoing CFD simulation at the NekRs-ML repository. 
The smartredis and onlineGNN branches have instructions on how to build and run the examples on Polaris.

The Fall 2023 ALCF User Hands-On Workshop repository also contains information on how to use SmartSim and NekRS-ML on Polaris, but note the instructions are specfic to the Fall of 2023.

Notes

### Human: How do I set up the environment variables for SmartSim?

### Assistant: The environment variables for SmartSim are set by exporting SMARTSIM_REDISAI=1.2.7, CC=cc, CXX=CC, CUDA_DEPS_BASE=/soft/libraries, and the various CUDA and CUDNN version-related variables.
    "
"
### Context: 
To use SmartSim in the future, simply load the same modules and source the virtual environment.

Then set up the environment variables
export SMARTSIM_REDISAI=1.2.7
export CC=cc
export CXX=CC
export CUDA_DEPS_BASE=/soft/libraries
export CUDA_VERSION_MAJOR=11
export CUDNN_VERSION_MAJOR=8
export CUDNN_VERSION_MINOR=6
export CUDNN_VERSION_EXTRA=0.163
export CUDNN_VERSION=$CUDNN_VERSION_MAJOR.$CUDNN_VERSION_MINOR.$CUDNN_VERSION_EXTRA
export CUDNN_BASE=$CUDA_DEPS_BASE/cudnn/cudnn-$CUDA_VERSION_MAJOR-linux-x64-v$CUDNN_VERSION
export CUDNN_LIBRARY=$CUDNN_BASE/lib/
export CUDNN_INCLUDE_DIR=$CUDNN_BASE/include/
export LD_LIBRARY_PATH=$CUDNN_LIBRARY:$LD_LIBRARY_PATH

Now, install SmartSim and the GPU backend
git clone https://github.com/CrayLabs/SmartSim.git
cd SmartSim
pip install -e .
export TORCH_PATH=$( python -c 'import torch;print(torch.utils.cmake_prefix_path)' )
export TF_PATH=$( python -c 'import tensorflow;print(""/"".join(tensorflow.__file__.split(""/"")[:-1]))' )
smart build -v --device gpu --torch_dir $TORCH_PATH --libtensorflow_dir $TF_PATH
cd ..

Finally, install the SmartRedis library
export LDFLAGS=-L/opt/cray/pe/gcc/11.2.0/snos/lib64/libstdc++.so.6
git clone https://github.com/CrayLabs/SmartRedis.git
cd SmartRedis
pip install -e .
make lib
cd ..

Examples

You can find examples of in situ training and inference of ML models from an ongoing CFD simulation at the NekRs-ML repository. 
The smartredis and onlineGNN branches have instructions on how to build and run the examples on Polaris.

The Fall 2023 ALCF User Hands-On Workshop repository also contains information on how to use SmartSim and NekRS-ML on Polaris, but note the instructions are specfic to the Fall of 2023.

Notes

### Human: What is required to build and run examples with SmartSim on Polaris?

### Assistant: To build and run examples with SmartSim on Polaris, load modules, set environment variables, install SmartSim and the GPU backend, install the SmartRedis library, and refer to example repositories.
    "
"
### Context: 
Notes

SmartSim workflows, such as online training, often require launching multiple MPI applications on the same set of nodes. On Polaris, the MPICH_OFI_CXI_PID_BASE=0 must be exported before the first call to mpiexec, and then incremented by 1 and re-exported before each successive call. This is done with the SmartSim API by adding env_vars={'MPICH_OFI_CXI_PID_BASE':str(0)} to the PalsMpiexecSettings() API.

### Human: What is the purpose of exporting MPICH_OFI_CXI_PID_BASE in SmartSim workflows?

### Assistant: The purpose of exporting MPICH_OFI_CXI_PID_BASE in SmartSim workflows is to enable proper communication between multiple MPI applications by keeping track of the process ID base for each application.
    "
"
### Context: 
Notes

SmartSim workflows, such as online training, often require launching multiple MPI applications on the same set of nodes. On Polaris, the MPICH_OFI_CXI_PID_BASE=0 must be exported before the first call to mpiexec, and then incremented by 1 and re-exported before each successive call. This is done with the SmartSim API by adding env_vars={'MPICH_OFI_CXI_PID_BASE':str(0)} to the PalsMpiexecSettings() API.

### Human: How do I increment MPICH_OFI_CXI_PID_BASE before each successive call to mpiexec in Polaris?

### Assistant: Increment MPICH_OFI_CXI_PID_BASE by adding env_vars={'MPICH_OFI_CXI_PID_BASE':str(current_value + 1)} to the PalsMpiexecSettings() API.
    "
"
### Context: 
Notes

SmartSim workflows, such as online training, often require launching multiple MPI applications on the same set of nodes. On Polaris, the MPICH_OFI_CXI_PID_BASE=0 must be exported before the first call to mpiexec, and then incremented by 1 and re-exported before each successive call. This is done with the SmartSim API by adding env_vars={'MPICH_OFI_CXI_PID_BASE':str(0)} to the PalsMpiexecSettings() API.

### Human: Which API should I use to set environment variables for PalsMpiexecSettings in SmartSim?

### Assistant: PalsMpiexecSettings()
    "
"
### Context: 
Balsam

Balsam is a Python-based workflow manager that helps users execute large numbers of jobs, potentially with interjob dependencies, track job outcomes, and manage postprocessing analysis. A Balsam Site runs on a node with access to the job scheduler, where it can submit and monitor jobs. Overall job state is aggregated on the Balsam Server, making job data from all Sites accessible from any individual site (or the user's laptop), via the command-line interface or the Python API. To get information on how to use the command line tool, you can type balsam --help in your shell.

Full documentation for Balsam is available online.

Balsam requires Python 3.7+. To install Balsam on Polaris, first set up a virtual Python environment:

shell
module load conda
conda activate base
python -m venv env
source env/bin/activate
pip install --upgrade pip
pip install --pre balsam

To use Balsam, users need an account on the Balsam server.  Users can get an account by contacting the ALCF Help Desk.  Once a user has an account, they can login and make a new site.  A Balsam site is a project space for your workflow. You will be prompted to select what machine (Polaris) you are working on when creating a new site:

shell
balsam login
balsam site init -n new-site new-site
cd new-site
balsam site start

See the Balsam documentation for full details.

### Human: How do I get started with using Balsam?

### Assistant: To get started with using Balsam, install it on Polaris by setting up a virtual Python environment, obtain an account on the Balsam server, create a new site, and start the site.
    "
"
### Context: 
Balsam

Balsam is a Python-based workflow manager that helps users execute large numbers of jobs, potentially with interjob dependencies, track job outcomes, and manage postprocessing analysis. A Balsam Site runs on a node with access to the job scheduler, where it can submit and monitor jobs. Overall job state is aggregated on the Balsam Server, making job data from all Sites accessible from any individual site (or the user's laptop), via the command-line interface or the Python API. To get information on how to use the command line tool, you can type balsam --help in your shell.

Full documentation for Balsam is available online.

Balsam requires Python 3.7+. To install Balsam on Polaris, first set up a virtual Python environment:

shell
module load conda
conda activate base
python -m venv env
source env/bin/activate
pip install --upgrade pip
pip install --pre balsam

To use Balsam, users need an account on the Balsam server.  Users can get an account by contacting the ALCF Help Desk.  Once a user has an account, they can login and make a new site.  A Balsam site is a project space for your workflow. You will be prompted to select what machine (Polaris) you are working on when creating a new site:

shell
balsam login
balsam site init -n new-site new-site
cd new-site
balsam site start

See the Balsam documentation for full details.

### Human: What are the system requirements to install Balsam on Polaris?

### Assistant: To install Balsam on Polaris, you need to set up a virtual Python environment by loading conda, activating the base environment, creating a new environment, activating it, upgrading pip, and installing Balsam.
    "
"
### Context: 
Balsam

Balsam is a Python-based workflow manager that helps users execute large numbers of jobs, potentially with interjob dependencies, track job outcomes, and manage postprocessing analysis. A Balsam Site runs on a node with access to the job scheduler, where it can submit and monitor jobs. Overall job state is aggregated on the Balsam Server, making job data from all Sites accessible from any individual site (or the user's laptop), via the command-line interface or the Python API. To get information on how to use the command line tool, you can type balsam --help in your shell.

Full documentation for Balsam is available online.

Balsam requires Python 3.7+. To install Balsam on Polaris, first set up a virtual Python environment:

shell
module load conda
conda activate base
python -m venv env
source env/bin/activate
pip install --upgrade pip
pip install --pre balsam

To use Balsam, users need an account on the Balsam server.  Users can get an account by contacting the ALCF Help Desk.  Once a user has an account, they can login and make a new site.  A Balsam site is a project space for your workflow. You will be prompted to select what machine (Polaris) you are working on when creating a new site:

shell
balsam login
balsam site init -n new-site new-site
cd new-site
balsam site start

See the Balsam documentation for full details.

### Human: How can I create a new site in Balsam?

### Assistant: Create a new site in Balsam by logging in, initializing the site, changing into the directory, and starting the site.
    "
"
### Context: 
Parsl on Polaris

Parsl is a flexible and scalable parallel programming library for Python.

-- Parsl Documentation

For many applications, managing an ensemble of jobs into a workflow is a critical step that can easily become a performance bottleneck.  Many tools exist to address this, of which parsl is just one.  On this page, we'll highlight some of the key pieces of information about parsl that are relevant to Polaris.  Parsl is also extensively documented, has a dedicated Slack Channel, and a large community of users and developers beyond ALCF.  We encourage you to engage with the parsl community for support with parsl specific questions, and for Polaris-specific questions or problems, please contact support@alcf.anl.gov.

Getting Parsl on Polaris

You can install parsl building off of the conda modules.  You have some flexibility in how you want to extend the conda module to include parsl, but here is an example way to do it:

```python

Load the Conda Module (needed everytime you use parsl)

module load conda
conda activate

Create a virtual env that uses the conda env as the system packages.

Only do the next line on initial set up:

python -m venv --system-site-packages /path/to/your/virtualenv

Load the virtual env (every time):

source /path/to/your/virtualenv/bin/activate

Install parsl (only once)

pip install parsl

```

Using Parsl on Polaris

Parsl has a variety of possible configuration settings.  As an example, we provide the configuration below that will run one task per GPU:

```python
from parsl.config import Config

PBSPro is the right provider for Polaris:

from parsl.providers import PBSProProvider

The high throughput executor is for scaling to HPC systems:

from parsl.executors import HighThroughputExecutor

You can use the MPI launcher, but may want the Gnu Parallel launcher, see below

from parsl.launchers import MpiExecLauncher, GnuParallelLauncher

address_by_interface is needed for the HighThroughputExecutor:

### Human: How do I install Parsl on Polaris?

### Assistant: Install Parsl on Polaris by loading the Conda Module, activating the Conda environment, creating a virtual environment, loading the virtual environment, and installing Parsl.
    "
"
### Context: 
Parsl on Polaris

Parsl is a flexible and scalable parallel programming library for Python.

-- Parsl Documentation

For many applications, managing an ensemble of jobs into a workflow is a critical step that can easily become a performance bottleneck.  Many tools exist to address this, of which parsl is just one.  On this page, we'll highlight some of the key pieces of information about parsl that are relevant to Polaris.  Parsl is also extensively documented, has a dedicated Slack Channel, and a large community of users and developers beyond ALCF.  We encourage you to engage with the parsl community for support with parsl specific questions, and for Polaris-specific questions or problems, please contact support@alcf.anl.gov.

Getting Parsl on Polaris

You can install parsl building off of the conda modules.  You have some flexibility in how you want to extend the conda module to include parsl, but here is an example way to do it:

```python

Load the Conda Module (needed everytime you use parsl)

module load conda
conda activate

Create a virtual env that uses the conda env as the system packages.

Only do the next line on initial set up:

python -m venv --system-site-packages /path/to/your/virtualenv

Load the virtual env (every time):

source /path/to/your/virtualenv/bin/activate

Install parsl (only once)

pip install parsl

```

Using Parsl on Polaris

Parsl has a variety of possible configuration settings.  As an example, we provide the configuration below that will run one task per GPU:

```python
from parsl.config import Config

PBSPro is the right provider for Polaris:

from parsl.providers import PBSProProvider

The high throughput executor is for scaling to HPC systems:

from parsl.executors import HighThroughputExecutor

You can use the MPI launcher, but may want the Gnu Parallel launcher, see below

from parsl.launchers import MpiExecLauncher, GnuParallelLauncher

address_by_interface is needed for the HighThroughputExecutor:

### Human: What configuration settings are available in Parsl for Polaris?

### Assistant: PBSPro provider, high-throughput executor, and Gnu Parallel launcher.
    "
"
### Context: 
Parsl on Polaris

Parsl is a flexible and scalable parallel programming library for Python.

-- Parsl Documentation

For many applications, managing an ensemble of jobs into a workflow is a critical step that can easily become a performance bottleneck.  Many tools exist to address this, of which parsl is just one.  On this page, we'll highlight some of the key pieces of information about parsl that are relevant to Polaris.  Parsl is also extensively documented, has a dedicated Slack Channel, and a large community of users and developers beyond ALCF.  We encourage you to engage with the parsl community for support with parsl specific questions, and for Polaris-specific questions or problems, please contact support@alcf.anl.gov.

Getting Parsl on Polaris

You can install parsl building off of the conda modules.  You have some flexibility in how you want to extend the conda module to include parsl, but here is an example way to do it:

```python

Load the Conda Module (needed everytime you use parsl)

module load conda
conda activate

Create a virtual env that uses the conda env as the system packages.

Only do the next line on initial set up:

python -m venv --system-site-packages /path/to/your/virtualenv

Load the virtual env (every time):

source /path/to/your/virtualenv/bin/activate

Install parsl (only once)

pip install parsl

```

Using Parsl on Polaris

Parsl has a variety of possible configuration settings.  As an example, we provide the configuration below that will run one task per GPU:

```python
from parsl.config import Config

PBSPro is the right provider for Polaris:

from parsl.providers import PBSProProvider

The high throughput executor is for scaling to HPC systems:

from parsl.executors import HighThroughputExecutor

You can use the MPI launcher, but may want the Gnu Parallel launcher, see below

from parsl.launchers import MpiExecLauncher, GnuParallelLauncher

address_by_interface is needed for the HighThroughputExecutor:

### Human: Can I use MPI launcher with Parsl on Polaris?

### Assistant: Yes, you can use the MPI launcher with Parsl on Polaris.
    "
"
### Context: 
address_by_interface is needed for the HighThroughputExecutor:

from parsl.addresses import address_by_interface

For checkpointing:

from parsl.utils import get_all_checkpoints

Adjust your user-specific options here:

run_dir=""/lus/grand/projects/yourproject/yourrundir/""

user_opts = {
    ""worker_init"":      f""source /path/to/your/virtualenv/bin/activate; cd {run_dir}"", # load the environment where parsl is installed
    ""scheduler_options"":""#PBS -l filesystems=home:eagle:grand"" , # specify any PBS options here, like filesystems
    ""account"":          ""YOURPROJECT"",
    ""queue"":            ""debug-scaling"",
    ""walltime"":         ""1:00:00"",
    ""nodes_per_block"":  3, # think of a block as one job on polaris, so to run on the main queues, set this >= 10
    ""cpus_per_node"":    32, # Up to 64 with multithreading
    ""available_accelerators"": 4, # Each Polaris node has 4 GPUs, setting this ensures one worker per GPU
    ""cores_per_worker"": 8, # this will set the number of cpu hardware threads per worker.

checkpoints = get_all_checkpoints(run_dir)
print(""Found the following checkpoints: "", checkpoints)

### Human: What is needed for the HighThroughputExecutor in Parsl?

### Assistant: address_by_interface.
    "
"
### Context: 
address_by_interface is needed for the HighThroughputExecutor:

from parsl.addresses import address_by_interface

For checkpointing:

from parsl.utils import get_all_checkpoints

Adjust your user-specific options here:

run_dir=""/lus/grand/projects/yourproject/yourrundir/""

user_opts = {
    ""worker_init"":      f""source /path/to/your/virtualenv/bin/activate; cd {run_dir}"", # load the environment where parsl is installed
    ""scheduler_options"":""#PBS -l filesystems=home:eagle:grand"" , # specify any PBS options here, like filesystems
    ""account"":          ""YOURPROJECT"",
    ""queue"":            ""debug-scaling"",
    ""walltime"":         ""1:00:00"",
    ""nodes_per_block"":  3, # think of a block as one job on polaris, so to run on the main queues, set this >= 10
    ""cpus_per_node"":    32, # Up to 64 with multithreading
    ""available_accelerators"": 4, # Each Polaris node has 4 GPUs, setting this ensures one worker per GPU
    ""cores_per_worker"": 8, # this will set the number of cpu hardware threads per worker.

checkpoints = get_all_checkpoints(run_dir)
print(""Found the following checkpoints: "", checkpoints)

### Human: How can one adjust user-specific options in Parsl?

### Assistant: Adjust user-specific options by modifying the values assigned to each key in the `user_opts` dictionary.
    "
"
### Context: 
address_by_interface is needed for the HighThroughputExecutor:

from parsl.addresses import address_by_interface

For checkpointing:

from parsl.utils import get_all_checkpoints

Adjust your user-specific options here:

run_dir=""/lus/grand/projects/yourproject/yourrundir/""

user_opts = {
    ""worker_init"":      f""source /path/to/your/virtualenv/bin/activate; cd {run_dir}"", # load the environment where parsl is installed
    ""scheduler_options"":""#PBS -l filesystems=home:eagle:grand"" , # specify any PBS options here, like filesystems
    ""account"":          ""YOURPROJECT"",
    ""queue"":            ""debug-scaling"",
    ""walltime"":         ""1:00:00"",
    ""nodes_per_block"":  3, # think of a block as one job on polaris, so to run on the main queues, set this >= 10
    ""cpus_per_node"":    32, # Up to 64 with multithreading
    ""available_accelerators"": 4, # Each Polaris node has 4 GPUs, setting this ensures one worker per GPU
    ""cores_per_worker"": 8, # this will set the number of cpu hardware threads per worker.

checkpoints = get_all_checkpoints(run_dir)
print(""Found the following checkpoints: "", checkpoints)

### Human: What is the purpose of get_all_checkpoints in Parsl?

### Assistant: The purpose of get_all_checkpoints in Parsl is to retrieve all checkpoint files in a given directory, allowing for checkpointing and management.
    "
"
### Context: 
config = Config(
        executors=[
            HighThroughputExecutor(
                label=""htex"",
                heartbeat_period=15,
                heartbeat_threshold=120,
                worker_debug=True,
                available_accelerators=user_opts[""available_accelerators""], # if this is set, it will override other settings for max_workers if set
                cores_per_worker=user_opts[""cores_per_worker""],
                address=address_by_interface(""bond0""),
                cpu_affinity=""block-reverse"",
                prefetch_capacity=0,
                start_method=""spawn"",  # Needed to avoid interactions between MPI and os.fork
                provider=PBSProProvider(
                    launcher=MpiExecLauncher(bind_cmd=""--cpu-bind"", overrides=""--depth=64 --ppn 1""),
                    # Which launcher to use?  Check out the note below for some details.  Try MPI first!
                    # launcher=GnuParallelLauncher(),
                    account=user_opts[""account""],
                    queue=user_opts[""queue""],
                    select_options=""ngpus=4"",
                    # PBS directives (header lines): for array jobs pass '-J' option
                    scheduler_options=user_opts[""scheduler_options""],
                    # Command to be run before starting a worker, such as:
                    worker_init=user_opts[""worker_init""],
                    # number of compute nodes allocated for each block
                    nodes_per_block=user_opts[""nodes_per_block""],
                    init_blocks=1,
                    min_blocks=0,
                    max_blocks=1, # Can increase more to have more parallel jobs
                    cpus_per_node=user_opts[""cpus_per_node""],
                    walltime=user_opts[""walltime""]
                ),
            ),
        ],
        checkpoint_files = checkpoints,
        run_dir=run_dir,
        checkpoint_mode = 'task_exit',
        retries=2,
        app_cache=True,
)

```

### Human: How many cores does each worker use?

### Assistant: $user_opts[""cores_per_worker""]
    "
"
### Context: 
config = Config(
        executors=[
            HighThroughputExecutor(
                label=""htex"",
                heartbeat_period=15,
                heartbeat_threshold=120,
                worker_debug=True,
                available_accelerators=user_opts[""available_accelerators""], # if this is set, it will override other settings for max_workers if set
                cores_per_worker=user_opts[""cores_per_worker""],
                address=address_by_interface(""bond0""),
                cpu_affinity=""block-reverse"",
                prefetch_capacity=0,
                start_method=""spawn"",  # Needed to avoid interactions between MPI and os.fork
                provider=PBSProProvider(
                    launcher=MpiExecLauncher(bind_cmd=""--cpu-bind"", overrides=""--depth=64 --ppn 1""),
                    # Which launcher to use?  Check out the note below for some details.  Try MPI first!
                    # launcher=GnuParallelLauncher(),
                    account=user_opts[""account""],
                    queue=user_opts[""queue""],
                    select_options=""ngpus=4"",
                    # PBS directives (header lines): for array jobs pass '-J' option
                    scheduler_options=user_opts[""scheduler_options""],
                    # Command to be run before starting a worker, such as:
                    worker_init=user_opts[""worker_init""],
                    # number of compute nodes allocated for each block
                    nodes_per_block=user_opts[""nodes_per_block""],
                    init_blocks=1,
                    min_blocks=0,
                    max_blocks=1, # Can increase more to have more parallel jobs
                    cpus_per_node=user_opts[""cpus_per_node""],
                    walltime=user_opts[""walltime""]
                ),
            ),
        ],
        checkpoint_files = checkpoints,
        run_dir=run_dir,
        checkpoint_mode = 'task_exit',
        retries=2,
        app_cache=True,
)

```

### Human: What is the default scheduler option used by PBSProProvider?

### Assistant: The default scheduler option used by PBSProProvider is not explicitly defined and instead relies on the value of `user_opts[""scheduler_options""]`.
    "
"
### Context: 
config = Config(
        executors=[
            HighThroughputExecutor(
                label=""htex"",
                heartbeat_period=15,
                heartbeat_threshold=120,
                worker_debug=True,
                available_accelerators=user_opts[""available_accelerators""], # if this is set, it will override other settings for max_workers if set
                cores_per_worker=user_opts[""cores_per_worker""],
                address=address_by_interface(""bond0""),
                cpu_affinity=""block-reverse"",
                prefetch_capacity=0,
                start_method=""spawn"",  # Needed to avoid interactions between MPI and os.fork
                provider=PBSProProvider(
                    launcher=MpiExecLauncher(bind_cmd=""--cpu-bind"", overrides=""--depth=64 --ppn 1""),
                    # Which launcher to use?  Check out the note below for some details.  Try MPI first!
                    # launcher=GnuParallelLauncher(),
                    account=user_opts[""account""],
                    queue=user_opts[""queue""],
                    select_options=""ngpus=4"",
                    # PBS directives (header lines): for array jobs pass '-J' option
                    scheduler_options=user_opts[""scheduler_options""],
                    # Command to be run before starting a worker, such as:
                    worker_init=user_opts[""worker_init""],
                    # number of compute nodes allocated for each block
                    nodes_per_block=user_opts[""nodes_per_block""],
                    init_blocks=1,
                    min_blocks=0,
                    max_blocks=1, # Can increase more to have more parallel jobs
                    cpus_per_node=user_opts[""cpus_per_node""],
                    walltime=user_opts[""walltime""]
                ),
            ),
        ],
        checkpoint_files = checkpoints,
        run_dir=run_dir,
        checkpoint_mode = 'task_exit',
        retries=2,
        app_cache=True,
)

```

### Human: What is the maximum number of blocks that can be run in parallel?

### Assistant: The maximum number of blocks that can be run in parallel is currently 1, but it can be increased.
    "
"
### Context: 
```

Special notes for Polaris

On Polaris, there is a known bug where python applications launched with mpi and that use fork to spawn processes can sometimes have unexplaned hangs.  For this reason, it is recommended to use start_method=""spawn"" on Polaris when using the MpiExecLauncher as is shown in the example config above.  Alternatively, another solution is to use the GNUParallelLauncher which uses GNU Parallel to spawn processes.  GNU Parallel can be loaded in your environment with the command module load gnu-parallel.  Both of these approaches will circumvent the hang issue from using fork.

Updates

For parsl versions after July 2023, the address passed in the HighThroughputExecutor needs to be set to address = address_by_interface(""bond0"").  With parsl versions prior to July 2023, it was recommended to use address = address_by_hostname() on Polaris, but with later versions this will not work on Polaris (or any other machine).

### Human: What is the recommended start method for python applications on Polaris?

### Assistant: start_method=""spawn""
    "
"
### Context: 
```

Special notes for Polaris

On Polaris, there is a known bug where python applications launched with mpi and that use fork to spawn processes can sometimes have unexplaned hangs.  For this reason, it is recommended to use start_method=""spawn"" on Polaris when using the MpiExecLauncher as is shown in the example config above.  Alternatively, another solution is to use the GNUParallelLauncher which uses GNU Parallel to spawn processes.  GNU Parallel can be loaded in your environment with the command module load gnu-parallel.  Both of these approaches will circumvent the hang issue from using fork.

Updates

For parsl versions after July 2023, the address passed in the HighThroughputExecutor needs to be set to address = address_by_interface(""bond0"").  With parsl versions prior to July 2023, it was recommended to use address = address_by_hostname() on Polaris, but with later versions this will not work on Polaris (or any other machine).

### Human: Why can python applications launched with mpi and fork have unexplained hangs on Polaris?

### Assistant: Python applications launched with MPI and fork can have unexplained hangs on Polaris due to a known bug, which can be circumvented by using `start_method=""spawn""` or the GNUParallelLauncher.
    "
"
### Context: 
```

Special notes for Polaris

On Polaris, there is a known bug where python applications launched with mpi and that use fork to spawn processes can sometimes have unexplaned hangs.  For this reason, it is recommended to use start_method=""spawn"" on Polaris when using the MpiExecLauncher as is shown in the example config above.  Alternatively, another solution is to use the GNUParallelLauncher which uses GNU Parallel to spawn processes.  GNU Parallel can be loaded in your environment with the command module load gnu-parallel.  Both of these approaches will circumvent the hang issue from using fork.

Updates

For parsl versions after July 2023, the address passed in the HighThroughputExecutor needs to be set to address = address_by_interface(""bond0"").  With parsl versions prior to July 2023, it was recommended to use address = address_by_hostname() on Polaris, but with later versions this will not work on Polaris (or any other machine).

### Human: How can one avoid the hang issue when using fork to spawn processes on Polaris?

### Assistant: Use start_method=""spawn"" or GNUParallelLauncher.
    "
"
### Context: 
Multi-Instance GPU (MIG) mode

MIG mode can be enabled and configured on Polaris by passing a valid configuration file to qsub:

qsub ... -l mig_config=/home/ME/path/to/mig_config.json ...

You can find a concise explanation of MIG concepts and terms at https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#concepts

Configuration

Please study the following example of a valid configuration file:

shell
{
  ""group1"": {
    ""gpus"": [0,1],
    ""mig_enabled"": true,
    ""instances"": {""7g.40gb"": [""4c.7g.40gb"", ""3c.7g.40gb""] }
  },
  ""group2"": {
    ""gpus"": [2,3],
    ""mig_enabled"": true,
    ""instances"": {""3g.20gb"": [""2c.3g.20gb"", ""1c.3g.20gb""], ""2g.10gb"": [""2g.10gb""], ""1g.5gb"": [""1g.5gb""], ""1g.5gb"": [""1g.5gb""]}
  }
}

Notes

Group names are arbitrary, but must be unique

""gpus"" must be an array of integers.  if only one physical gpu is being configured in a group, it must still be contained within an array(ex. ""gpus"": [0],)

Only groups with mig_enabled set to true will be configured

instances denote the MIG gpu instances and the nested compute instances you wish to be configured

syntax is {""gpu instance 1"": [""cpu instance 1"", ""cpu instance 2""], ...}

valid gpu instances are 1g.5gb, 1g.10gb, 2g.10gb, 3g.20gb, 4g.20gb, and 7g.40gb.  the first number denotes the number of slots used out of 7 total, and the second number denotes memory in GB

the default cpu instance for any gpu instance has the same identifier as the gpu instance(in which case it will be the only one configurable)

other cpu instances can be configured with the identifier syntax Xc.Y, where X is the number of slots available in that gpu instance, and Y is the gpu instance identifier string

some gpu instances cannot be configured adjacently, despite there being sufficient slots/memory remaining(ex. 3g.20gb and 4g.20gb). Please see NVIDIA MIG documentation for further details

### Human: How do I enable MIG mode on Polaris?

### Assistant: To enable MIG mode on Polaris, pass a valid configuration file to qsub using the command `qsub ... -l mig_config=/home/ME/path/to/mig_config.json ...`.
    "
"
### Context: 
Multi-Instance GPU (MIG) mode

MIG mode can be enabled and configured on Polaris by passing a valid configuration file to qsub:

qsub ... -l mig_config=/home/ME/path/to/mig_config.json ...

You can find a concise explanation of MIG concepts and terms at https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#concepts

Configuration

Please study the following example of a valid configuration file:

shell
{
  ""group1"": {
    ""gpus"": [0,1],
    ""mig_enabled"": true,
    ""instances"": {""7g.40gb"": [""4c.7g.40gb"", ""3c.7g.40gb""] }
  },
  ""group2"": {
    ""gpus"": [2,3],
    ""mig_enabled"": true,
    ""instances"": {""3g.20gb"": [""2c.3g.20gb"", ""1c.3g.20gb""], ""2g.10gb"": [""2g.10gb""], ""1g.5gb"": [""1g.5gb""], ""1g.5gb"": [""1g.5gb""]}
  }
}

Notes

Group names are arbitrary, but must be unique

""gpus"" must be an array of integers.  if only one physical gpu is being configured in a group, it must still be contained within an array(ex. ""gpus"": [0],)

Only groups with mig_enabled set to true will be configured

instances denote the MIG gpu instances and the nested compute instances you wish to be configured

syntax is {""gpu instance 1"": [""cpu instance 1"", ""cpu instance 2""], ...}

valid gpu instances are 1g.5gb, 1g.10gb, 2g.10gb, 3g.20gb, 4g.20gb, and 7g.40gb.  the first number denotes the number of slots used out of 7 total, and the second number denotes memory in GB

the default cpu instance for any gpu instance has the same identifier as the gpu instance(in which case it will be the only one configurable)

other cpu instances can be configured with the identifier syntax Xc.Y, where X is the number of slots available in that gpu instance, and Y is the gpu instance identifier string

some gpu instances cannot be configured adjacently, despite there being sufficient slots/memory remaining(ex. 3g.20gb and 4g.20gb). Please see NVIDIA MIG documentation for further details

### Human: What is the syntax for configuring MIG instances in a configuration file?

### Assistant: The syntax for configuring MIG instances in a configuration file is a JSON object with group definitions, where each group contains an array of GPUs and their corresponding MIG-enabled instances.
    "
"
### Context: 
Multi-Instance GPU (MIG) mode

MIG mode can be enabled and configured on Polaris by passing a valid configuration file to qsub:

qsub ... -l mig_config=/home/ME/path/to/mig_config.json ...

You can find a concise explanation of MIG concepts and terms at https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#concepts

Configuration

Please study the following example of a valid configuration file:

shell
{
  ""group1"": {
    ""gpus"": [0,1],
    ""mig_enabled"": true,
    ""instances"": {""7g.40gb"": [""4c.7g.40gb"", ""3c.7g.40gb""] }
  },
  ""group2"": {
    ""gpus"": [2,3],
    ""mig_enabled"": true,
    ""instances"": {""3g.20gb"": [""2c.3g.20gb"", ""1c.3g.20gb""], ""2g.10gb"": [""2g.10gb""], ""1g.5gb"": [""1g.5gb""], ""1g.5gb"": [""1g.5gb""]}
  }
}

Notes

Group names are arbitrary, but must be unique

""gpus"" must be an array of integers.  if only one physical gpu is being configured in a group, it must still be contained within an array(ex. ""gpus"": [0],)

Only groups with mig_enabled set to true will be configured

instances denote the MIG gpu instances and the nested compute instances you wish to be configured

syntax is {""gpu instance 1"": [""cpu instance 1"", ""cpu instance 2""], ...}

valid gpu instances are 1g.5gb, 1g.10gb, 2g.10gb, 3g.20gb, 4g.20gb, and 7g.40gb.  the first number denotes the number of slots used out of 7 total, and the second number denotes memory in GB

the default cpu instance for any gpu instance has the same identifier as the gpu instance(in which case it will be the only one configurable)

other cpu instances can be configured with the identifier syntax Xc.Y, where X is the number of slots available in that gpu instance, and Y is the gpu instance identifier string

some gpu instances cannot be configured adjacently, despite there being sufficient slots/memory remaining(ex. 3g.20gb and 4g.20gb). Please see NVIDIA MIG documentation for further details

### Human: Are there any restrictions on which MIG gpu instances can be configured together?

### Assistant: There are restrictions on which MIG GPU instances can be configured together, specifically some GPU instances cannot be configured adjacently, although the exact combinations of restricted instances are not explicitly listed.
    "
"
### Context: 
Currently, MIG configuration is only available in the debug, debug-scaling, and preemptable queues.  submissions to other queues will result in any MIG config files passed being silently ignored

Files which do not match the above syntax will be silently rejected, and any invalid configurations in properly formatted files will be silently ignored. Please test any changes to your configuration in an interactive job session before use

A basic validator script is available at /soft/pbs/mig_conf_validate.sh. It will check for simple errors in your config, and print the expected configuration. For example:

```shell
ascovel@polaris-login-02:~> /soft/pbs/mig_conf_validate.sh -h
usage: mig_conf_validate.sh -c CONFIG_FILE
ascovel@polaris-login-02:~> /soft/pbs/mig_conf_validate.sh -c ./polaris-mig/mig_config.json
expected MIG configuration:
GPU     GPU_INST   COMPUTE_INST

0       7g.40gb    4c.7g.40gb
0       7g.40gb    3c.7g.40gb
1       7g.40gb    4c.7g.40gb
1       7g.40gb    3c.7g.40gb
2       2g.10gb    2g.10gb
2       4g.20gb    2c.4g.20gb
2       4g.20gb    2c.4g.20gb
3       2g.10gb    2g.10gb
3       4g.20gb    2c.4g.20gb
3       4g.20gb    2c.4g.20gb
ascovel@polaris-login-02:~>
```

Example use of MIG compute instances

The following example demonstrates the use of MIG compute instances via the CUDA_VISIBLE_DEVICES environment variable:

```shell
ascovel@polaris-login-02:~/polaris-mig> qsub -l mig_config=/home/ascovel/polaris-mig/mig_config.json -l select=1 -l walltime=60:00 -l filesystems=home:grand:swift -A Operations -q R639752 -k doe -I
qsub: waiting for job 640002.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov to start
qsub: job 640002.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov ready

### Human: What types of queues support MIG configuration in PBS?

### Assistant: Debug, debug-scaling, and preemptable
    "
"
### Context: 
Currently, MIG configuration is only available in the debug, debug-scaling, and preemptable queues.  submissions to other queues will result in any MIG config files passed being silently ignored

Files which do not match the above syntax will be silently rejected, and any invalid configurations in properly formatted files will be silently ignored. Please test any changes to your configuration in an interactive job session before use

A basic validator script is available at /soft/pbs/mig_conf_validate.sh. It will check for simple errors in your config, and print the expected configuration. For example:

```shell
ascovel@polaris-login-02:~> /soft/pbs/mig_conf_validate.sh -h
usage: mig_conf_validate.sh -c CONFIG_FILE
ascovel@polaris-login-02:~> /soft/pbs/mig_conf_validate.sh -c ./polaris-mig/mig_config.json
expected MIG configuration:
GPU     GPU_INST   COMPUTE_INST

0       7g.40gb    4c.7g.40gb
0       7g.40gb    3c.7g.40gb
1       7g.40gb    4c.7g.40gb
1       7g.40gb    3c.7g.40gb
2       2g.10gb    2g.10gb
2       4g.20gb    2c.4g.20gb
2       4g.20gb    2c.4g.20gb
3       2g.10gb    2g.10gb
3       4g.20gb    2c.4g.20gb
3       4g.20gb    2c.4g.20gb
ascovel@polaris-login-02:~>
```

Example use of MIG compute instances

The following example demonstrates the use of MIG compute instances via the CUDA_VISIBLE_DEVICES environment variable:

```shell
ascovel@polaris-login-02:~/polaris-mig> qsub -l mig_config=/home/ascovel/polaris-mig/mig_config.json -l select=1 -l walltime=60:00 -l filesystems=home:grand:swift -A Operations -q R639752 -k doe -I
qsub: waiting for job 640002.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov to start
qsub: job 640002.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov ready

### Human: What happens to submissions made to queues other than the ones supporting MIG config files?

### Assistant: Submissions made to queues other than the ones supporting MIG config files (debug, debug-scaling, and preemptable queues) will result in any MIG config files passed being silently ignored.
    "
"
### Context: 
Currently, MIG configuration is only available in the debug, debug-scaling, and preemptable queues.  submissions to other queues will result in any MIG config files passed being silently ignored

Files which do not match the above syntax will be silently rejected, and any invalid configurations in properly formatted files will be silently ignored. Please test any changes to your configuration in an interactive job session before use

A basic validator script is available at /soft/pbs/mig_conf_validate.sh. It will check for simple errors in your config, and print the expected configuration. For example:

```shell
ascovel@polaris-login-02:~> /soft/pbs/mig_conf_validate.sh -h
usage: mig_conf_validate.sh -c CONFIG_FILE
ascovel@polaris-login-02:~> /soft/pbs/mig_conf_validate.sh -c ./polaris-mig/mig_config.json
expected MIG configuration:
GPU     GPU_INST   COMPUTE_INST

0       7g.40gb    4c.7g.40gb
0       7g.40gb    3c.7g.40gb
1       7g.40gb    4c.7g.40gb
1       7g.40gb    3c.7g.40gb
2       2g.10gb    2g.10gb
2       4g.20gb    2c.4g.20gb
2       4g.20gb    2c.4g.20gb
3       2g.10gb    2g.10gb
3       4g.20gb    2c.4g.20gb
3       4g.20gb    2c.4g.20gb
ascovel@polaris-login-02:~>
```

Example use of MIG compute instances

The following example demonstrates the use of MIG compute instances via the CUDA_VISIBLE_DEVICES environment variable:

```shell
ascovel@polaris-login-02:~/polaris-mig> qsub -l mig_config=/home/ascovel/polaris-mig/mig_config.json -l select=1 -l walltime=60:00 -l filesystems=home:grand:swift -A Operations -q R639752 -k doe -I
qsub: waiting for job 640002.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov to start
qsub: job 640002.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov ready

### Human: How can you test any changes to your MIG configuration before use?

### Assistant: Test changes by validating the config file with `mig_conf_validate.sh` and then testing it in an interactive job session.
    "
"
### Context: 
ascovel@x3209c0s19b0n0:~> cat ./polaris-mig/mig_config.json
{
  ""group1"": {
    ""gpus"": [0,1],
    ""mig_enabled"": true,
    ""instances"": {""7g.40gb"": [""4c.7g.40gb"", ""3c.7g.40gb""] }
  },
  ""group2"": {
    ""gpus"": [2,3],
    ""mig_enabled"": true,
    ""instances"": {""4g.20gb"": [""2c.4g.20gb"", ""2c.4g.20gb""], ""2g.10gb"": [""2g.10gb""] }
  }
}
ascovel@x3209c0s19b0n0:~> nvidia-smi -L | grep -Po -e ""MIG[0-9a-f-]+""
MIG-63aa1884-acb8-5880-a586-173f6506966c
MIG-b86283ae-9953-514f-81df-99be7e0553a5
MIG-79065f64-bdbb-53ff-89e3-9d35f270b208
MIG-6dd56a9d-e362-567e-95b1-108afbcfc674
MIG-76459138-79df-5d00-a11f-b0a2a747bd9e
MIG-4d5c9fb3-b0e3-50e8-a60c-233104222611
MIG-bdfeeb2d-7a50-5e39-b3c5-767838a0b7a3
MIG-87a2c2f3-d008-51be-b64b-6adb56deb679
MIG-3d4cdd8c-fc36-5ce9-9676-a6e46d4a6c86
MIG-773e8e18-f62a-5250-af1e-9343c9286ce1
ascovel@x3209c0s19b0n0:~> for mig in $( nvidia-smi -L | grep -Po -e ""MIG[0-9a-f-]+"" ) ; do CUDA_VISIBLE_DEVICES=${mig} ./saxpy & done 2>/dev/null
ascovel@x3209c0s19b0n0:~> nvidia-smi | tail -n 16
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0    0    0      17480      C   ./saxpy                          8413MiB |
|    0    0    1      17481      C   ./saxpy                          8363MiB |
|    1    0    0      17482      C   ./saxpy                          8413MiB |
|    1    0    1      17483      C   ./saxpy                          8363MiB |
|    2    1    0      17484      C   ./saxpy                          8313MiB |
|    2    1    1      17485      C   ./saxpy                          8313MiB |
|    2    5    0      17486      C   ./saxpy                          8313MiB |

### Human: What is Multi-Instance GPU (MIG)?

### Assistant: Multi-Instance GPU (MIG) is a configuration that allows multiple instances of GPU memory to be allocated from a single physical GPU, with 2 instances in group1 and 3 instances in group2.
    "
"
### Context: 
ascovel@x3209c0s19b0n0:~> cat ./polaris-mig/mig_config.json
{
  ""group1"": {
    ""gpus"": [0,1],
    ""mig_enabled"": true,
    ""instances"": {""7g.40gb"": [""4c.7g.40gb"", ""3c.7g.40gb""] }
  },
  ""group2"": {
    ""gpus"": [2,3],
    ""mig_enabled"": true,
    ""instances"": {""4g.20gb"": [""2c.4g.20gb"", ""2c.4g.20gb""], ""2g.10gb"": [""2g.10gb""] }
  }
}
ascovel@x3209c0s19b0n0:~> nvidia-smi -L | grep -Po -e ""MIG[0-9a-f-]+""
MIG-63aa1884-acb8-5880-a586-173f6506966c
MIG-b86283ae-9953-514f-81df-99be7e0553a5
MIG-79065f64-bdbb-53ff-89e3-9d35f270b208
MIG-6dd56a9d-e362-567e-95b1-108afbcfc674
MIG-76459138-79df-5d00-a11f-b0a2a747bd9e
MIG-4d5c9fb3-b0e3-50e8-a60c-233104222611
MIG-bdfeeb2d-7a50-5e39-b3c5-767838a0b7a3
MIG-87a2c2f3-d008-51be-b64b-6adb56deb679
MIG-3d4cdd8c-fc36-5ce9-9676-a6e46d4a6c86
MIG-773e8e18-f62a-5250-af1e-9343c9286ce1
ascovel@x3209c0s19b0n0:~> for mig in $( nvidia-smi -L | grep -Po -e ""MIG[0-9a-f-]+"" ) ; do CUDA_VISIBLE_DEVICES=${mig} ./saxpy & done 2>/dev/null
ascovel@x3209c0s19b0n0:~> nvidia-smi | tail -n 16
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0    0    0      17480      C   ./saxpy                          8413MiB |
|    0    0    1      17481      C   ./saxpy                          8363MiB |
|    1    0    0      17482      C   ./saxpy                          8413MiB |
|    1    0    1      17483      C   ./saxpy                          8363MiB |
|    2    1    0      17484      C   ./saxpy                          8313MiB |
|    2    1    1      17485      C   ./saxpy                          8313MiB |
|    2    5    0      17486      C   ./saxpy                          8313MiB |

### Human: How do you enable MIG on a specific group of GPUs?

### Assistant: To enable MIG on a specific group of GPUs, set the CUDA_VISIBLE_DEVICES environment variable to the MIG ID of the first GPU in that group.
    "
"
### Context: 
ascovel@x3209c0s19b0n0:~> cat ./polaris-mig/mig_config.json
{
  ""group1"": {
    ""gpus"": [0,1],
    ""mig_enabled"": true,
    ""instances"": {""7g.40gb"": [""4c.7g.40gb"", ""3c.7g.40gb""] }
  },
  ""group2"": {
    ""gpus"": [2,3],
    ""mig_enabled"": true,
    ""instances"": {""4g.20gb"": [""2c.4g.20gb"", ""2c.4g.20gb""], ""2g.10gb"": [""2g.10gb""] }
  }
}
ascovel@x3209c0s19b0n0:~> nvidia-smi -L | grep -Po -e ""MIG[0-9a-f-]+""
MIG-63aa1884-acb8-5880-a586-173f6506966c
MIG-b86283ae-9953-514f-81df-99be7e0553a5
MIG-79065f64-bdbb-53ff-89e3-9d35f270b208
MIG-6dd56a9d-e362-567e-95b1-108afbcfc674
MIG-76459138-79df-5d00-a11f-b0a2a747bd9e
MIG-4d5c9fb3-b0e3-50e8-a60c-233104222611
MIG-bdfeeb2d-7a50-5e39-b3c5-767838a0b7a3
MIG-87a2c2f3-d008-51be-b64b-6adb56deb679
MIG-3d4cdd8c-fc36-5ce9-9676-a6e46d4a6c86
MIG-773e8e18-f62a-5250-af1e-9343c9286ce1
ascovel@x3209c0s19b0n0:~> for mig in $( nvidia-smi -L | grep -Po -e ""MIG[0-9a-f-]+"" ) ; do CUDA_VISIBLE_DEVICES=${mig} ./saxpy & done 2>/dev/null
ascovel@x3209c0s19b0n0:~> nvidia-smi | tail -n 16
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0    0    0      17480      C   ./saxpy                          8413MiB |
|    0    0    1      17481      C   ./saxpy                          8363MiB |
|    1    0    0      17482      C   ./saxpy                          8413MiB |
|    1    0    1      17483      C   ./saxpy                          8363MiB |
|    2    1    0      17484      C   ./saxpy                          8313MiB |
|    2    1    1      17485      C   ./saxpy                          8313MiB |
|    2    5    0      17486      C   ./saxpy                          8313MiB |

### Human: Can you provide an example of how to utilize MIG instances for concurrent processing?

### Assistant: The final answer is that you can utilize MIG instances for concurrent processing by setting the `CUDA_VISIBLE_DEVICES` environment variable to specify which MIG instance to use for each process.
    "
"
### Context: 
|    2    5    0      17486      C   ./saxpy                          8313MiB |
|    3    1    0      17487      C   ./saxpy                          8313MiB |
|    3    1    1      17488      C   ./saxpy                          8313MiB |
|    3    5    0      17489      C   ./saxpy                          8313MiB |
+-----------------------------------------------------------------------------+
ascovel@x3209c0s19b0n0:~>
```

### Human: What is the purpose of the Saxpy command?

### Assistant: Saxpy command is used for optimizing or analyzing memory usage on the system.
    "
"
### Context: 
|    2    5    0      17486      C   ./saxpy                          8313MiB |
|    3    1    0      17487      C   ./saxpy                          8313MiB |
|    3    1    1      17488      C   ./saxpy                          8313MiB |
|    3    5    0      17489      C   ./saxpy                          8313MiB |
+-----------------------------------------------------------------------------+
ascovel@x3209c0s19b0n0:~>
```

### Human: How many MiB does the .saxpy command use?

### Assistant: 83MiB
    "
"
### Context: 
|    2    5    0      17486      C   ./saxpy                          8313MiB |
|    3    1    0      17487      C   ./saxpy                          8313MiB |
|    3    1    1      17488      C   ./saxpy                          8313MiB |
|    3    5    0      17489      C   ./saxpy                          8313MiB |
+-----------------------------------------------------------------------------+
ascovel@x3209c0s19b0n0:~>
```

### Human: Can I run multiple instances of the Saxpy command simultaneously?

### Assistant: Yes, you can run multiple instances of the Saxpy command simultaneously.
    "
"
### Context: 
Julia

Julia is a high-level, high-performance dynamic programming language for
technical computing. It has a syntax familiar to users of many other
technical computing environments. Designed at MIT to tackle large-scale
partial-differential equation simulation and distributed linear algebra, Julia
features a robust ecosystem of tools for
optimization,
statistics, parallel programming, and data
visualization. Julia is actively developed by the Julia
Labs team at MIT and in
industry, along with hundreds of domain-expert
scientists and programmers worldwide.

Contributing

This guide is a first draft of the Julia documentation for Polaris. If you have any
suggestions or contributions, please open a pull request or contact us by
opening a ticket at the ALCF Helpdesk.

Julia Installation

We encourage users interested in using Julia on Polaris to install in their home or project directories at this time. Using the official Julia 1.9 binaries from the Julia
webpage is recommended.
Juliaup provides a convenient way to
install Julia and manage the various Julia versions. The default installation will install julia, juliaup, and other commands in a ${HOME}/.julia directory and update profile files like .bashrc to update PATH to include that directory. One can customize the installation to change these defaults.

bash
module load craype-accel-nvidia80
curl -fsSL https://install.julialang.org | sh

If you chose a custom installation, then be sure to update the PATH environment variable appropriately.

export PATH=${HOME}/.juliaup/bin:${PATH}

You may then list the available Julia versions with juliaup list and install a
specific version with juliaup install <version>. You can then activate a
specific version with juliaup use <version> and set the default version with
juliaup default <version>. juliaup update will update the installed Julia
versions. In general, the latest stable release of Julia should be used.

bash
juliaup add release

Julia Project Environment

### Human: What programming language is used for large-scale partial-differential equation simulation and distributed linear algebra?

### Assistant: Julia
    "
"
### Context: 
Julia

Julia is a high-level, high-performance dynamic programming language for
technical computing. It has a syntax familiar to users of many other
technical computing environments. Designed at MIT to tackle large-scale
partial-differential equation simulation and distributed linear algebra, Julia
features a robust ecosystem of tools for
optimization,
statistics, parallel programming, and data
visualization. Julia is actively developed by the Julia
Labs team at MIT and in
industry, along with hundreds of domain-expert
scientists and programmers worldwide.

Contributing

This guide is a first draft of the Julia documentation for Polaris. If you have any
suggestions or contributions, please open a pull request or contact us by
opening a ticket at the ALCF Helpdesk.

Julia Installation

We encourage users interested in using Julia on Polaris to install in their home or project directories at this time. Using the official Julia 1.9 binaries from the Julia
webpage is recommended.
Juliaup provides a convenient way to
install Julia and manage the various Julia versions. The default installation will install julia, juliaup, and other commands in a ${HOME}/.julia directory and update profile files like .bashrc to update PATH to include that directory. One can customize the installation to change these defaults.

bash
module load craype-accel-nvidia80
curl -fsSL https://install.julialang.org | sh

If you chose a custom installation, then be sure to update the PATH environment variable appropriately.

export PATH=${HOME}/.juliaup/bin:${PATH}

You may then list the available Julia versions with juliaup list and install a
specific version with juliaup install <version>. You can then activate a
specific version with juliaup use <version> and set the default version with
juliaup default <version>. juliaup update will update the installed Julia
versions. In general, the latest stable release of Julia should be used.

bash
juliaup add release

Julia Project Environment

### Human: How can I install Julia and manage different Julia versions using a convenient method called Juliaup?

### Assistant: Install Julia using `curl -fsSL https://install.julialang.org | sh`, then manage different Julia versions using `juliaup list`, `juliaup install <version>`, `juliaup use <version>`, `juliaup default <version>`, and `juliaup update`.
    "
"
### Context: 
Julia

Julia is a high-level, high-performance dynamic programming language for
technical computing. It has a syntax familiar to users of many other
technical computing environments. Designed at MIT to tackle large-scale
partial-differential equation simulation and distributed linear algebra, Julia
features a robust ecosystem of tools for
optimization,
statistics, parallel programming, and data
visualization. Julia is actively developed by the Julia
Labs team at MIT and in
industry, along with hundreds of domain-expert
scientists and programmers worldwide.

Contributing

This guide is a first draft of the Julia documentation for Polaris. If you have any
suggestions or contributions, please open a pull request or contact us by
opening a ticket at the ALCF Helpdesk.

Julia Installation

We encourage users interested in using Julia on Polaris to install in their home or project directories at this time. Using the official Julia 1.9 binaries from the Julia
webpage is recommended.
Juliaup provides a convenient way to
install Julia and manage the various Julia versions. The default installation will install julia, juliaup, and other commands in a ${HOME}/.julia directory and update profile files like .bashrc to update PATH to include that directory. One can customize the installation to change these defaults.

bash
module load craype-accel-nvidia80
curl -fsSL https://install.julialang.org | sh

If you chose a custom installation, then be sure to update the PATH environment variable appropriately.

export PATH=${HOME}/.juliaup/bin:${PATH}

You may then list the available Julia versions with juliaup list and install a
specific version with juliaup install <version>. You can then activate a
specific version with juliaup use <version> and set the default version with
juliaup default <version>. juliaup update will update the installed Julia
versions. In general, the latest stable release of Julia should be used.

bash
juliaup add release

Julia Project Environment

### Human: What is the recommended way of installing Julia according to the provided guide?

### Assistant: Using the official Julia 1.9 binaries from the Julia webpage is recommended, followed by installing Julia using Juliaup with the command `curl -fsSL https://install.julialang.org | sh`.
    "
"
### Context: 
bash
juliaup add release

Julia Project Environment

The Julia built-in package manager allows you to create a project and enable
project-specific dependencies. Julia manages packages in the Julia depot located
by default in ~/.julia. However, that NFS filesystem is not meant for
high-speed access. Therefore, this Julia depot folder should be located on a
fast filesystem of your choice (grand, eagle). The Julia depot directory is
set via the environment variable JULIA_DEPOT_PATH. For example, you can set
the Julia depot to a directory on Polaris grand filesystem by adding the following line
to your ~/.bashrc file:

bash
export JULIA_DEPOT_PATH=/grand/$PROJECT/$USER/julia_depot

Programming Julia on Polaris

There are three key components to using Julia for large-scale computations:

MPI support through MPI.jl

GPU support through CUDA.jl

HDF5 support through HDF5.jl

In addition, we recommend VSCode with the Julia
extension for a modern IDE experience, together
with the ssh-remote extension for remote interactive development.

MPI Support

MPI support is provided through the MPI.jl.
bash
$ julia --project -e 'using Pkg; Pkg.add(""MPI"")'
This will install the MPI.jl package and default MPI prebuilt binaries provided by an artifact. For on-node debugging purposes the default artifact is sufficient. However, for large-scale computations, it is important to use the Cray MPICH installed on Polaris. As of MPI.jl v0.20 this is handled through MPIPrefences.jl.
$ julia --project -e 'using Pkg; Pkg.add(""MPIPreferences"")'
$ julia --project -e 'using MPIPreferences; MPIPreferences.use_system_binary(vendor=""cray"")'

The vendor=""cray"" option is important if you intend to use gpu-aware MPI in your applications.

Check that the correct MPI library is targeted with Julia.
```
julia --project -e 'using MPI; MPI.versioninfo()'
MPIPreferences:
  binary:  system
  abi:     MPICH
  libmpi:  libmpi_nvidia.so
  mpiexec: mpiexec

### Human: What is Julia depot path?

### Assistant: The Julia depot path can be set by adding a line to your ~/.bashrc file, for example: `export JULIA_DEPOT_PATH=/home/user/julia_depot`.
    "
"
### Context: 
bash
juliaup add release

Julia Project Environment

The Julia built-in package manager allows you to create a project and enable
project-specific dependencies. Julia manages packages in the Julia depot located
by default in ~/.julia. However, that NFS filesystem is not meant for
high-speed access. Therefore, this Julia depot folder should be located on a
fast filesystem of your choice (grand, eagle). The Julia depot directory is
set via the environment variable JULIA_DEPOT_PATH. For example, you can set
the Julia depot to a directory on Polaris grand filesystem by adding the following line
to your ~/.bashrc file:

bash
export JULIA_DEPOT_PATH=/grand/$PROJECT/$USER/julia_depot

Programming Julia on Polaris

There are three key components to using Julia for large-scale computations:

MPI support through MPI.jl

GPU support through CUDA.jl

HDF5 support through HDF5.jl

In addition, we recommend VSCode with the Julia
extension for a modern IDE experience, together
with the ssh-remote extension for remote interactive development.

MPI Support

MPI support is provided through the MPI.jl.
bash
$ julia --project -e 'using Pkg; Pkg.add(""MPI"")'
This will install the MPI.jl package and default MPI prebuilt binaries provided by an artifact. For on-node debugging purposes the default artifact is sufficient. However, for large-scale computations, it is important to use the Cray MPICH installed on Polaris. As of MPI.jl v0.20 this is handled through MPIPrefences.jl.
$ julia --project -e 'using Pkg; Pkg.add(""MPIPreferences"")'
$ julia --project -e 'using MPIPreferences; MPIPreferences.use_system_binary(vendor=""cray"")'

The vendor=""cray"" option is important if you intend to use gpu-aware MPI in your applications.

Check that the correct MPI library is targeted with Julia.
```
julia --project -e 'using MPI; MPI.versioninfo()'
MPIPreferences:
  binary:  system
  abi:     MPICH
  libmpi:  libmpi_nvidia.so
  mpiexec: mpiexec

### Human: How do I enable MPI support in Julia?

### Assistant: Enable MPI support in Julia by installing the MPI.jl package and setting up the MPIPreferences.jl package with `vendor=""cray""` for large-scale computations.
    "
"
### Context: 
bash
juliaup add release

Julia Project Environment

The Julia built-in package manager allows you to create a project and enable
project-specific dependencies. Julia manages packages in the Julia depot located
by default in ~/.julia. However, that NFS filesystem is not meant for
high-speed access. Therefore, this Julia depot folder should be located on a
fast filesystem of your choice (grand, eagle). The Julia depot directory is
set via the environment variable JULIA_DEPOT_PATH. For example, you can set
the Julia depot to a directory on Polaris grand filesystem by adding the following line
to your ~/.bashrc file:

bash
export JULIA_DEPOT_PATH=/grand/$PROJECT/$USER/julia_depot

Programming Julia on Polaris

There are three key components to using Julia for large-scale computations:

MPI support through MPI.jl

GPU support through CUDA.jl

HDF5 support through HDF5.jl

In addition, we recommend VSCode with the Julia
extension for a modern IDE experience, together
with the ssh-remote extension for remote interactive development.

MPI Support

MPI support is provided through the MPI.jl.
bash
$ julia --project -e 'using Pkg; Pkg.add(""MPI"")'
This will install the MPI.jl package and default MPI prebuilt binaries provided by an artifact. For on-node debugging purposes the default artifact is sufficient. However, for large-scale computations, it is important to use the Cray MPICH installed on Polaris. As of MPI.jl v0.20 this is handled through MPIPrefences.jl.
$ julia --project -e 'using Pkg; Pkg.add(""MPIPreferences"")'
$ julia --project -e 'using MPIPreferences; MPIPreferences.use_system_binary(vendor=""cray"")'

The vendor=""cray"" option is important if you intend to use gpu-aware MPI in your applications.

Check that the correct MPI library is targeted with Julia.
```
julia --project -e 'using MPI; MPI.versioninfo()'
MPIPreferences:
  binary:  system
  abi:     MPICH
  libmpi:  libmpi_nvidia.so
  mpiexec: mpiexec

### Human: Which MPI library does Julia use by default?

### Assistant: MPICH
    "
"
### Context: 
Package versions
  MPI.jl:             0.20.19
  MPIPreferences.jl:  0.1.11

Library information:
  libmpi:  libmpi_nvidia.so
  libmpi dlpath:  /opt/cray/pe/lib64/libmpi_nvidia.so
  MPI version:  3.1.0
  Library version:

MPI VERSION    : CRAY MPICH version 8.1.28.2 (ANL base 3.4a2)
    MPI BUILD INFO : Wed Nov 15 21:59 2023 (git hash 1cde46f)

``
When running on the login node, switch back to the default provided MPI binaries inMPI_jll.jl

by removing theLocalPreferences.toml` file.

GPU Support

NVIDIA GPU support is provided through the CUDA.jl package. The default in Julia is to download artifacts (e.g. CUDA toolkit) based on the runtime detected. While that should generally work, it is recommended to use the local CUDA installation provided on Polaris especially if using gpu-aware MPI in your workloads (important to use supported versions of CUDA with Cray MPICH provided).

To use the local CUDA installation provided by the modules on Polaris, the LocalPreferences.toml file can be modified as follows.

$ head $JULIA_DEPOT_PATH/environments/v1.10/LocalPreferences.toml
[CUDA_Runtime_jll]
local = true

If using the default PrgEnv-nvhpc module on Polaris, then it will be necessary to correct a path to the CUPTI library to successfully install CUDA.jl.

$ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CRAY_NVIDIA_PREFIX/cuda/12.2/extras/CUPTI/lib64/
$ julia --project -e 'using Pkg; Pkg.add(""CUDA"")'

The GPUs are not currently usable on the Polaris login nodes, so one can confirm the version of CUDA being used by testing in a batch or interactive job on a compute node.

```
$ qsub -I -l select=1,walltime=1:00:00,filesystems=home:grand:eagle -A [PROJECT] -q debug

$ julia --project -e ""using CUDA; CUDA.versioninfo()""
CUDA runtime 12.4, artifact installation
CUDA driver 12.4
NVIDIA driver 535.154.5, originally for CUDA 12.2

CUDA libraries: 
- CUBLAS: 12.2.1
- CURAND: 10.3.5
- CUFFT: 11.2.1
- CUSOLVER: 11.6.1
- CUSPARSE: 12.3.1
- CUPTI: 22.0.0
- NVML: 12.0.0+535.154.5

### Human: What is the current version of MPI.jl installed?

### Assistant: The current version of MPI.jl installed is 0.20.19.
    "
"
### Context: 
Package versions
  MPI.jl:             0.20.19
  MPIPreferences.jl:  0.1.11

Library information:
  libmpi:  libmpi_nvidia.so
  libmpi dlpath:  /opt/cray/pe/lib64/libmpi_nvidia.so
  MPI version:  3.1.0
  Library version:

MPI VERSION    : CRAY MPICH version 8.1.28.2 (ANL base 3.4a2)
    MPI BUILD INFO : Wed Nov 15 21:59 2023 (git hash 1cde46f)

``
When running on the login node, switch back to the default provided MPI binaries inMPI_jll.jl

by removing theLocalPreferences.toml` file.

GPU Support

NVIDIA GPU support is provided through the CUDA.jl package. The default in Julia is to download artifacts (e.g. CUDA toolkit) based on the runtime detected. While that should generally work, it is recommended to use the local CUDA installation provided on Polaris especially if using gpu-aware MPI in your workloads (important to use supported versions of CUDA with Cray MPICH provided).

To use the local CUDA installation provided by the modules on Polaris, the LocalPreferences.toml file can be modified as follows.

$ head $JULIA_DEPOT_PATH/environments/v1.10/LocalPreferences.toml
[CUDA_Runtime_jll]
local = true

If using the default PrgEnv-nvhpc module on Polaris, then it will be necessary to correct a path to the CUPTI library to successfully install CUDA.jl.

$ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CRAY_NVIDIA_PREFIX/cuda/12.2/extras/CUPTI/lib64/
$ julia --project -e 'using Pkg; Pkg.add(""CUDA"")'

The GPUs are not currently usable on the Polaris login nodes, so one can confirm the version of CUDA being used by testing in a batch or interactive job on a compute node.

```
$ qsub -I -l select=1,walltime=1:00:00,filesystems=home:grand:eagle -A [PROJECT] -q debug

$ julia --project -e ""using CUDA; CUDA.versioninfo()""
CUDA runtime 12.4, artifact installation
CUDA driver 12.4
NVIDIA driver 535.154.5, originally for CUDA 12.2

CUDA libraries: 
- CUBLAS: 12.2.1
- CURAND: 10.3.5
- CUFFT: 11.2.1
- CUSOLVER: 11.6.1
- CUSPARSE: 12.3.1
- CUPTI: 22.0.0
- NVML: 12.0.0+535.154.5

### Human: How can I switch back to the default provided MPI binaries in MPI_jll.jl when running on the login node?

### Assistant: Remove the LocalPreferences.toml file.
    "
"
### Context: 
Package versions
  MPI.jl:             0.20.19
  MPIPreferences.jl:  0.1.11

Library information:
  libmpi:  libmpi_nvidia.so
  libmpi dlpath:  /opt/cray/pe/lib64/libmpi_nvidia.so
  MPI version:  3.1.0
  Library version:

MPI VERSION    : CRAY MPICH version 8.1.28.2 (ANL base 3.4a2)
    MPI BUILD INFO : Wed Nov 15 21:59 2023 (git hash 1cde46f)

``
When running on the login node, switch back to the default provided MPI binaries inMPI_jll.jl

by removing theLocalPreferences.toml` file.

GPU Support

NVIDIA GPU support is provided through the CUDA.jl package. The default in Julia is to download artifacts (e.g. CUDA toolkit) based on the runtime detected. While that should generally work, it is recommended to use the local CUDA installation provided on Polaris especially if using gpu-aware MPI in your workloads (important to use supported versions of CUDA with Cray MPICH provided).

To use the local CUDA installation provided by the modules on Polaris, the LocalPreferences.toml file can be modified as follows.

$ head $JULIA_DEPOT_PATH/environments/v1.10/LocalPreferences.toml
[CUDA_Runtime_jll]
local = true

If using the default PrgEnv-nvhpc module on Polaris, then it will be necessary to correct a path to the CUPTI library to successfully install CUDA.jl.

$ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CRAY_NVIDIA_PREFIX/cuda/12.2/extras/CUPTI/lib64/
$ julia --project -e 'using Pkg; Pkg.add(""CUDA"")'

The GPUs are not currently usable on the Polaris login nodes, so one can confirm the version of CUDA being used by testing in a batch or interactive job on a compute node.

```
$ qsub -I -l select=1,walltime=1:00:00,filesystems=home:grand:eagle -A [PROJECT] -q debug

$ julia --project -e ""using CUDA; CUDA.versioninfo()""
CUDA runtime 12.4, artifact installation
CUDA driver 12.4
NVIDIA driver 535.154.5, originally for CUDA 12.2

CUDA libraries: 
- CUBLAS: 12.2.1
- CURAND: 10.3.5
- CUFFT: 11.2.1
- CUSOLVER: 11.6.1
- CUSPARSE: 12.3.1
- CUPTI: 22.0.0
- NVML: 12.0.0+535.154.5

### Human: What is the version of CUDA runtime being used by Julia?

### Assistant: 12.4
    "
"
### Context: 
Julia packages: 
- CUDA: 5.3.3
- CUDA_Driver_jll: 0.8.1+0
- CUDA_Runtime_jll: 0.12.1+0

Toolchain:
- Julia: 1.10.3
- LLVM: 15.0.7

4 devices:
  0: NVIDIA A100-SXM4-40GB (sm_80, 39.390 GiB / 40.000 GiB available)
  1: NVIDIA A100-SXM4-40GB (sm_80, 39.390 GiB / 40.000 GiB available)
  2: NVIDIA A100-SXM4-40GB (sm_80, 39.390 GiB / 40.000 GiB available)
  3: NVIDIA A100-SXM4-40GB (sm_80, 39.390 GiB / 40.000 GiB available)
```

One can then switch between versions of CUDA as needed. Note, the following commands were executed in an interactive job on a compute node.

$ julia --project -e ""using CUDA; CUDA.set_runtime_version!(local_toolkit=true)""
[ Info: Configure the active project to use the default CUDA from the local system; please re-start Julia for this to take effect.

```
$ julia --project -e ""using CUDA; CUDA.versioninfo()""
CUDA runtime 12.2, local installation
CUDA driver 12.4
NVIDIA driver 535.154.5, originally for CUDA 12.2

CUDA libraries: 
- CUBLAS: 12.2.1
- CURAND: 10.3.3
- CUFFT: 11.0.8
- CUSOLVER: 11.5.0
- CUSPARSE: 12.1.1
- CUPTI: 20.0.0
- NVML: 12.0.0+535.154.5

Julia packages: 
- CUDA: 5.3.3
- CUDA_Driver_jll: 0.8.1+0
- CUDA_Runtime_jll: 0.12.1+0
- CUDA_Runtime_Discovery: 0.2.4

Toolchain:
- Julia: 1.10.3
- LLVM: 15.0.7

Preferences:
- CUDA_Runtime_jll.local: true

4 devices:
  0: NVIDIA A100-SXM4-40GB (sm_80, 39.390 GiB / 40.000 GiB available)
  1: NVIDIA A100-SXM4-40GB (sm_80, 39.390 GiB / 40.000 GiB available)
  2: NVIDIA A100-SXM4-40GB (sm_80, 39.390 GiB / 40.000 GiB available)
  3: NVIDIA A100-SXM4-40GB (sm_80, 39.390 GiB / 40.000 GiB available)

Warning messages from the presence of CUDA in LD_LIBRARY_PATH were ommitted in output of the first two commands. In this case, the artifact and local installation are similar. If there was a difference, then the local installation should be preferred.

### Human: What is the current version of CUDA installed?

### Assistant: CUDA 12.2
    "
"
### Context: 
Julia packages: 
- CUDA: 5.3.3
- CUDA_Driver_jll: 0.8.1+0
- CUDA_Runtime_jll: 0.12.1+0

Toolchain:
- Julia: 1.10.3
- LLVM: 15.0.7

4 devices:
  0: NVIDIA A100-SXM4-40GB (sm_80, 39.390 GiB / 40.000 GiB available)
  1: NVIDIA A100-SXM4-40GB (sm_80, 39.390 GiB / 40.000 GiB available)
  2: NVIDIA A100-SXM4-40GB (sm_80, 39.390 GiB / 40.000 GiB available)
  3: NVIDIA A100-SXM4-40GB (sm_80, 39.390 GiB / 40.000 GiB available)
```

One can then switch between versions of CUDA as needed. Note, the following commands were executed in an interactive job on a compute node.

$ julia --project -e ""using CUDA; CUDA.set_runtime_version!(local_toolkit=true)""
[ Info: Configure the active project to use the default CUDA from the local system; please re-start Julia for this to take effect.

```
$ julia --project -e ""using CUDA; CUDA.versioninfo()""
CUDA runtime 12.2, local installation
CUDA driver 12.4
NVIDIA driver 535.154.5, originally for CUDA 12.2

CUDA libraries: 
- CUBLAS: 12.2.1
- CURAND: 10.3.3
- CUFFT: 11.0.8
- CUSOLVER: 11.5.0
- CUSPARSE: 12.1.1
- CUPTI: 20.0.0
- NVML: 12.0.0+535.154.5

Julia packages: 
- CUDA: 5.3.3
- CUDA_Driver_jll: 0.8.1+0
- CUDA_Runtime_jll: 0.12.1+0
- CUDA_Runtime_Discovery: 0.2.4

Toolchain:
- Julia: 1.10.3
- LLVM: 15.0.7

Preferences:
- CUDA_Runtime_jll.local: true

4 devices:
  0: NVIDIA A100-SXM4-40GB (sm_80, 39.390 GiB / 40.000 GiB available)
  1: NVIDIA A100-SXM4-40GB (sm_80, 39.390 GiB / 40.000 GiB available)
  2: NVIDIA A100-SXM4-40GB (sm_80, 39.390 GiB / 40.000 GiB available)
  3: NVIDIA A100-SXM4-40GB (sm_80, 39.390 GiB / 40.000 GiB available)

Warning messages from the presence of CUDA in LD_LIBRARY_PATH were ommitted in output of the first two commands. In this case, the artifact and local installation are similar. If there was a difference, then the local installation should be preferred.

### Human: How many devices with NVIDIA A100-SXM4-40GB architecture are available for use?

### Assistant: 4
    "
"
### Context: 
Julia packages: 
- CUDA: 5.3.3
- CUDA_Driver_jll: 0.8.1+0
- CUDA_Runtime_jll: 0.12.1+0

Toolchain:
- Julia: 1.10.3
- LLVM: 15.0.7

4 devices:
  0: NVIDIA A100-SXM4-40GB (sm_80, 39.390 GiB / 40.000 GiB available)
  1: NVIDIA A100-SXM4-40GB (sm_80, 39.390 GiB / 40.000 GiB available)
  2: NVIDIA A100-SXM4-40GB (sm_80, 39.390 GiB / 40.000 GiB available)
  3: NVIDIA A100-SXM4-40GB (sm_80, 39.390 GiB / 40.000 GiB available)
```

One can then switch between versions of CUDA as needed. Note, the following commands were executed in an interactive job on a compute node.

$ julia --project -e ""using CUDA; CUDA.set_runtime_version!(local_toolkit=true)""
[ Info: Configure the active project to use the default CUDA from the local system; please re-start Julia for this to take effect.

```
$ julia --project -e ""using CUDA; CUDA.versioninfo()""
CUDA runtime 12.2, local installation
CUDA driver 12.4
NVIDIA driver 535.154.5, originally for CUDA 12.2

CUDA libraries: 
- CUBLAS: 12.2.1
- CURAND: 10.3.3
- CUFFT: 11.0.8
- CUSOLVER: 11.5.0
- CUSPARSE: 12.1.1
- CUPTI: 20.0.0
- NVML: 12.0.0+535.154.5

Julia packages: 
- CUDA: 5.3.3
- CUDA_Driver_jll: 0.8.1+0
- CUDA_Runtime_jll: 0.12.1+0
- CUDA_Runtime_Discovery: 0.2.4

Toolchain:
- Julia: 1.10.3
- LLVM: 15.0.7

Preferences:
- CUDA_Runtime_jll.local: true

4 devices:
  0: NVIDIA A100-SXM4-40GB (sm_80, 39.390 GiB / 40.000 GiB available)
  1: NVIDIA A100-SXM4-40GB (sm_80, 39.390 GiB / 40.000 GiB available)
  2: NVIDIA A100-SXM4-40GB (sm_80, 39.390 GiB / 40.000 GiB available)
  3: NVIDIA A100-SXM4-40GB (sm_80, 39.390 GiB / 40.000 GiB available)

Warning messages from the presence of CUDA in LD_LIBRARY_PATH were ommitted in output of the first two commands. In this case, the artifact and local installation are similar. If there was a difference, then the local installation should be preferred.

### Human: Can you list all the Julia packages installed, including their versions?

### Assistant: The Julia packages installed, including their versions, are: CUDA: 5.3.3, CUDA_Driver_jll: 0.8.1+0, CUDA_Runtime_jll: 0.12.1+0.
    "
"
### Context: 
In case you want write portable GPU kernels we highly recommend the KernelAbstractions.jl package. It provides a high-level abstraction for writing GPU kernels that can be compiled for different GPU backends.

julia --project -e 'using Pkg; Pkg.add(""KernelAbstractions"")'

By loading either oneAPI.jl, AMDGPU.jl, or CUDA.jl (see quickstart guide below).

CUDA-aware MPI

MPI.jl supports CUDA-aware MPI. This is enabled by setting the following environment variables.

bash
export JULIA_CUDA_MEMORY_POOL=none
export MPICH_GPU_SUPPORT_ENABLED=1
export JULIA_MPI_PATH=${CRAY_MPICH_DIR}
export JULIA_MPI_HAS_CUDA=1

Note that MPI.jl needs to be rebuilt for the changes to take effect.

bash
julia --project -e 'using Pkg; Pkg.build(""MPI"")'

HDF5 Support

Parallel HDF5 support is provided by
module load cray-hdf5-parallel
After setting export JULIA_HDF5_PATH=$HDF5_DIR we can install the HDF5.jl package.

julia --project -e 'using Pkg; Pkg.add(""HDF5"")'

To remove warning messages indicating that use of JULIA_HDF5_PATH has been deprecated, one can use the following command to set the HDF5 libraries.

```
$ echo $CRAY_HDF5_PARALLEL_PREFIX/
/opt/cray/pe/hdf5-parallel/1.12.2.9/nvidia/23.3

$ julia --project -e 'using HDF5; HDF5.API.set_libraries!(""/opt/cray/pe/hdf5-parallel/1.12.2.9/nvidia/23.3/lib/libhdf5.so"", ""/opt/cray/pe/hdf5-parallel/1.12.2.9/nvidia/23.3/lib/libhdf5_hl.so"")'
```

Quickstart Guide

The following example shows how to use MPI.jl, CUDA.jl, and HDF5.jl to write a
parallel program that computes the sum of two vectors on the GPU and writes the
result to an HDF5 file. A repository with an example code computing an
approximation of pi can be found at
Polaris.jl. In this repository, you will also find
a setup_polaris.sh script that will build the HDF5.jl and MPI.jl package for the system libraries.
The dependencies are installed with the following commands:
bash
julia --project

julia
julia> ] up

```julia
using CUDA
using HDF5
using MPI
using Printf
using Random

### Human: What is the recommended package for writing portable GPU kernels in Julia?

### Assistant: The recommended package for writing portable GPU kernels in Julia is KernelAbstractions.jl.
    "
"
### Context: 
In case you want write portable GPU kernels we highly recommend the KernelAbstractions.jl package. It provides a high-level abstraction for writing GPU kernels that can be compiled for different GPU backends.

julia --project -e 'using Pkg; Pkg.add(""KernelAbstractions"")'

By loading either oneAPI.jl, AMDGPU.jl, or CUDA.jl (see quickstart guide below).

CUDA-aware MPI

MPI.jl supports CUDA-aware MPI. This is enabled by setting the following environment variables.

bash
export JULIA_CUDA_MEMORY_POOL=none
export MPICH_GPU_SUPPORT_ENABLED=1
export JULIA_MPI_PATH=${CRAY_MPICH_DIR}
export JULIA_MPI_HAS_CUDA=1

Note that MPI.jl needs to be rebuilt for the changes to take effect.

bash
julia --project -e 'using Pkg; Pkg.build(""MPI"")'

HDF5 Support

Parallel HDF5 support is provided by
module load cray-hdf5-parallel
After setting export JULIA_HDF5_PATH=$HDF5_DIR we can install the HDF5.jl package.

julia --project -e 'using Pkg; Pkg.add(""HDF5"")'

To remove warning messages indicating that use of JULIA_HDF5_PATH has been deprecated, one can use the following command to set the HDF5 libraries.

```
$ echo $CRAY_HDF5_PARALLEL_PREFIX/
/opt/cray/pe/hdf5-parallel/1.12.2.9/nvidia/23.3

$ julia --project -e 'using HDF5; HDF5.API.set_libraries!(""/opt/cray/pe/hdf5-parallel/1.12.2.9/nvidia/23.3/lib/libhdf5.so"", ""/opt/cray/pe/hdf5-parallel/1.12.2.9/nvidia/23.3/lib/libhdf5_hl.so"")'
```

Quickstart Guide

The following example shows how to use MPI.jl, CUDA.jl, and HDF5.jl to write a
parallel program that computes the sum of two vectors on the GPU and writes the
result to an HDF5 file. A repository with an example code computing an
approximation of pi can be found at
Polaris.jl. In this repository, you will also find
a setup_polaris.sh script that will build the HDF5.jl and MPI.jl package for the system libraries.
The dependencies are installed with the following commands:
bash
julia --project

julia
julia> ] up

```julia
using CUDA
using HDF5
using MPI
using Printf
using Random

### Human: How do I enable CUDA-aware MPI support in Julia?

### Assistant: To enable CUDA-aware MPI support in Julia, set the environment variables and rebuild MPI.jl.

Answer: $To enable CUDA-aware MPI support in Julia, set the environment variables and rebuild MPI.jl.
    "
"
### Context: 
In case you want write portable GPU kernels we highly recommend the KernelAbstractions.jl package. It provides a high-level abstraction for writing GPU kernels that can be compiled for different GPU backends.

julia --project -e 'using Pkg; Pkg.add(""KernelAbstractions"")'

By loading either oneAPI.jl, AMDGPU.jl, or CUDA.jl (see quickstart guide below).

CUDA-aware MPI

MPI.jl supports CUDA-aware MPI. This is enabled by setting the following environment variables.

bash
export JULIA_CUDA_MEMORY_POOL=none
export MPICH_GPU_SUPPORT_ENABLED=1
export JULIA_MPI_PATH=${CRAY_MPICH_DIR}
export JULIA_MPI_HAS_CUDA=1

Note that MPI.jl needs to be rebuilt for the changes to take effect.

bash
julia --project -e 'using Pkg; Pkg.build(""MPI"")'

HDF5 Support

Parallel HDF5 support is provided by
module load cray-hdf5-parallel
After setting export JULIA_HDF5_PATH=$HDF5_DIR we can install the HDF5.jl package.

julia --project -e 'using Pkg; Pkg.add(""HDF5"")'

To remove warning messages indicating that use of JULIA_HDF5_PATH has been deprecated, one can use the following command to set the HDF5 libraries.

```
$ echo $CRAY_HDF5_PARALLEL_PREFIX/
/opt/cray/pe/hdf5-parallel/1.12.2.9/nvidia/23.3

$ julia --project -e 'using HDF5; HDF5.API.set_libraries!(""/opt/cray/pe/hdf5-parallel/1.12.2.9/nvidia/23.3/lib/libhdf5.so"", ""/opt/cray/pe/hdf5-parallel/1.12.2.9/nvidia/23.3/lib/libhdf5_hl.so"")'
```

Quickstart Guide

The following example shows how to use MPI.jl, CUDA.jl, and HDF5.jl to write a
parallel program that computes the sum of two vectors on the GPU and writes the
result to an HDF5 file. A repository with an example code computing an
approximation of pi can be found at
Polaris.jl. In this repository, you will also find
a setup_polaris.sh script that will build the HDF5.jl and MPI.jl package for the system libraries.
The dependencies are installed with the following commands:
bash
julia --project

julia
julia> ] up

```julia
using CUDA
using HDF5
using MPI
using Printf
using Random

### Human: What steps can I take to install and set up HDF5.jl and MPI.jl packages for parallel programming with Julia?

### Assistant: To install and set up HDF5.jl and MPI.jl packages for parallel programming with Julia, follow these steps: Install KernelAbstractions.jl, load the desired GPU backend package, enable CUDA-aware MPI, rebuild MPI.jl, install HDF5.jl.
    "
"
### Context: 
julia
julia> ] up

```julia
using CUDA
using HDF5
using MPI
using Printf
using Random

function pi_kernel(x, y, d, n)
    idx = (blockIdx().x-1) * blockDim().x + threadIdx().x
    if idx <= n
        d[idx] = (x[idx] - 0.5)^2 + (y[idx] - 0.5)^2 <= 0.25 ? 1 : 0
    end
    return nothing
end

function approximate_pi_gpu(n::Integer)
    x = CUDA.rand(Float64, n)
    y = CUDA.rand(Float64, n)
    d = CUDA.zeros(Float64, n)

end

function main()
    n = 100000  # Number of points to generate per rank
    Random.seed!(1234)  # Set a fixed random seed for reproducibility

end

MPI.Init()
if !isinteractive()
    pi_approx = main()
    h5open(""pi.h5"", ""w"") do file
        write(file, ""pi"", pi_approx)
    end
end
```

Job submission script

This example can be run on Polaris with the following job submission script:

```bash

!/bin/bash -l

PBS -l select=1:system=polaris

PBS -l place=scatter

PBS -l walltime=0:30:00

PBS -l filesystems=home:grand

PBS -q debug

PBS -A PROJECT

cd ${PBS_O_WORKDIR}

MPI example w/ 4 MPI ranks per node spread evenly across cores

NNODES=wc -l < $PBS_NODEFILE
NRANKS_PER_NODE=4
NDEPTH=8
NTHREADS=1

Setup Julia environment

. ./setup_env.sh

NTOTRANKS=$(( NNODES * NRANKS_PER_NODE ))
echo ""NUM_OF_NODES= ${NNODES} TOTAL_NUM_RANKS= ${NTOTRANKS} RANKS_PER_NODE=${NRANKS_PER_NODE} THREADS_PER_RANK= ${NTHREADS}""

EXE=/home/knight/.julia/juliaup/julia-1.10.3+0.x64.linux.gnu/bin/julia

MPI_ARGS=""-n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --depth=${NDEPTH} --cpu-bind depth""

mpiexec ${MPI_ARGS} ${EXE} --check-bounds=no --project pi.jl
```

The setup_env.sh script updates the environment as indicated above.

```
$ cat ./setup_env.sh
module restore
module load craype-accel-nvidia80
module load cray-hdf5-parallel

export PATH=/home/knight/.juliaup/bin:${PATH}
export JULIA_DEPOT_PATH=/grand/catalyst/proj-shared/knight/polaris/julia/depot

export JULIA_HDF5_PATH=$HDF5_DIR

export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CRAY_NVIDIA_PREFIX/cuda/12.2/extras/CUPTI/lib64/

### Human: What is the purpose of the `MPI_Init()` function in this script?

### Assistant: The purpose of the `MPI_Init()` function in this script is to initialize the MPI environment.
    "
"
### Context: 
julia
julia> ] up

```julia
using CUDA
using HDF5
using MPI
using Printf
using Random

function pi_kernel(x, y, d, n)
    idx = (blockIdx().x-1) * blockDim().x + threadIdx().x
    if idx <= n
        d[idx] = (x[idx] - 0.5)^2 + (y[idx] - 0.5)^2 <= 0.25 ? 1 : 0
    end
    return nothing
end

function approximate_pi_gpu(n::Integer)
    x = CUDA.rand(Float64, n)
    y = CUDA.rand(Float64, n)
    d = CUDA.zeros(Float64, n)

end

function main()
    n = 100000  # Number of points to generate per rank
    Random.seed!(1234)  # Set a fixed random seed for reproducibility

end

MPI.Init()
if !isinteractive()
    pi_approx = main()
    h5open(""pi.h5"", ""w"") do file
        write(file, ""pi"", pi_approx)
    end
end
```

Job submission script

This example can be run on Polaris with the following job submission script:

```bash

!/bin/bash -l

PBS -l select=1:system=polaris

PBS -l place=scatter

PBS -l walltime=0:30:00

PBS -l filesystems=home:grand

PBS -q debug

PBS -A PROJECT

cd ${PBS_O_WORKDIR}

MPI example w/ 4 MPI ranks per node spread evenly across cores

NNODES=wc -l < $PBS_NODEFILE
NRANKS_PER_NODE=4
NDEPTH=8
NTHREADS=1

Setup Julia environment

. ./setup_env.sh

NTOTRANKS=$(( NNODES * NRANKS_PER_NODE ))
echo ""NUM_OF_NODES= ${NNODES} TOTAL_NUM_RANKS= ${NTOTRANKS} RANKS_PER_NODE=${NRANKS_PER_NODE} THREADS_PER_RANK= ${NTHREADS}""

EXE=/home/knight/.julia/juliaup/julia-1.10.3+0.x64.linux.gnu/bin/julia

MPI_ARGS=""-n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --depth=${NDEPTH} --cpu-bind depth""

mpiexec ${MPI_ARGS} ${EXE} --check-bounds=no --project pi.jl
```

The setup_env.sh script updates the environment as indicated above.

```
$ cat ./setup_env.sh
module restore
module load craype-accel-nvidia80
module load cray-hdf5-parallel

export PATH=/home/knight/.juliaup/bin:${PATH}
export JULIA_DEPOT_PATH=/grand/catalyst/proj-shared/knight/polaris/julia/depot

export JULIA_HDF5_PATH=$HDF5_DIR

export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CRAY_NVIDIA_PREFIX/cuda/12.2/extras/CUPTI/lib64/

### Human: How many points are generated by the `approximate_pi_gpu(n)` function in each run?

### Assistant: The approximate_pi_gpu function generates no points.
    "
"
### Context: 
julia
julia> ] up

```julia
using CUDA
using HDF5
using MPI
using Printf
using Random

function pi_kernel(x, y, d, n)
    idx = (blockIdx().x-1) * blockDim().x + threadIdx().x
    if idx <= n
        d[idx] = (x[idx] - 0.5)^2 + (y[idx] - 0.5)^2 <= 0.25 ? 1 : 0
    end
    return nothing
end

function approximate_pi_gpu(n::Integer)
    x = CUDA.rand(Float64, n)
    y = CUDA.rand(Float64, n)
    d = CUDA.zeros(Float64, n)

end

function main()
    n = 100000  # Number of points to generate per rank
    Random.seed!(1234)  # Set a fixed random seed for reproducibility

end

MPI.Init()
if !isinteractive()
    pi_approx = main()
    h5open(""pi.h5"", ""w"") do file
        write(file, ""pi"", pi_approx)
    end
end
```

Job submission script

This example can be run on Polaris with the following job submission script:

```bash

!/bin/bash -l

PBS -l select=1:system=polaris

PBS -l place=scatter

PBS -l walltime=0:30:00

PBS -l filesystems=home:grand

PBS -q debug

PBS -A PROJECT

cd ${PBS_O_WORKDIR}

MPI example w/ 4 MPI ranks per node spread evenly across cores

NNODES=wc -l < $PBS_NODEFILE
NRANKS_PER_NODE=4
NDEPTH=8
NTHREADS=1

Setup Julia environment

. ./setup_env.sh

NTOTRANKS=$(( NNODES * NRANKS_PER_NODE ))
echo ""NUM_OF_NODES= ${NNODES} TOTAL_NUM_RANKS= ${NTOTRANKS} RANKS_PER_NODE=${NRANKS_PER_NODE} THREADS_PER_RANK= ${NTHREADS}""

EXE=/home/knight/.julia/juliaup/julia-1.10.3+0.x64.linux.gnu/bin/julia

MPI_ARGS=""-n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --depth=${NDEPTH} --cpu-bind depth""

mpiexec ${MPI_ARGS} ${EXE} --check-bounds=no --project pi.jl
```

The setup_env.sh script updates the environment as indicated above.

```
$ cat ./setup_env.sh
module restore
module load craype-accel-nvidia80
module load cray-hdf5-parallel

export PATH=/home/knight/.juliaup/bin:${PATH}
export JULIA_DEPOT_PATH=/grand/catalyst/proj-shared/knight/polaris/julia/depot

export JULIA_HDF5_PATH=$HDF5_DIR

export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CRAY_NVIDIA_PREFIX/cuda/12.2/extras/CUPTI/lib64/

### Human: What environment setup is performed by the `setup_env.sh` script?

### Assistant: The environment setup performed by the `setup_env.sh` script includes loading modules for NVIDIA GPU acceleration and HDF5 parallel processing, updating the `PATH` variable, and setting export variables related to Julia package management and HDF5 processing.
    "
"
### Context: 
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CRAY_NVIDIA_PREFIX/cuda/12.2/extras/CUPTI/lib64/

export JULIA_CUDA_MEMORY_POOL=none
export MPICH_GPU_SUPPORT_ENABLED=1
export JULIA_MPI_PATH=${CRAY_MPICH_DIR}
export JULIA_MPI_HAS_CUDA=1

export TMPDIR=/local/scratch

Temporary workaround

export LD_PRELOAD=libmpi_gtl_cuda.so
```

Verify that JULIA_DEPOT_PATH is set to the correct path and JULIA_PATH
points to the Julia executable. When using juliaup, the Julia executable is
located in the juliaup folder of your JULIA_DEPOT_PATH.

Large-scale parallelism

CUDA.jl uses the nvcc compiler to compile GPU kernels. This will create object files in the TEMP filesystem. The default TMPDIR in a job on Polaris is set to a temp directory that only exists on the head node of a job. We recommend setting TEMPDIR to a local directory on each compute node.
bash
export TMPDIR=/local/scratch

A simple example to test gpu-aware MPI on multiple nodes is available here.

### Human: What is the recommended setting for the TMPDIR environment variable in a job on Polaris?

### Assistant: /local/scratch
    "
"
### Context: 
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CRAY_NVIDIA_PREFIX/cuda/12.2/extras/CUPTI/lib64/

export JULIA_CUDA_MEMORY_POOL=none
export MPICH_GPU_SUPPORT_ENABLED=1
export JULIA_MPI_PATH=${CRAY_MPICH_DIR}
export JULIA_MPI_HAS_CUDA=1

export TMPDIR=/local/scratch

Temporary workaround

export LD_PRELOAD=libmpi_gtl_cuda.so
```

Verify that JULIA_DEPOT_PATH is set to the correct path and JULIA_PATH
points to the Julia executable. When using juliaup, the Julia executable is
located in the juliaup folder of your JULIA_DEPOT_PATH.

Large-scale parallelism

CUDA.jl uses the nvcc compiler to compile GPU kernels. This will create object files in the TEMP filesystem. The default TMPDIR in a job on Polaris is set to a temp directory that only exists on the head node of a job. We recommend setting TEMPDIR to a local directory on each compute node.
bash
export TMPDIR=/local/scratch

A simple example to test gpu-aware MPI on multiple nodes is available here.

### Human: How does CUDA.jl compile GPU kernels, and what kind of object files does it create?

### Assistant: CUDA.jl compiles GPU kernels using the nvcc compiler and creates object files in the TEMP filesystem.
    "
"
### Context: 
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CRAY_NVIDIA_PREFIX/cuda/12.2/extras/CUPTI/lib64/

export JULIA_CUDA_MEMORY_POOL=none
export MPICH_GPU_SUPPORT_ENABLED=1
export JULIA_MPI_PATH=${CRAY_MPICH_DIR}
export JULIA_MPI_HAS_CUDA=1

export TMPDIR=/local/scratch

Temporary workaround

export LD_PRELOAD=libmpi_gtl_cuda.so
```

Verify that JULIA_DEPOT_PATH is set to the correct path and JULIA_PATH
points to the Julia executable. When using juliaup, the Julia executable is
located in the juliaup folder of your JULIA_DEPOT_PATH.

Large-scale parallelism

CUDA.jl uses the nvcc compiler to compile GPU kernels. This will create object files in the TEMP filesystem. The default TMPDIR in a job on Polaris is set to a temp directory that only exists on the head node of a job. We recommend setting TEMPDIR to a local directory on each compute node.
bash
export TMPDIR=/local/scratch

A simple example to test gpu-aware MPI on multiple nodes is available here.

### Human: What is a simple example to test gpu-aware MPI on multiple nodes using CUDA.jl?

### Assistant: The steps above provide a simple example to test gpu-aware MPI on multiple nodes using CUDA.jl.
    "
"
### Context: 
Python

We provide prebuilt conda environments containing GPU-supported builds of
torch, tensorflow (both with horovod support for multi-node
calculations), jax, and many other commonly-used Python modules.

Users can activate this environment by first loading the conda module, and
then activating the base environment.

Explicitly (either from an interactive job, or inside a job script):

bash
module use /soft/modulefiles; module load conda ; conda activate base

This will load and activate the base environment.

Virtual environments via venv

To install additional packages that are missing from the base environment,
we can build a venv on top of it.

!!! success ""Conda base environment + venv""

You can always retroactively change the #!bash --system-site-packages flag
state for this virtual environment by editing #!bash ${VENV_DIR}/pyvenv.cfg and
changing the value of the line #!bash include-system-site-packages=false.

To install a different version of a package that is already installed in the
base environment, you can use:

bash
python3 pip install --ignore-installed <package> # or -I

The shared base environment is not writable, so it is impossible to remove or
uninstall packages from it. The packages installed with the above pip command
should shadow those installed in the base environment.

Cloning the base Anaconda environment

!!! warning

If you need more flexibility, you can clone the conda environment into a custom
path, which would then allow for root-like installations via #!bash conda install
<module> or #!bash pip install <module>.

Unlike the venv approach, using a cloned Anaconda environment requires you to
copy the entirety of the base environment, which can use significant storage
space.

To clone the base environment:

bash
module load conda ; conda activate base
conda create --clone base --prefix /path/to/envs/base-clone
conda activate /path/to/envs/base-clone

where, #!bash path/to/envs/base-clone should be replaced by a suitably chosen
path.

### Human: How do I activate the prebuilt conda environment?

### Assistant: Activate the prebuilt conda environment by running `module load conda` and then `conda activate base`.
    "
"
### Context: 
Python

We provide prebuilt conda environments containing GPU-supported builds of
torch, tensorflow (both with horovod support for multi-node
calculations), jax, and many other commonly-used Python modules.

Users can activate this environment by first loading the conda module, and
then activating the base environment.

Explicitly (either from an interactive job, or inside a job script):

bash
module use /soft/modulefiles; module load conda ; conda activate base

This will load and activate the base environment.

Virtual environments via venv

To install additional packages that are missing from the base environment,
we can build a venv on top of it.

!!! success ""Conda base environment + venv""

You can always retroactively change the #!bash --system-site-packages flag
state for this virtual environment by editing #!bash ${VENV_DIR}/pyvenv.cfg and
changing the value of the line #!bash include-system-site-packages=false.

To install a different version of a package that is already installed in the
base environment, you can use:

bash
python3 pip install --ignore-installed <package> # or -I

The shared base environment is not writable, so it is impossible to remove or
uninstall packages from it. The packages installed with the above pip command
should shadow those installed in the base environment.

Cloning the base Anaconda environment

!!! warning

If you need more flexibility, you can clone the conda environment into a custom
path, which would then allow for root-like installations via #!bash conda install
<module> or #!bash pip install <module>.

Unlike the venv approach, using a cloned Anaconda environment requires you to
copy the entirety of the base environment, which can use significant storage
space.

To clone the base environment:

bash
module load conda ; conda activate base
conda create --clone base --prefix /path/to/envs/base-clone
conda activate /path/to/envs/base-clone

where, #!bash path/to/envs/base-clone should be replaced by a suitably chosen
path.

### Human: Can I install additional packages in the base environment?

### Assistant: You can build a venv on top of the base environment to install additional packages.
    "
"
### Context: 
Python

We provide prebuilt conda environments containing GPU-supported builds of
torch, tensorflow (both with horovod support for multi-node
calculations), jax, and many other commonly-used Python modules.

Users can activate this environment by first loading the conda module, and
then activating the base environment.

Explicitly (either from an interactive job, or inside a job script):

bash
module use /soft/modulefiles; module load conda ; conda activate base

This will load and activate the base environment.

Virtual environments via venv

To install additional packages that are missing from the base environment,
we can build a venv on top of it.

!!! success ""Conda base environment + venv""

You can always retroactively change the #!bash --system-site-packages flag
state for this virtual environment by editing #!bash ${VENV_DIR}/pyvenv.cfg and
changing the value of the line #!bash include-system-site-packages=false.

To install a different version of a package that is already installed in the
base environment, you can use:

bash
python3 pip install --ignore-installed <package> # or -I

The shared base environment is not writable, so it is impossible to remove or
uninstall packages from it. The packages installed with the above pip command
should shadow those installed in the base environment.

Cloning the base Anaconda environment

!!! warning

If you need more flexibility, you can clone the conda environment into a custom
path, which would then allow for root-like installations via #!bash conda install
<module> or #!bash pip install <module>.

Unlike the venv approach, using a cloned Anaconda environment requires you to
copy the entirety of the base environment, which can use significant storage
space.

To clone the base environment:

bash
module load conda ; conda activate base
conda create --clone base --prefix /path/to/envs/base-clone
conda activate /path/to/envs/base-clone

where, #!bash path/to/envs/base-clone should be replaced by a suitably chosen
path.

### Human: What is the best way to clone the base Anaconda environment for more flexibility?

### Assistant: Clone the base Anaconda environment by running `module load conda ; conda activate base` followed by `conda create --clone base --prefix /path/to/envs/base-clone` and then `conda activate /path/to/envs/base-clone`.
    "
"
### Context: 
where, #!bash path/to/envs/base-clone should be replaced by a suitably chosen
path.

Note: The cloning process can be quite slow.

Using pip install --user (not recommended)

!!! danger

With the conda environment setup, one can install common Python modules using
#!bash python3 pip install --users '<module-name>' which will install
packages in #!bash $PYTHONUSERBASE/lib/pythonX.Y/site-packages.

The #!bash $PYTHONUSERBASE environment variable is automatically set when you
load the base conda module, and is equal to  #!bash
/home/$USER/.local/polaris/conda/YYYY-MM-DD.

Note, Python modules installed this way that contain command line binaries will
not have those binaries automatically added to the shell's #!bash $PATH. To
manually add the path:

bash
export PATH=""$PYTHONUSERBASE/bin:$PATH""

Be sure to remove this location from #!bash $PATH if you deactivate the base
Anaconda environment or unload the module.

Cloning the Anaconda environment, or using venv are both more flexible and
transparent when compared to #!bash --user installs.

### Human: What is the purpose of loading the base conda module?

### Assistant: The purpose of loading the base conda module is to set the $PYTHONUSERBASE environment variable.
    "
"
### Context: 
where, #!bash path/to/envs/base-clone should be replaced by a suitably chosen
path.

Note: The cloning process can be quite slow.

Using pip install --user (not recommended)

!!! danger

With the conda environment setup, one can install common Python modules using
#!bash python3 pip install --users '<module-name>' which will install
packages in #!bash $PYTHONUSERBASE/lib/pythonX.Y/site-packages.

The #!bash $PYTHONUSERBASE environment variable is automatically set when you
load the base conda module, and is equal to  #!bash
/home/$USER/.local/polaris/conda/YYYY-MM-DD.

Note, Python modules installed this way that contain command line binaries will
not have those binaries automatically added to the shell's #!bash $PATH. To
manually add the path:

bash
export PATH=""$PYTHONUSERBASE/bin:$PATH""

Be sure to remove this location from #!bash $PATH if you deactivate the base
Anaconda environment or unload the module.

Cloning the Anaconda environment, or using venv are both more flexible and
transparent when compared to #!bash --user installs.

### Human: How do you manually add a path containing command line binaries installed using pip install --user?

### Assistant: export PATH=""$PYTHONUSERBASE/bin:$PATH""
    "
"
### Context: 
where, #!bash path/to/envs/base-clone should be replaced by a suitably chosen
path.

Note: The cloning process can be quite slow.

Using pip install --user (not recommended)

!!! danger

With the conda environment setup, one can install common Python modules using
#!bash python3 pip install --users '<module-name>' which will install
packages in #!bash $PYTHONUSERBASE/lib/pythonX.Y/site-packages.

The #!bash $PYTHONUSERBASE environment variable is automatically set when you
load the base conda module, and is equal to  #!bash
/home/$USER/.local/polaris/conda/YYYY-MM-DD.

Note, Python modules installed this way that contain command line binaries will
not have those binaries automatically added to the shell's #!bash $PATH. To
manually add the path:

bash
export PATH=""$PYTHONUSERBASE/bin:$PATH""

Be sure to remove this location from #!bash $PATH if you deactivate the base
Anaconda environment or unload the module.

Cloning the Anaconda environment, or using venv are both more flexible and
transparent when compared to #!bash --user installs.

### Human: Why are pip install --user installations not recommended?

### Assistant: Pip install --user installations are not recommended because they do not automatically add command line binaries to the shell's $PATH, requiring manual modifications to environment variables.
    "
"
### Context: 
DeepSpeed

The base conda environment on Polaris comes with Microsoft's
DeepSpeed pre-installed. Instructions
for using / cloning the base environment can be found here.

A batch submission script for the following example is available
here.

We describe below the steps needed to get started with DeepSpeed on Polaris.

We focus on the cifar example provided in the
DeepSpeedExamples repository,
though this approach should be generally applicable for running any model with
DeepSpeed support.

Running DeepSpeed on Polaris

!!! note

Load conda module and activate base environment:
bash
module load conda ; conda activate base

Clone
   microsoft/DeepSpeedExamples
   and navigate into the directory:
bash
git clone https://github.com/microsoft/DeepSpeedExamples.git
cd DeepSpeedExamples/cifar

!!! example ""Launching DeepSpeed""

???- bug ""AssertionError: Micro batch sizer per gpu: 0 has to be greater than 0""

### Human: How do I load and activate the base conda environment on Polaris?

### Assistant: Load and activate the base conda environment by running `module load conda` followed by `conda activate base`.
    "
"
### Context: 
DeepSpeed

The base conda environment on Polaris comes with Microsoft's
DeepSpeed pre-installed. Instructions
for using / cloning the base environment can be found here.

A batch submission script for the following example is available
here.

We describe below the steps needed to get started with DeepSpeed on Polaris.

We focus on the cifar example provided in the
DeepSpeedExamples repository,
though this approach should be generally applicable for running any model with
DeepSpeed support.

Running DeepSpeed on Polaris

!!! note

Load conda module and activate base environment:
bash
module load conda ; conda activate base

Clone
   microsoft/DeepSpeedExamples
   and navigate into the directory:
bash
git clone https://github.com/microsoft/DeepSpeedExamples.git
cd DeepSpeedExamples/cifar

!!! example ""Launching DeepSpeed""

???- bug ""AssertionError: Micro batch sizer per gpu: 0 has to be greater than 0""

### Human: What is an example of a model I can run with DeepSpeed support using the steps described in the instructions?

### Assistant: To run an example model with DeepSpeed support on Polaris, follow steps 1-3 and ensure that the micro batch size per GPU is set to a value greater than 0.
    "
"
### Context: 
DeepSpeed

The base conda environment on Polaris comes with Microsoft's
DeepSpeed pre-installed. Instructions
for using / cloning the base environment can be found here.

A batch submission script for the following example is available
here.

We describe below the steps needed to get started with DeepSpeed on Polaris.

We focus on the cifar example provided in the
DeepSpeedExamples repository,
though this approach should be generally applicable for running any model with
DeepSpeed support.

Running DeepSpeed on Polaris

!!! note

Load conda module and activate base environment:
bash
module load conda ; conda activate base

Clone
   microsoft/DeepSpeedExamples
   and navigate into the directory:
bash
git clone https://github.com/microsoft/DeepSpeedExamples.git
cd DeepSpeedExamples/cifar

!!! example ""Launching DeepSpeed""

???- bug ""AssertionError: Micro batch sizer per gpu: 0 has to be greater than 0""

### Human: Why am I getting an AssertionError when launching DeepSpeed, saying ""Micro batch sizer per gpu: 0 has to be greater than 0""?

### Assistant: Try setting the micro batch size per GPU to a value greater than 0 (e.g., 32 or 64) in your configuration file.
    "
"
### Context: 
PyTorch on Polaris

PyTorch is a popular, open source deep learning framework developed and released by Facebook.  The PyTorch home page has more information about PyTorch, which you can refer to.  For trouble shooting on Polaris, please contact support@alcf.anl.gov.

Installation on Polaris

PyTorch is installed on Polaris already, available in the conda module.  To use it from a compute node, please do:

bash
module load conda
conda activate

Then, you can load PyTorch in python as usual (below showing results from the conda/2022-07-19 module):

```python

import torch
torch.version
'1.12.0a0+git67ece03'

```

This installation of PyTorch was built from source and the cuda libraries it uses are found via the CUDA_HOME environment variable (below showing results from the conda/2022-07-19 module):

bash
$ echo $CUDA_HOME
/soft/datascience/cuda/cuda_11.5.2_495.29.05_linux

If you need to build applications that use this version of PyTorch and CUDA, we recommend using these cuda libraries to ensure compatibility.  We periodically update the PyTorch release, though updates will come in the form of new versions of the conda module.

PyTorch is also available through nvidia containers that have been translated to Singularity containers.  For more information about containers, please see the containers documentation page.

PyTorch Best Practices on Polaris

Single Node Performance

When running PyTorch applications, we have found the following practices to be generally, if not universally, useful and encourage you to try some of these techniques to boost performance of your own applications.

### Human: What is the current version of PyTorch installed on Polaris?

### Assistant: 1.12.0a0+git67ece03
    "
"
### Context: 
PyTorch on Polaris

PyTorch is a popular, open source deep learning framework developed and released by Facebook.  The PyTorch home page has more information about PyTorch, which you can refer to.  For trouble shooting on Polaris, please contact support@alcf.anl.gov.

Installation on Polaris

PyTorch is installed on Polaris already, available in the conda module.  To use it from a compute node, please do:

bash
module load conda
conda activate

Then, you can load PyTorch in python as usual (below showing results from the conda/2022-07-19 module):

```python

import torch
torch.version
'1.12.0a0+git67ece03'

```

This installation of PyTorch was built from source and the cuda libraries it uses are found via the CUDA_HOME environment variable (below showing results from the conda/2022-07-19 module):

bash
$ echo $CUDA_HOME
/soft/datascience/cuda/cuda_11.5.2_495.29.05_linux

If you need to build applications that use this version of PyTorch and CUDA, we recommend using these cuda libraries to ensure compatibility.  We periodically update the PyTorch release, though updates will come in the form of new versions of the conda module.

PyTorch is also available through nvidia containers that have been translated to Singularity containers.  For more information about containers, please see the containers documentation page.

PyTorch Best Practices on Polaris

Single Node Performance

When running PyTorch applications, we have found the following practices to be generally, if not universally, useful and encourage you to try some of these techniques to boost performance of your own applications.

### Human: How can I load PyTorch in Python after activating the conda module on Polaris?

### Assistant: Load PyTorch by running `module load conda` and then `conda activate`.
    "
"
### Context: 
PyTorch on Polaris

PyTorch is a popular, open source deep learning framework developed and released by Facebook.  The PyTorch home page has more information about PyTorch, which you can refer to.  For trouble shooting on Polaris, please contact support@alcf.anl.gov.

Installation on Polaris

PyTorch is installed on Polaris already, available in the conda module.  To use it from a compute node, please do:

bash
module load conda
conda activate

Then, you can load PyTorch in python as usual (below showing results from the conda/2022-07-19 module):

```python

import torch
torch.version
'1.12.0a0+git67ece03'

```

This installation of PyTorch was built from source and the cuda libraries it uses are found via the CUDA_HOME environment variable (below showing results from the conda/2022-07-19 module):

bash
$ echo $CUDA_HOME
/soft/datascience/cuda/cuda_11.5.2_495.29.05_linux

If you need to build applications that use this version of PyTorch and CUDA, we recommend using these cuda libraries to ensure compatibility.  We periodically update the PyTorch release, though updates will come in the form of new versions of the conda module.

PyTorch is also available through nvidia containers that have been translated to Singularity containers.  For more information about containers, please see the containers documentation page.

PyTorch Best Practices on Polaris

Single Node Performance

When running PyTorch applications, we have found the following practices to be generally, if not universally, useful and encourage you to try some of these techniques to boost performance of your own applications.

### Human: Where are the CUDA libraries used by PyTorch on Polaris stored?

### Assistant: /soft/datascience/cuda/cuda_11.5.2_495.29.05_linux
    "
"
### Context: 
Use Reduced Precision. Reduced Precision is available on A100 via tensorcores and is supported with PyTorch operations.  In general, the way to do this is via the PyTorch Automatic Mixed Precision package (AMP), as descibed in the mixed precision documentation.  In PyTorch, users generally need to manage casting and loss scaling manually,  though context managers and function decorators can provide easy tools to do this.

PyTorch has a JIT module as well as backends to support op fusion, similar to TensorFlow's tf.function tools.  However, PyTorch JIT capabilities are newer and may not yield performance improvements.  Please see TorchScript for more information.

Multi-GPU / Multi-Node Scale up

PyTorch is compatible with scaling up to multiple GPUs per node, and across multiple nodes.  Good scaling performance has been seen up to the entire Polaris system, > 2048 GPUs.  Good performance with PyTorch has been seen with both DDP and Horovod.  For details, please see the Horovod documentation or the Distributed Data Parallel documentation.  Some Polaris-specific details that may be helpful to you:

CPU affinity and NCCL settings can improve scaling performance, particularly at the largest scales.  In particular, we encourage users to try their scaling measurements with the following settings:

Set the environment variable NCCL_COLLNET_ENABLE=1

Set the environment varialbe NCCL_NET_GDR_LEVEL=PHB

Manually set the CPU affinity via mpiexec, such as with --cpu-bind verbose,list:0,8,16,24

### Human: What is Reduced Precision in PyTorch?

### Assistant: Reduced Precision in PyTorch refers to the ability to use reduced precision with tensorcores on A100 via Automatic Mixed Precision (AMP) package.
    "
"
### Context: 
Use Reduced Precision. Reduced Precision is available on A100 via tensorcores and is supported with PyTorch operations.  In general, the way to do this is via the PyTorch Automatic Mixed Precision package (AMP), as descibed in the mixed precision documentation.  In PyTorch, users generally need to manage casting and loss scaling manually,  though context managers and function decorators can provide easy tools to do this.

PyTorch has a JIT module as well as backends to support op fusion, similar to TensorFlow's tf.function tools.  However, PyTorch JIT capabilities are newer and may not yield performance improvements.  Please see TorchScript for more information.

Multi-GPU / Multi-Node Scale up

PyTorch is compatible with scaling up to multiple GPUs per node, and across multiple nodes.  Good scaling performance has been seen up to the entire Polaris system, > 2048 GPUs.  Good performance with PyTorch has been seen with both DDP and Horovod.  For details, please see the Horovod documentation or the Distributed Data Parallel documentation.  Some Polaris-specific details that may be helpful to you:

CPU affinity and NCCL settings can improve scaling performance, particularly at the largest scales.  In particular, we encourage users to try their scaling measurements with the following settings:

Set the environment variable NCCL_COLLNET_ENABLE=1

Set the environment varialbe NCCL_NET_GDR_LEVEL=PHB

Manually set the CPU affinity via mpiexec, such as with --cpu-bind verbose,list:0,8,16,24

### Human: How does Automatic Mixed Precision package (AMP) work in PyTorch?

### Assistant: AMP works in PyTorch by allowing users to manage casting and loss scaling manually, while following the steps outlined in the mixed precision documentation.
    "
"
### Context: 
Use Reduced Precision. Reduced Precision is available on A100 via tensorcores and is supported with PyTorch operations.  In general, the way to do this is via the PyTorch Automatic Mixed Precision package (AMP), as descibed in the mixed precision documentation.  In PyTorch, users generally need to manage casting and loss scaling manually,  though context managers and function decorators can provide easy tools to do this.

PyTorch has a JIT module as well as backends to support op fusion, similar to TensorFlow's tf.function tools.  However, PyTorch JIT capabilities are newer and may not yield performance improvements.  Please see TorchScript for more information.

Multi-GPU / Multi-Node Scale up

PyTorch is compatible with scaling up to multiple GPUs per node, and across multiple nodes.  Good scaling performance has been seen up to the entire Polaris system, > 2048 GPUs.  Good performance with PyTorch has been seen with both DDP and Horovod.  For details, please see the Horovod documentation or the Distributed Data Parallel documentation.  Some Polaris-specific details that may be helpful to you:

CPU affinity and NCCL settings can improve scaling performance, particularly at the largest scales.  In particular, we encourage users to try their scaling measurements with the following settings:

Set the environment variable NCCL_COLLNET_ENABLE=1

Set the environment varialbe NCCL_NET_GDR_LEVEL=PHB

Manually set the CPU affinity via mpiexec, such as with --cpu-bind verbose,list:0,8,16,24

### Human: Can I scale up my PyTorch training to multiple GPUs or nodes?

### Assistant: Yes, you can scale up your PyTorch training to multiple GPUs or nodes.
    "
"
### Context: 
Manually set the CPU affinity via mpiexec, such as with --cpu-bind verbose,list:0,8,16,24

Horovod and DDP work best when you limit the visible devices to only one GPU.  Note that if you import mpi4py or horovod, and then do something like os.environ[""CUDA_VISIBLE_DEVICES""] = hvd.local_rank(), it may not actually work!  You must set the CUDA_VISIBLE_DEVICES environment variable prior to doing MPI.COMM_WORLD.init(), which is done in horovod.init() as well as implicitly in from mpi4py import MPI.   On Polaris specifically, you can use the environment variable PMI_LOCAL_RANK (as well as PMI_LOCAL_SIZE) to learn information about the node-local MPI ranks.

DeepSpeed

DeepSpeed is also available and usable on Polaris.  For more information, please see the DeepSpeed documentation directly.

PyTorch DataLoader and multi-node Horovod

Please note there is a bug that causes a hang when using PyTorch's multithreaded data loaders with distributed training across multiple nodes. To workaround this, NVIDIA recommends setting num_workers=0 in the dataloader configuration, which serializes data loading.

For more details, see Polaris Known Issues.

### Human: How do you manually set CPU affinity via mpiexec when running distributed deep learning models?

### Assistant: $--cpu-bind verbose,list:0,8,16,24
    "
"
### Context: 
Manually set the CPU affinity via mpiexec, such as with --cpu-bind verbose,list:0,8,16,24

Horovod and DDP work best when you limit the visible devices to only one GPU.  Note that if you import mpi4py or horovod, and then do something like os.environ[""CUDA_VISIBLE_DEVICES""] = hvd.local_rank(), it may not actually work!  You must set the CUDA_VISIBLE_DEVICES environment variable prior to doing MPI.COMM_WORLD.init(), which is done in horovod.init() as well as implicitly in from mpi4py import MPI.   On Polaris specifically, you can use the environment variable PMI_LOCAL_RANK (as well as PMI_LOCAL_SIZE) to learn information about the node-local MPI ranks.

DeepSpeed

DeepSpeed is also available and usable on Polaris.  For more information, please see the DeepSpeed documentation directly.

PyTorch DataLoader and multi-node Horovod

Please note there is a bug that causes a hang when using PyTorch's multithreaded data loaders with distributed training across multiple nodes. To workaround this, NVIDIA recommends setting num_workers=0 in the dataloader configuration, which serializes data loading.

For more details, see Polaris Known Issues.

### Human: Why is it important to limit visible devices to only one GPU when using Horovod and DDP for distributed training?

### Assistant: Limit visible devices to only one GPU by setting the CUDA_VISIBLE_DEVICES environment variable prior to initializing MPI.
    "
"
### Context: 
Manually set the CPU affinity via mpiexec, such as with --cpu-bind verbose,list:0,8,16,24

Horovod and DDP work best when you limit the visible devices to only one GPU.  Note that if you import mpi4py or horovod, and then do something like os.environ[""CUDA_VISIBLE_DEVICES""] = hvd.local_rank(), it may not actually work!  You must set the CUDA_VISIBLE_DEVICES environment variable prior to doing MPI.COMM_WORLD.init(), which is done in horovod.init() as well as implicitly in from mpi4py import MPI.   On Polaris specifically, you can use the environment variable PMI_LOCAL_RANK (as well as PMI_LOCAL_SIZE) to learn information about the node-local MPI ranks.

DeepSpeed

DeepSpeed is also available and usable on Polaris.  For more information, please see the DeepSpeed documentation directly.

PyTorch DataLoader and multi-node Horovod

Please note there is a bug that causes a hang when using PyTorch's multithreaded data loaders with distributed training across multiple nodes. To workaround this, NVIDIA recommends setting num_workers=0 in the dataloader configuration, which serializes data loading.

For more details, see Polaris Known Issues.

### Human: What is a known issue with PyTorch DataLoader and multi-node Horovod, and how can it be worked around?

### Assistant: Set `num_workers=0` in the DataLoader configuration to serialize data loading and avoid the hang.
    "
"
### Context: 
JAX

JAX is another popular python package for accelerated computing.  JAX is built on XLA (the same XLA TensorFlow uses) as well as AutoGrad, and additionally has acceleration tools that operate on functions such as vmap, jit, etc.  JAX is not as widespread in machine learning as TensorFlow and PyTorch for traditional models (Computer Vision, Language Models) though it is quickly gaining promienence.  JAX is very powerful when a program needs non-traditional autodifferentiation or vectorizatoin, such as: forward-mode AD, higher order derivatives, Jacobians, Hessians, or any combination of the above.  Users of JAX on Polaris are encouraged to read the user documentation in detail, particularly the details about pure-functional programming, no in-place operations, and the common mistakes in writing functions for the @jit decorator.

JAX on Polaris

JAX is installed on Polaris via the conda module, available with:
bash
module load conda; conda activate

Then, you can load JAX in python as usual (below showing results from the conda/2022-07-19 module):

```python

import jax
jax.version
'0.3.15'

```

Notes on JAX 0.3.15

On Polaris, due to a bug, an environment variable must be set to use JAX on GPUs.  The following code will crash:
python
import jax.numpy as numpy
a = numpy.zeros(1000)
outputting an error that looks like:
python
jaxlib.xla_extension.XlaRuntimeError: UNKNOWN: no kernel image is available for execution on the device

You can fix this by setting an environment variable:
bash
export XLA_FLAGS=""--xla_gpu_force_compilation_parallelism=1""

Scaling JAX to multiple GPUs and multiple Nodes

Jax has intrinsic scaling tools to use multiple GPUs on a single node, via the pmap function.  If this is sufficient for your needs, excellent.  If not, another alternative is to use the newer package mpi4jax.

### Human: What is JAX used for in accelerated computing?

### Assistant: JAX is used for non-traditional autodifferentiation or vectorization, such as forward-mode AD, higher order derivatives, Jacobians, Hessians, or any combination of the above, and has intrinsic scaling tools to use multiple GPUs on a single node.
    "
"
### Context: 
JAX

JAX is another popular python package for accelerated computing.  JAX is built on XLA (the same XLA TensorFlow uses) as well as AutoGrad, and additionally has acceleration tools that operate on functions such as vmap, jit, etc.  JAX is not as widespread in machine learning as TensorFlow and PyTorch for traditional models (Computer Vision, Language Models) though it is quickly gaining promienence.  JAX is very powerful when a program needs non-traditional autodifferentiation or vectorizatoin, such as: forward-mode AD, higher order derivatives, Jacobians, Hessians, or any combination of the above.  Users of JAX on Polaris are encouraged to read the user documentation in detail, particularly the details about pure-functional programming, no in-place operations, and the common mistakes in writing functions for the @jit decorator.

JAX on Polaris

JAX is installed on Polaris via the conda module, available with:
bash
module load conda; conda activate

Then, you can load JAX in python as usual (below showing results from the conda/2022-07-19 module):

```python

import jax
jax.version
'0.3.15'

```

Notes on JAX 0.3.15

On Polaris, due to a bug, an environment variable must be set to use JAX on GPUs.  The following code will crash:
python
import jax.numpy as numpy
a = numpy.zeros(1000)
outputting an error that looks like:
python
jaxlib.xla_extension.XlaRuntimeError: UNKNOWN: no kernel image is available for execution on the device

You can fix this by setting an environment variable:
bash
export XLA_FLAGS=""--xla_gpu_force_compilation_parallelism=1""

Scaling JAX to multiple GPUs and multiple Nodes

Jax has intrinsic scaling tools to use multiple GPUs on a single node, via the pmap function.  If this is sufficient for your needs, excellent.  If not, another alternative is to use the newer package mpi4jax.

### Human: How do you install JAX on Polaris using conda?

### Assistant: Install JAX on Polaris using conda by loading the conda module and activating the conda environment.
    "
"
### Context: 
JAX

JAX is another popular python package for accelerated computing.  JAX is built on XLA (the same XLA TensorFlow uses) as well as AutoGrad, and additionally has acceleration tools that operate on functions such as vmap, jit, etc.  JAX is not as widespread in machine learning as TensorFlow and PyTorch for traditional models (Computer Vision, Language Models) though it is quickly gaining promienence.  JAX is very powerful when a program needs non-traditional autodifferentiation or vectorizatoin, such as: forward-mode AD, higher order derivatives, Jacobians, Hessians, or any combination of the above.  Users of JAX on Polaris are encouraged to read the user documentation in detail, particularly the details about pure-functional programming, no in-place operations, and the common mistakes in writing functions for the @jit decorator.

JAX on Polaris

JAX is installed on Polaris via the conda module, available with:
bash
module load conda; conda activate

Then, you can load JAX in python as usual (below showing results from the conda/2022-07-19 module):

```python

import jax
jax.version
'0.3.15'

```

Notes on JAX 0.3.15

On Polaris, due to a bug, an environment variable must be set to use JAX on GPUs.  The following code will crash:
python
import jax.numpy as numpy
a = numpy.zeros(1000)
outputting an error that looks like:
python
jaxlib.xla_extension.XlaRuntimeError: UNKNOWN: no kernel image is available for execution on the device

You can fix this by setting an environment variable:
bash
export XLA_FLAGS=""--xla_gpu_force_compilation_parallelism=1""

Scaling JAX to multiple GPUs and multiple Nodes

Jax has intrinsic scaling tools to use multiple GPUs on a single node, via the pmap function.  If this is sufficient for your needs, excellent.  If not, another alternative is to use the newer package mpi4jax.

### Human: Why does setting an environment variable like XLA_FLAGS=""--xla_gpu_force_compilation_parallelism=1"" resolve an error when running JAX code?

### Assistant: Setting the environment variable `XLA_FLAGS` with the value `--xla_gpu_force_compilation_parallelism=1` resolves the error when running JAX code because it allows JAX to compile and execute kernels on the GPU, which is necessary for JAX's acceleration features.
    "
"
### Context: 
mpi4Jax is a relatively new project and requires setting some environment variables for good performance and usability:
- Set MPI4JAX_USE_CUDA_MPI=1 to use CUDA-Aware MPI, supported in the conda module, to do operations directly from the GPU.
- Set MPICH_GPU_SUPPORT_ENABLED=1 to use CUDA-Aware MPI.

The following code, based off of a test script from the mpi4jax repository, can help you verify you are using mpi4jax properly:

```python
import os
from mpi4py import MPI
import jax
import jax.numpy as jnp
import mpi4jax

comm = MPI.COMM_WORLD
rank = comm.Get_rank()
local_rank = int(os.environ[""PMI_LOCAL_RANK""])

available_devices = jax.devices(""gpu"")
if len(available_devices) <= local_rank:
    raise Exception(""Could not find enough GPUs"")

target_device = available_devices[local_rank]

@jax.jit
def foo(arr):
   arr = arr + rank
   arr_sum, _ = mpi4jax.allreduce(arr, op=MPI.SUM, comm=comm)
   return arr_sum

with jax.default_device(target_device):
    a = jnp.zeros((3, 3))
    print(f""Rank {rank}, local rank {local_rank}, a.device is {a.device()}"")
    result = foo(a)
    print(f""Rank {rank}, local rank {local_rank}, result.device is {result.device()}"")

if rank == 0:
   print(result)

```

JAX and mpi4jax are both still somewhat early in their software lifecycles.  Updates are frequent, and if you require assistance please contact support@alcf.anl.gov.

### Human: What environment variables should you set for good performance and usability with MPI4JAX?

### Assistant: Set `MPI4JAX_USE_CUDA_MPI=1` and `MPICH_GPU_SUPPORT_ENABLED=1` to use CUDA-Aware MPI for good performance and usability with MPI4JAX.
    "
"
### Context: 
mpi4Jax is a relatively new project and requires setting some environment variables for good performance and usability:
- Set MPI4JAX_USE_CUDA_MPI=1 to use CUDA-Aware MPI, supported in the conda module, to do operations directly from the GPU.
- Set MPICH_GPU_SUPPORT_ENABLED=1 to use CUDA-Aware MPI.

The following code, based off of a test script from the mpi4jax repository, can help you verify you are using mpi4jax properly:

```python
import os
from mpi4py import MPI
import jax
import jax.numpy as jnp
import mpi4jax

comm = MPI.COMM_WORLD
rank = comm.Get_rank()
local_rank = int(os.environ[""PMI_LOCAL_RANK""])

available_devices = jax.devices(""gpu"")
if len(available_devices) <= local_rank:
    raise Exception(""Could not find enough GPUs"")

target_device = available_devices[local_rank]

@jax.jit
def foo(arr):
   arr = arr + rank
   arr_sum, _ = mpi4jax.allreduce(arr, op=MPI.SUM, comm=comm)
   return arr_sum

with jax.default_device(target_device):
    a = jnp.zeros((3, 3))
    print(f""Rank {rank}, local rank {local_rank}, a.device is {a.device()}"")
    result = foo(a)
    print(f""Rank {rank}, local rank {local_rank}, result.device is {result.device()}"")

if rank == 0:
   print(result)

```

JAX and mpi4jax are both still somewhat early in their software lifecycles.  Updates are frequent, and if you require assistance please contact support@alcf.anl.gov.

### Human: How do I verify that I am using mpi4jax properly in my code?

### Assistant: The code is using mpi4jax properly if it runs without errors and the output shows that the computation is correctly placed on the GPUs.
    "
"
### Context: 
mpi4Jax is a relatively new project and requires setting some environment variables for good performance and usability:
- Set MPI4JAX_USE_CUDA_MPI=1 to use CUDA-Aware MPI, supported in the conda module, to do operations directly from the GPU.
- Set MPICH_GPU_SUPPORT_ENABLED=1 to use CUDA-Aware MPI.

The following code, based off of a test script from the mpi4jax repository, can help you verify you are using mpi4jax properly:

```python
import os
from mpi4py import MPI
import jax
import jax.numpy as jnp
import mpi4jax

comm = MPI.COMM_WORLD
rank = comm.Get_rank()
local_rank = int(os.environ[""PMI_LOCAL_RANK""])

available_devices = jax.devices(""gpu"")
if len(available_devices) <= local_rank:
    raise Exception(""Could not find enough GPUs"")

target_device = available_devices[local_rank]

@jax.jit
def foo(arr):
   arr = arr + rank
   arr_sum, _ = mpi4jax.allreduce(arr, op=MPI.SUM, comm=comm)
   return arr_sum

with jax.default_device(target_device):
    a = jnp.zeros((3, 3))
    print(f""Rank {rank}, local rank {local_rank}, a.device is {a.device()}"")
    result = foo(a)
    print(f""Rank {rank}, local rank {local_rank}, result.device is {result.device()}"")

if rank == 0:
   print(result)

```

JAX and mpi4jax are both still somewhat early in their software lifecycles.  Updates are frequent, and if you require assistance please contact support@alcf.anl.gov.

### Human: What is the purpose of setting MPICH_GPU_SUPPORT_ENABLED=1 when using MPI4JAX?

### Assistant: The purpose of setting MPICH_GPU_SUPPORT_ENABLED=1 when using MPI4JAX is to enable CUDA-Aware MPI.
    "
"
### Context: 
TensorFlow on Polaris

TensorFlow is a popular, open-source deep learning framework developed and released by Google.  The TensorFlow home page has more information about TensorFlow, which you can refer to.  For trouble shooting on Polaris, please contact support@alcf.anl.gov.

Installation on Polaris

TensorFlow is already pre-installed on Polaris, available in the conda module.  To use it from a compute node, please do:

bash
module load conda
conda activate

Then, you can load TensorFlow in python as usual (below showing results from the conda/2022-07-19 module):

```python

import tensorflow as tf
tf.version
'2.9.1'

```

This installation of TensorFlow was built from source and the CUDA libraries it uses are found via the CUDA_HOME environment variable (below showing results from the conda/2022-07-19 module):

bash
$ echo $CUDA_HOME
/soft/datascience/cuda/cuda_11.5.2_495.29.05_linux

If you need to build applications that use this version of TensorFlow and CUDA, we recommend using these cuda libraries to ensure compatibility.  We periodically update the TensorFlow release, though updates will come in the form of new versions of the conda module.

TensorFlow is also available through NVIDIA containers that have been translated to Singularity containers.  For more information about containers, please see the Containers documentation page.

TensorFlow Best Practices on Polaris

Single Node Performance

When running TensorFlow applications, we have found the following practices to be generally, if not universally, useful and encourage you to try some of these techniques to boost performance of your own applications.

Use Reduced Precision. Reduced Precision is available on A100 via tensorcores and is supported with TensorFlow operations.  In general, the way to do this is via the tf.keras.mixed_precision Policy, as descibed in the mixed precision documentation.  If you use a custom training loop (and not keras.Model.fit), you will also need to apply loss scaling.

### Human: How do I install TensorFlow on Polaris?

### Assistant: TensorFlow is already pre-installed on Polaris and can be used directly from the conda environment by loading the conda module and activating the conda environment.
    "
"
### Context: 
TensorFlow on Polaris

TensorFlow is a popular, open-source deep learning framework developed and released by Google.  The TensorFlow home page has more information about TensorFlow, which you can refer to.  For trouble shooting on Polaris, please contact support@alcf.anl.gov.

Installation on Polaris

TensorFlow is already pre-installed on Polaris, available in the conda module.  To use it from a compute node, please do:

bash
module load conda
conda activate

Then, you can load TensorFlow in python as usual (below showing results from the conda/2022-07-19 module):

```python

import tensorflow as tf
tf.version
'2.9.1'

```

This installation of TensorFlow was built from source and the CUDA libraries it uses are found via the CUDA_HOME environment variable (below showing results from the conda/2022-07-19 module):

bash
$ echo $CUDA_HOME
/soft/datascience/cuda/cuda_11.5.2_495.29.05_linux

If you need to build applications that use this version of TensorFlow and CUDA, we recommend using these cuda libraries to ensure compatibility.  We periodically update the TensorFlow release, though updates will come in the form of new versions of the conda module.

TensorFlow is also available through NVIDIA containers that have been translated to Singularity containers.  For more information about containers, please see the Containers documentation page.

TensorFlow Best Practices on Polaris

Single Node Performance

When running TensorFlow applications, we have found the following practices to be generally, if not universally, useful and encourage you to try some of these techniques to boost performance of your own applications.

Use Reduced Precision. Reduced Precision is available on A100 via tensorcores and is supported with TensorFlow operations.  In general, the way to do this is via the tf.keras.mixed_precision Policy, as descibed in the mixed precision documentation.  If you use a custom training loop (and not keras.Model.fit), you will also need to apply loss scaling.

### Human: What version of TensorFlow is installed on Polaris by default?

### Assistant: 2.9.1
    "
"
### Context: 
TensorFlow on Polaris

TensorFlow is a popular, open-source deep learning framework developed and released by Google.  The TensorFlow home page has more information about TensorFlow, which you can refer to.  For trouble shooting on Polaris, please contact support@alcf.anl.gov.

Installation on Polaris

TensorFlow is already pre-installed on Polaris, available in the conda module.  To use it from a compute node, please do:

bash
module load conda
conda activate

Then, you can load TensorFlow in python as usual (below showing results from the conda/2022-07-19 module):

```python

import tensorflow as tf
tf.version
'2.9.1'

```

This installation of TensorFlow was built from source and the CUDA libraries it uses are found via the CUDA_HOME environment variable (below showing results from the conda/2022-07-19 module):

bash
$ echo $CUDA_HOME
/soft/datascience/cuda/cuda_11.5.2_495.29.05_linux

If you need to build applications that use this version of TensorFlow and CUDA, we recommend using these cuda libraries to ensure compatibility.  We periodically update the TensorFlow release, though updates will come in the form of new versions of the conda module.

TensorFlow is also available through NVIDIA containers that have been translated to Singularity containers.  For more information about containers, please see the Containers documentation page.

TensorFlow Best Practices on Polaris

Single Node Performance

When running TensorFlow applications, we have found the following practices to be generally, if not universally, useful and encourage you to try some of these techniques to boost performance of your own applications.

Use Reduced Precision. Reduced Precision is available on A100 via tensorcores and is supported with TensorFlow operations.  In general, the way to do this is via the tf.keras.mixed_precision Policy, as descibed in the mixed precision documentation.  If you use a custom training loop (and not keras.Model.fit), you will also need to apply loss scaling.

### Human: How do I ensure compatibility when building applications that use this version of TensorFlow and CUDA?

### Assistant: Use the same CUDA libraries found via `CUDA_HOME` and monitor updates to ensure compatibility.
    "
"
### Context: 
Use TensorFlow's graph API to improve efficiency of operations.  TensorFlow is, in general, an imperative language but with function decorators like @tf.function you can trace functions in your code.  Tracing replaces your python function with a lower-level, semi-compiled TensorFlow Graph. More information about the tf.function interface is available here.  When possible, use jit_compile, but be aware of sharp bits when using tf.function: python expressions that aren't tensors are often replaced as constants in the graph, which may or may not be your intention.

Use XLA compilation on your code.  XLA is the Accelerated Linear Algebra library that is available in tensorFlow and critical in software like JAX.  XLA will compile a tf.Graph object, generated with tf.function or similar, and perform optimizations like operation-fusion.  XLA can give impressive performance boosts with almost no user changes except to set an environment variable TF_XLA_FLAGS=--tf_xla_auto_jit=2.  If your code is complex, or has dynamically sized tensors (tensors where the shape changes every iteration), XLA can be detrimental: the overhead for compiling functions can be large enough to mitigate performance improvements.  XLA is particularly powerful when combined with reduced precision, yielding speedups > 100% in some models.

Multi-GPU / Multi-Node Scale up

TensorFlow is compatible with scaling up to multiple GPUs per node, and across multiple nodes.  Good scaling performance has been seen up to the entire Polaris system, > 2048 GPUs.  Good performance with tensorFlow has been seen with horovod in particular.  For details, please see the Horovod documentation.  Some polaris specific details that may be helpful to you:

CPU affinity and NCCL settings can improve scaling performance, particularly at the largest scales.  In particular, we encourage users to try their scaling measurements with the following settings:

Set the environment variable NCCL_COLLNET_ENABLE=1

### Human: What is XLA compilation and how can it improve performance in TensorFlow?

### Assistant: XLA compilation in TensorFlow improves performance by compiling a tf.Graph object and performing optimizations like operation-fusion, with almost no user changes except setting an environment variable.
    "
"
### Context: 
Use TensorFlow's graph API to improve efficiency of operations.  TensorFlow is, in general, an imperative language but with function decorators like @tf.function you can trace functions in your code.  Tracing replaces your python function with a lower-level, semi-compiled TensorFlow Graph. More information about the tf.function interface is available here.  When possible, use jit_compile, but be aware of sharp bits when using tf.function: python expressions that aren't tensors are often replaced as constants in the graph, which may or may not be your intention.

Use XLA compilation on your code.  XLA is the Accelerated Linear Algebra library that is available in tensorFlow and critical in software like JAX.  XLA will compile a tf.Graph object, generated with tf.function or similar, and perform optimizations like operation-fusion.  XLA can give impressive performance boosts with almost no user changes except to set an environment variable TF_XLA_FLAGS=--tf_xla_auto_jit=2.  If your code is complex, or has dynamically sized tensors (tensors where the shape changes every iteration), XLA can be detrimental: the overhead for compiling functions can be large enough to mitigate performance improvements.  XLA is particularly powerful when combined with reduced precision, yielding speedups > 100% in some models.

Multi-GPU / Multi-Node Scale up

TensorFlow is compatible with scaling up to multiple GPUs per node, and across multiple nodes.  Good scaling performance has been seen up to the entire Polaris system, > 2048 GPUs.  Good performance with tensorFlow has been seen with horovod in particular.  For details, please see the Horovod documentation.  Some polaris specific details that may be helpful to you:

CPU affinity and NCCL settings can improve scaling performance, particularly at the largest scales.  In particular, we encourage users to try their scaling measurements with the following settings:

Set the environment variable NCCL_COLLNET_ENABLE=1

### Human: How does @tf.function differ from regular function execution in TensorFlow, and what benefits do they bring to the table?

### Assistant: @tf.function differs from regular function execution by compiling Python code into a TensorFlow Graph, which can lead to improved performance and efficiency. The benefits brought to the table include better performance and support for XLA compilation.
    "
"
### Context: 
Use TensorFlow's graph API to improve efficiency of operations.  TensorFlow is, in general, an imperative language but with function decorators like @tf.function you can trace functions in your code.  Tracing replaces your python function with a lower-level, semi-compiled TensorFlow Graph. More information about the tf.function interface is available here.  When possible, use jit_compile, but be aware of sharp bits when using tf.function: python expressions that aren't tensors are often replaced as constants in the graph, which may or may not be your intention.

Use XLA compilation on your code.  XLA is the Accelerated Linear Algebra library that is available in tensorFlow and critical in software like JAX.  XLA will compile a tf.Graph object, generated with tf.function or similar, and perform optimizations like operation-fusion.  XLA can give impressive performance boosts with almost no user changes except to set an environment variable TF_XLA_FLAGS=--tf_xla_auto_jit=2.  If your code is complex, or has dynamically sized tensors (tensors where the shape changes every iteration), XLA can be detrimental: the overhead for compiling functions can be large enough to mitigate performance improvements.  XLA is particularly powerful when combined with reduced precision, yielding speedups > 100% in some models.

Multi-GPU / Multi-Node Scale up

TensorFlow is compatible with scaling up to multiple GPUs per node, and across multiple nodes.  Good scaling performance has been seen up to the entire Polaris system, > 2048 GPUs.  Good performance with tensorFlow has been seen with horovod in particular.  For details, please see the Horovod documentation.  Some polaris specific details that may be helpful to you:

CPU affinity and NCCL settings can improve scaling performance, particularly at the largest scales.  In particular, we encourage users to try their scaling measurements with the following settings:

Set the environment variable NCCL_COLLNET_ENABLE=1

### Human: Can you provide some best practices for scaling up TensorFlow to multiple GPUs or nodes?

### Assistant: To scale up TensorFlow to multiple GPUs or nodes, use `jit_compile` and `tf.function` to improve efficiency of operations, use XLA compilation on your code for performance boosts, and leverage TensorFlow's compatibility with scaling up to multiple GPUs per node and across multiple nodes.

Answer: $To scale up TensorFlow to multiple GPUs or nodes, use jit_compile and tf.function to improve efficiency of operations, use XLA compilation on your code for performance boosts, and leverage TensorFlow's compatibility with scaling up to multiple GPUs per node and across multiple nodes.
    "
"
### Context: 
Set the environment variable NCCL_COLLNET_ENABLE=1

Set the environment varialbe NCCL_NET_GDR_LEVEL=PHB

Manually set the CPU affinity via mpiexec, such as with --cpu-bind verbose,list:0,8,16,24

Horovod works best when you limit the visible devices to only one GPU.  Note that if you import mpi4py or horovod, and then do something like os.environ[""CUDA_VISIBLE_DEVICES""] = hvd.local_rank(), it may not actually work!  You must set the CUDA_VISIBLE_DEVICES environment variable prior to doing MPI.COMM_WORLD.init(), which is done in horovod.init() as well as implicitly in from mpi4py import MPI.   On Polaris specifically, you can use the environment variable PMI_LOCAL_RANK (as well as PMI_LOCAL_SIZE) to learn information about the node-local MPI ranks.

TensorFlow Dataloaders

Additional information to be provided.

### Human: How do you manually set CPU affinity in Horovod?

### Assistant: Set CPU affinity via mpiexec with --cpu-bind verbose,list:0,8,16,24.
    "
"
### Context: 
Set the environment variable NCCL_COLLNET_ENABLE=1

Set the environment varialbe NCCL_NET_GDR_LEVEL=PHB

Manually set the CPU affinity via mpiexec, such as with --cpu-bind verbose,list:0,8,16,24

Horovod works best when you limit the visible devices to only one GPU.  Note that if you import mpi4py or horovod, and then do something like os.environ[""CUDA_VISIBLE_DEVICES""] = hvd.local_rank(), it may not actually work!  You must set the CUDA_VISIBLE_DEVICES environment variable prior to doing MPI.COMM_WORLD.init(), which is done in horovod.init() as well as implicitly in from mpi4py import MPI.   On Polaris specifically, you can use the environment variable PMI_LOCAL_RANK (as well as PMI_LOCAL_SIZE) to learn information about the node-local MPI ranks.

TensorFlow Dataloaders

Additional information to be provided.

### Human: What is the recommended approach to limit visible devices when using Horovod with multiple GPUs?

### Assistant: Set the CUDA_VISIBLE_DEVICES environment variable prior to initializing MPI, and manually set the CPU affinity via mpiexec.
    "
"
### Context: 
Set the environment variable NCCL_COLLNET_ENABLE=1

Set the environment varialbe NCCL_NET_GDR_LEVEL=PHB

Manually set the CPU affinity via mpiexec, such as with --cpu-bind verbose,list:0,8,16,24

Horovod works best when you limit the visible devices to only one GPU.  Note that if you import mpi4py or horovod, and then do something like os.environ[""CUDA_VISIBLE_DEVICES""] = hvd.local_rank(), it may not actually work!  You must set the CUDA_VISIBLE_DEVICES environment variable prior to doing MPI.COMM_WORLD.init(), which is done in horovod.init() as well as implicitly in from mpi4py import MPI.   On Polaris specifically, you can use the environment variable PMI_LOCAL_RANK (as well as PMI_LOCAL_SIZE) to learn information about the node-local MPI ranks.

TensorFlow Dataloaders

Additional information to be provided.

### Human: Can you provide an example of how to dynamically set the CUDA_VISIBLE_DEVICES environment variable in Python when using Horovod?

### Assistant: The final answer is: os.environ[""CUDA_VISIBLE_DEVICES""] = str(hvd.local_rank()).
    "
"
### Context: 
Containers on Polaris

Polaris, powered by NVIDIA A100 GPUs, benefits from container-based workloads for seamless compatibility across NVIDIA systems. This guide details the use of containers on Polaris, including custom container creation, large-scale execution, and common pitfalls.

Apptainer Setup

Polaris employs Apptainer (formerly known as Singularity) for container management. To set up Apptainer, run:

bash
module use /soft/spack/gcc/0.6.1/install/modulefiles/Core
module load apptainer
apptainer version #1.2.2

The Apptainer version on Polaris is 1.2.2. Detailed user documentation is available here

Building from Docker or Argonne GitHub Container Registry

Containers on Polaris can be built by writing Dockerfiles on a local machine and then publish the container to DockerHub, or by directly building them on ALCF compute node by writing an Apptainer recipe file. If you prefer to use existing containers, you can pull them from various registries like DockerHub and run them on Polaris.

Since Docker requires root privileges, which users do not have on Polaris, existing Docker containers must be converted to Apptainer. To build a Docker-based container on Polaris, use the following as an example:

### Human: How do I set up containers on Polaris?

### Assistant: Set up containers on Polaris by setting up Apptainer and then building or pulling existing containers from registries like DockerHub.
    "
"
### Context: 
Containers on Polaris

Polaris, powered by NVIDIA A100 GPUs, benefits from container-based workloads for seamless compatibility across NVIDIA systems. This guide details the use of containers on Polaris, including custom container creation, large-scale execution, and common pitfalls.

Apptainer Setup

Polaris employs Apptainer (formerly known as Singularity) for container management. To set up Apptainer, run:

bash
module use /soft/spack/gcc/0.6.1/install/modulefiles/Core
module load apptainer
apptainer version #1.2.2

The Apptainer version on Polaris is 1.2.2. Detailed user documentation is available here

Building from Docker or Argonne GitHub Container Registry

Containers on Polaris can be built by writing Dockerfiles on a local machine and then publish the container to DockerHub, or by directly building them on ALCF compute node by writing an Apptainer recipe file. If you prefer to use existing containers, you can pull them from various registries like DockerHub and run them on Polaris.

Since Docker requires root privileges, which users do not have on Polaris, existing Docker containers must be converted to Apptainer. To build a Docker-based container on Polaris, use the following as an example:

### Human: What is the version of Apptainer on Polaris?

### Assistant: $1.2.2
    "
"
### Context: 
Containers on Polaris

Polaris, powered by NVIDIA A100 GPUs, benefits from container-based workloads for seamless compatibility across NVIDIA systems. This guide details the use of containers on Polaris, including custom container creation, large-scale execution, and common pitfalls.

Apptainer Setup

Polaris employs Apptainer (formerly known as Singularity) for container management. To set up Apptainer, run:

bash
module use /soft/spack/gcc/0.6.1/install/modulefiles/Core
module load apptainer
apptainer version #1.2.2

The Apptainer version on Polaris is 1.2.2. Detailed user documentation is available here

Building from Docker or Argonne GitHub Container Registry

Containers on Polaris can be built by writing Dockerfiles on a local machine and then publish the container to DockerHub, or by directly building them on ALCF compute node by writing an Apptainer recipe file. If you prefer to use existing containers, you can pull them from various registries like DockerHub and run them on Polaris.

Since Docker requires root privileges, which users do not have on Polaris, existing Docker containers must be converted to Apptainer. To build a Docker-based container on Polaris, use the following as an example:

### Human: How can I build containers on Polaris from existing Docker images or registries?

### Assistant: To build containers on Polaris from existing Docker images or registries, pull the desired Docker image and convert it to Apptainer by creating an Apptainer recipe file.
    "
"
### Context: 
bash
qsub -I -A <Project> -q debug -l select=1 -l walltime=01:00:00 -l filesystems=home:eagle -l singularity_fakeroot=true
export HTTP_PROXY=http://proxy.alcf.anl.gov:3128
export HTTPS_PROXY=http://proxy.alcf.anl.gov:3128
export http_proxy=http://proxy.alcf.anl.gov:3128
export https_proxy=http://proxy.alcf.anl.gov:3128
module use /soft/spack/gcc/0.6.1/install/modulefiles/Core
module load apptainer
apptainer build --fakeroot pytorch:22.06-py3.sing docker://nvcr.io/nvidia/pytorch:22.06-py3
You can find the latest prebuilt Nvidia PyTorch containers here.  The Tensorflow containers are here (though note that LCF doesn't prebuild the TF-1 containers typically).  You can search the full container registry here. For custom containers tailored for Polaris, visit ALCF's GitHub container registry

Note: Currently container build and executions are only supported on the Polaris compute nodes

Recipe-Based Container Building

As mentioned earlier, you can build Apptainer containers from recipe files. Instructions are available here. See available containers for more recipes.

Note: You can also build custom recipes by bootstrapping from prebuilt images. For e.g the first two lines in a recipe to use our custom Tensorflow implementation would be Bootstrap: oras followed by From: ghcr.io/argonne-lcf/tf2-mpich-nvidia-gpu:latest

Running Containers on Polaris

To run a container on Polaris you can use the submission script described here. Below is an explanation of the job submission script.

```bash

!/bin/sh

PBS -l select=2:system=polaris

PBS -q debug

PBS -l place=scatter

PBS -l walltime=0:30:00

PBS -l filesystems=home:grand

PBS -A

cd ${PBS_O_WORKDIR}
echo $CONTAINER
```

We move to current working directory and enable network access at run time by setting the proxy. We also load apptainer.

```bash

SET proxy for internet access

### Human: What is Apptainer, and how does it relate to building containers on Polaris?

### Assistant: Apptainer is a tool used for building and running containers on Polaris, allowing users to create custom containers tailored for the system.
    "
"
### Context: 
bash
qsub -I -A <Project> -q debug -l select=1 -l walltime=01:00:00 -l filesystems=home:eagle -l singularity_fakeroot=true
export HTTP_PROXY=http://proxy.alcf.anl.gov:3128
export HTTPS_PROXY=http://proxy.alcf.anl.gov:3128
export http_proxy=http://proxy.alcf.anl.gov:3128
export https_proxy=http://proxy.alcf.anl.gov:3128
module use /soft/spack/gcc/0.6.1/install/modulefiles/Core
module load apptainer
apptainer build --fakeroot pytorch:22.06-py3.sing docker://nvcr.io/nvidia/pytorch:22.06-py3
You can find the latest prebuilt Nvidia PyTorch containers here.  The Tensorflow containers are here (though note that LCF doesn't prebuild the TF-1 containers typically).  You can search the full container registry here. For custom containers tailored for Polaris, visit ALCF's GitHub container registry

Note: Currently container build and executions are only supported on the Polaris compute nodes

Recipe-Based Container Building

As mentioned earlier, you can build Apptainer containers from recipe files. Instructions are available here. See available containers for more recipes.

Note: You can also build custom recipes by bootstrapping from prebuilt images. For e.g the first two lines in a recipe to use our custom Tensorflow implementation would be Bootstrap: oras followed by From: ghcr.io/argonne-lcf/tf2-mpich-nvidia-gpu:latest

Running Containers on Polaris

To run a container on Polaris you can use the submission script described here. Below is an explanation of the job submission script.

```bash

!/bin/sh

PBS -l select=2:system=polaris

PBS -q debug

PBS -l place=scatter

PBS -l walltime=0:30:00

PBS -l filesystems=home:grand

PBS -A

cd ${PBS_O_WORKDIR}
echo $CONTAINER
```

We move to current working directory and enable network access at run time by setting the proxy. We also load apptainer.

```bash

SET proxy for internet access

### Human: Can I build a custom container using recipe files on the Polaris compute nodes?

### Assistant: Yes, you can build a custom container using recipe files on the Polaris compute nodes.
    "
"
### Context: 
bash
qsub -I -A <Project> -q debug -l select=1 -l walltime=01:00:00 -l filesystems=home:eagle -l singularity_fakeroot=true
export HTTP_PROXY=http://proxy.alcf.anl.gov:3128
export HTTPS_PROXY=http://proxy.alcf.anl.gov:3128
export http_proxy=http://proxy.alcf.anl.gov:3128
export https_proxy=http://proxy.alcf.anl.gov:3128
module use /soft/spack/gcc/0.6.1/install/modulefiles/Core
module load apptainer
apptainer build --fakeroot pytorch:22.06-py3.sing docker://nvcr.io/nvidia/pytorch:22.06-py3
You can find the latest prebuilt Nvidia PyTorch containers here.  The Tensorflow containers are here (though note that LCF doesn't prebuild the TF-1 containers typically).  You can search the full container registry here. For custom containers tailored for Polaris, visit ALCF's GitHub container registry

Note: Currently container build and executions are only supported on the Polaris compute nodes

Recipe-Based Container Building

As mentioned earlier, you can build Apptainer containers from recipe files. Instructions are available here. See available containers for more recipes.

Note: You can also build custom recipes by bootstrapping from prebuilt images. For e.g the first two lines in a recipe to use our custom Tensorflow implementation would be Bootstrap: oras followed by From: ghcr.io/argonne-lcf/tf2-mpich-nvidia-gpu:latest

Running Containers on Polaris

To run a container on Polaris you can use the submission script described here. Below is an explanation of the job submission script.

```bash

!/bin/sh

PBS -l select=2:system=polaris

PBS -q debug

PBS -l place=scatter

PBS -l walltime=0:30:00

PBS -l filesystems=home:grand

PBS -A

cd ${PBS_O_WORKDIR}
echo $CONTAINER
```

We move to current working directory and enable network access at run time by setting the proxy. We also load apptainer.

```bash

SET proxy for internet access

### Human: How do I run a prebuilt or custom container on the Polaris cluster using a submission script?

### Assistant: Run a prebuilt or custom container on Polaris cluster using submission script by setting up environment, building container, creating submission script, and submitting job with qsub.
    "
"
### Context: 
Permission Denied Error: If you encounter permission errors during the build

Check your quota and delete any unnecessary files. 
Clean-up apptainer cache, ~/.apptainer/cache, and set the apptainer tmp and cache directories as below:
    bash
    export APPTAINER_TMPDIR=/tmp/apptainer-tmpdir
    mkdir $APPTAINER_TMPDIR
    export APPTAINER_CACHEDIR=/tmp/apptainer-cachedir/
    mkdir $APPTAINER_CACHEDIR 
Make sure you are not on a directory accessed with a symlink, i.e. check if pwd and pwd -P returns the same path.
If any of the above doesn't work, try running the build in your home directory.

Mapping to rank 0 on all nodes: Ensure that the container's MPI aligns with the system MPI. Follow the additional steps outlined in the container registry documentation for MPI on Polaris

libmpi.so.40 not found: This can happen if the container's application has an OpenMPI dependency which is not currently supported on Polaris. It can also spring up if the containers base environment is not debian architecture like Ubuntu. Ensure the application has an MPICH implementation as well. Also try removing .conda, .cache, and .local folders from your home directory and rebuild the container.

### Human: What are common issues when building containers in certain directories?

### Assistant: Common issues when building containers in certain directories include permission denied errors, symlink issues, MPI alignment issues, libmpi.so.40 not found errors, and unnecessary folder removal.
    "
"
### Context: 
Permission Denied Error: If you encounter permission errors during the build

Check your quota and delete any unnecessary files. 
Clean-up apptainer cache, ~/.apptainer/cache, and set the apptainer tmp and cache directories as below:
    bash
    export APPTAINER_TMPDIR=/tmp/apptainer-tmpdir
    mkdir $APPTAINER_TMPDIR
    export APPTAINER_CACHEDIR=/tmp/apptainer-cachedir/
    mkdir $APPTAINER_CACHEDIR 
Make sure you are not on a directory accessed with a symlink, i.e. check if pwd and pwd -P returns the same path.
If any of the above doesn't work, try running the build in your home directory.

Mapping to rank 0 on all nodes: Ensure that the container's MPI aligns with the system MPI. Follow the additional steps outlined in the container registry documentation for MPI on Polaris

libmpi.so.40 not found: This can happen if the container's application has an OpenMPI dependency which is not currently supported on Polaris. It can also spring up if the containers base environment is not debian architecture like Ubuntu. Ensure the application has an MPICH implementation as well. Also try removing .conda, .cache, and .local folders from your home directory and rebuild the container.

### Human: How can one resolve permission errors during a build process?

### Assistant: Resolve permission errors by checking quotas, cleaning up apptainer cache, verifying directory access, running builds in home directory, aligning MPI implementations, and removing unnecessary cache files.
    "
"
### Context: 
Permission Denied Error: If you encounter permission errors during the build

Check your quota and delete any unnecessary files. 
Clean-up apptainer cache, ~/.apptainer/cache, and set the apptainer tmp and cache directories as below:
    bash
    export APPTAINER_TMPDIR=/tmp/apptainer-tmpdir
    mkdir $APPTAINER_TMPDIR
    export APPTAINER_CACHEDIR=/tmp/apptainer-cachedir/
    mkdir $APPTAINER_CACHEDIR 
Make sure you are not on a directory accessed with a symlink, i.e. check if pwd and pwd -P returns the same path.
If any of the above doesn't work, try running the build in your home directory.

Mapping to rank 0 on all nodes: Ensure that the container's MPI aligns with the system MPI. Follow the additional steps outlined in the container registry documentation for MPI on Polaris

libmpi.so.40 not found: This can happen if the container's application has an OpenMPI dependency which is not currently supported on Polaris. It can also spring up if the containers base environment is not debian architecture like Ubuntu. Ensure the application has an MPICH implementation as well. Also try removing .conda, .cache, and .local folders from your home directory and rebuild the container.

### Human: What is the possible solution to resolve an issue where libmpi.so.40 is not found?

### Assistant: Try removing .conda, .cache, and .local folders from your home directory and rebuild the container.
    "
"
### Context: 
Megatron-DeepSpeed

We describe below the instructions for launching distributed training with
Microsoft's Megatron-DeepSpeed and briefly describe some parallelism
strategies and various optimizations that are supported.

!!! note

Setup

Load conda and activate base environment:
```bash
load conda + activate base env
module load conda/2023-10-04 ; conda activate base
```

Clone
   argonne-lcf/Megatron-DeepSpeed
   and navigate into it:
```bash
clone + navigate into Megatron-DeepSpeed repo
git clone https://github.com/argonne-lcf/Megatron-DeepSpeed
cd Megatron-DeepSpeed
```

Make virtual environment (on top of base conda):
```bash
make virtual environment (on top of base conda)
mkdir -p venvs/polaris/2023-10-04
python3 -m venv venvs/polaris/2023-10-04 --system-site-packages
source venvs/polaris/2023-10-04/bin/activate
```

Install missing dependency:
```bash
install *missing dependency
python3 -m pip install ""git+https://github.com/saforem2/ezpz""
```

Launch training:
```bash
---- launch training -----------------------
- MODEL_SIZE_KEY: defined in ALCF/model.sh
- other args: defined in ALCF/args.sh
---------------------------------------------
MODEL_SIZE_KEY=""GPT25B"" \
    SEQ_LEN=4096 \ 
    USE_FLASH_ATTN_V2=1 \
    MICRO_BATCH=1 \
    GAS=1 \
    SP_TYPE=""megatron"" \
    ZERO_STAGE=1 \
    ./ALCF/train-gpt3.sh
```

Helper Scripts

ALCF/train-gpt3.sh

:   Main entry point for training. This script will automatically source the
    rest of the required ALCF/*.sh scripts below

ALCF/model.sh

:   Contains some example model architectures for GPT3-style models

ALCF/args.sh

:   Logic for parsing / setting up runtime options for Megatron and DeepSpeed.

ALCF/setup.sh

:   Locate and activate virtual environment to be used, ensure MPI
    variables are set properly

ALCF/launch.sh

### Human: What is the main entry point for training with Megatron-DeepSpeed?

### Assistant: The main entry point for training with Megatron-DeepSpeed is `ALCF/train-gpt3.sh`.
    "
"
### Context: 
Megatron-DeepSpeed

We describe below the instructions for launching distributed training with
Microsoft's Megatron-DeepSpeed and briefly describe some parallelism
strategies and various optimizations that are supported.

!!! note

Setup

Load conda and activate base environment:
```bash
load conda + activate base env
module load conda/2023-10-04 ; conda activate base
```

Clone
   argonne-lcf/Megatron-DeepSpeed
   and navigate into it:
```bash
clone + navigate into Megatron-DeepSpeed repo
git clone https://github.com/argonne-lcf/Megatron-DeepSpeed
cd Megatron-DeepSpeed
```

Make virtual environment (on top of base conda):
```bash
make virtual environment (on top of base conda)
mkdir -p venvs/polaris/2023-10-04
python3 -m venv venvs/polaris/2023-10-04 --system-site-packages
source venvs/polaris/2023-10-04/bin/activate
```

Install missing dependency:
```bash
install *missing dependency
python3 -m pip install ""git+https://github.com/saforem2/ezpz""
```

Launch training:
```bash
---- launch training -----------------------
- MODEL_SIZE_KEY: defined in ALCF/model.sh
- other args: defined in ALCF/args.sh
---------------------------------------------
MODEL_SIZE_KEY=""GPT25B"" \
    SEQ_LEN=4096 \ 
    USE_FLASH_ATTN_V2=1 \
    MICRO_BATCH=1 \
    GAS=1 \
    SP_TYPE=""megatron"" \
    ZERO_STAGE=1 \
    ./ALCF/train-gpt3.sh
```

Helper Scripts

ALCF/train-gpt3.sh

:   Main entry point for training. This script will automatically source the
    rest of the required ALCF/*.sh scripts below

ALCF/model.sh

:   Contains some example model architectures for GPT3-style models

ALCF/args.sh

:   Logic for parsing / setting up runtime options for Megatron and DeepSpeed.

ALCF/setup.sh

:   Locate and activate virtual environment to be used, ensure MPI
    variables are set properly

ALCF/launch.sh

### Human: How do I install the missing dependency required by ALCF's scripts?

### Assistant: $python3 -m pip install ""git+https://github.com/saforem2/ezpz""
    "
"
### Context: 
Megatron-DeepSpeed

We describe below the instructions for launching distributed training with
Microsoft's Megatron-DeepSpeed and briefly describe some parallelism
strategies and various optimizations that are supported.

!!! note

Setup

Load conda and activate base environment:
```bash
load conda + activate base env
module load conda/2023-10-04 ; conda activate base
```

Clone
   argonne-lcf/Megatron-DeepSpeed
   and navigate into it:
```bash
clone + navigate into Megatron-DeepSpeed repo
git clone https://github.com/argonne-lcf/Megatron-DeepSpeed
cd Megatron-DeepSpeed
```

Make virtual environment (on top of base conda):
```bash
make virtual environment (on top of base conda)
mkdir -p venvs/polaris/2023-10-04
python3 -m venv venvs/polaris/2023-10-04 --system-site-packages
source venvs/polaris/2023-10-04/bin/activate
```

Install missing dependency:
```bash
install *missing dependency
python3 -m pip install ""git+https://github.com/saforem2/ezpz""
```

Launch training:
```bash
---- launch training -----------------------
- MODEL_SIZE_KEY: defined in ALCF/model.sh
- other args: defined in ALCF/args.sh
---------------------------------------------
MODEL_SIZE_KEY=""GPT25B"" \
    SEQ_LEN=4096 \ 
    USE_FLASH_ATTN_V2=1 \
    MICRO_BATCH=1 \
    GAS=1 \
    SP_TYPE=""megatron"" \
    ZERO_STAGE=1 \
    ./ALCF/train-gpt3.sh
```

Helper Scripts

ALCF/train-gpt3.sh

:   Main entry point for training. This script will automatically source the
    rest of the required ALCF/*.sh scripts below

ALCF/model.sh

:   Contains some example model architectures for GPT3-style models

ALCF/args.sh

:   Logic for parsing / setting up runtime options for Megatron and DeepSpeed.

ALCF/setup.sh

:   Locate and activate virtual environment to be used, ensure MPI
    variables are set properly

ALCF/launch.sh

### Human: What is the purpose of the `MODEL_SIZE_KEY` variable in the ALCF/train-gpt3.sh script?

### Assistant: The purpose of the `MODEL_SIZE_KEY` variable is to specify the size of the model architecture.
    "
"
### Context: 
ALCF/launch.sh

:   Identify available resources and build the command to be ran i.e.
    figure out how many: {nodes, GPUs per node, GPUs total}, to pass to
    mpi{run,exec} then, use this to build  mpiexec <mpiexec-args> python3
    pretrain_gpt.py

### Human: What is the purpose of the `launch.sh` script in ALCF?

### Assistant: The purpose of the `launch.sh` script in ALCF is to identify available resources and build a command to run using `mpiexec`, which executes the `pretrain_gpt.py` script.
    "
"
### Context: 
ALCF/launch.sh

:   Identify available resources and build the command to be ran i.e.
    figure out how many: {nodes, GPUs per node, GPUs total}, to pass to
    mpi{run,exec} then, use this to build  mpiexec <mpiexec-args> python3
    pretrain_gpt.py

### Human: How many nodes are required to run the `pretrain_gpt.py` script using ALCF's resources?

### Assistant: The number of nodes required to run the `pretrain_gpt.py` script using ALCF's resources is unknown without specific information about the available resources.

Note that this answer does not provide a specific value for the number of nodes, as it depends on the actual availability of resources.
    "
"
### Context: 
ALCF/launch.sh

:   Identify available resources and build the command to be ran i.e.
    figure out how many: {nodes, GPUs per node, GPUs total}, to pass to
    mpi{run,exec} then, use this to build  mpiexec <mpiexec-args> python3
    pretrain_gpt.py

### Human: What is the name of the Python script that needs to be run using the `launch.sh` command in ALCF?

### Assistant: pretrain_gpt.py
    "
"
### Context: 
VASP

What is VASP?

The Vienna Ab initio Simulation Package (VASP) is a software package for performing electronic structure calculations with periodic boundary conditions. It is most commonly used that to perform density functional theory (DFT) calculations in a planewave basis using the projector augemented wave (PAW) method. A more complete description of VASP can be found here:
https://www.vasp.at

Using VASP at ALCF

VASP is commercial software. Access to binaries compiled by ALCF can only be accessed after the user requesting access has been verified to be on the VASP license by an official VASP license distributor.

To access the VASP binary at ALCF, please email the details listed directly below to support@alcf.anl.gov. It can take up to 5 - 10 business days to verify a VASP license.

Information to provide:
- User’s full name:
- User’s ALCF username:
- Name of organization that purchased the VASP license:
- Principal investigator who is the POC for the VASP license:
- VASP license number:
- Version of VASP requested (VASP5, VASP6):

VASP support policy

ALCF compiles the latest release of VASP on a per request basis. We do not offer support for compiling customized versions of VASP with plugins. We are able to provide Makefiles and step-by-step build instructions to users with a verified VASP license. 
Support for scientific runs that encounter performance or numerical issues should be directed to the official VASP support mailing list or the VASP user forum. Limited support is available for fatal errors encountered at run time.

How to obtain the code

The VASP souce can only be obtained by an official license reseller of VASP. This is either the University of Vienna or Material Designs, Inc.

VASP 6.x.x in Polaris (NVHPC+OpenACC+OpenMP+CUDA math+CrayMPI)

General compiling/installing instructions provided by VASP support

Instructions and samples of makefile.include could be found in the vasp.at wiki page.

### Human: What is the purpose of the Vienna Ab initio Simulation Package (VASP)?

### Assistant: The purpose of the Vienna Ab initio Simulation Package (VASP) is to perform electronic structure calculations with periodic boundary conditions, including density functional theory (DFT) calculations in a plane-wave basis using the projector augmented wave (PAW) method.
    "
"
### Context: 
VASP

What is VASP?

The Vienna Ab initio Simulation Package (VASP) is a software package for performing electronic structure calculations with periodic boundary conditions. It is most commonly used that to perform density functional theory (DFT) calculations in a planewave basis using the projector augemented wave (PAW) method. A more complete description of VASP can be found here:
https://www.vasp.at

Using VASP at ALCF

VASP is commercial software. Access to binaries compiled by ALCF can only be accessed after the user requesting access has been verified to be on the VASP license by an official VASP license distributor.

To access the VASP binary at ALCF, please email the details listed directly below to support@alcf.anl.gov. It can take up to 5 - 10 business days to verify a VASP license.

Information to provide:
- User’s full name:
- User’s ALCF username:
- Name of organization that purchased the VASP license:
- Principal investigator who is the POC for the VASP license:
- VASP license number:
- Version of VASP requested (VASP5, VASP6):

VASP support policy

ALCF compiles the latest release of VASP on a per request basis. We do not offer support for compiling customized versions of VASP with plugins. We are able to provide Makefiles and step-by-step build instructions to users with a verified VASP license. 
Support for scientific runs that encounter performance or numerical issues should be directed to the official VASP support mailing list or the VASP user forum. Limited support is available for fatal errors encountered at run time.

How to obtain the code

The VASP souce can only be obtained by an official license reseller of VASP. This is either the University of Vienna or Material Designs, Inc.

VASP 6.x.x in Polaris (NVHPC+OpenACC+OpenMP+CUDA math+CrayMPI)

General compiling/installing instructions provided by VASP support

Instructions and samples of makefile.include could be found in the vasp.at wiki page.

### Human: How do I access the VASP binary at ALCF?

### Assistant: To access the VASP binary at ALCF, email the required information (user's full name, ALCF username, organization that purchased the VASP license, principal investigator who is the POC for the VASP license, VASP license number, and version of VASP requested) to support@alcf.anl.gov.
    "
"
### Context: 
VASP

What is VASP?

The Vienna Ab initio Simulation Package (VASP) is a software package for performing electronic structure calculations with periodic boundary conditions. It is most commonly used that to perform density functional theory (DFT) calculations in a planewave basis using the projector augemented wave (PAW) method. A more complete description of VASP can be found here:
https://www.vasp.at

Using VASP at ALCF

VASP is commercial software. Access to binaries compiled by ALCF can only be accessed after the user requesting access has been verified to be on the VASP license by an official VASP license distributor.

To access the VASP binary at ALCF, please email the details listed directly below to support@alcf.anl.gov. It can take up to 5 - 10 business days to verify a VASP license.

Information to provide:
- User’s full name:
- User’s ALCF username:
- Name of organization that purchased the VASP license:
- Principal investigator who is the POC for the VASP license:
- VASP license number:
- Version of VASP requested (VASP5, VASP6):

VASP support policy

ALCF compiles the latest release of VASP on a per request basis. We do not offer support for compiling customized versions of VASP with plugins. We are able to provide Makefiles and step-by-step build instructions to users with a verified VASP license. 
Support for scientific runs that encounter performance or numerical issues should be directed to the official VASP support mailing list or the VASP user forum. Limited support is available for fatal errors encountered at run time.

How to obtain the code

The VASP souce can only be obtained by an official license reseller of VASP. This is either the University of Vienna or Material Designs, Inc.

VASP 6.x.x in Polaris (NVHPC+OpenACC+OpenMP+CUDA math+CrayMPI)

General compiling/installing instructions provided by VASP support

Instructions and samples of makefile.include could be found in the vasp.at wiki page.

### Human: Where can I obtain the source code for VASP?

### Assistant: You can obtain the source code for VASP by contacting one of the official license resellers, either the University of Vienna or Material Designs, Inc.
    "
"
### Context: 
Instructions and samples of makefile.include could be found in the vasp.at wiki page.

The follow makefile.include was tailored for Polaris, originally taken from here.

```makefile

Precompiler options

CPP_OPTIONS = -DHOST=\""LinuxNV\"" \
              -DMPI -DMPI_BLOCK=8000 -Duse_collective \
              -DscaLAPACK \
              -DCACHE_SIZE=4000 \
              -Davoidalloc \
              -Dvasp6 \
              -Duse_bse_te \
              -Dtbdyn \
              -Dqd_emulate \
              -Dfock_dblbuf \
              -D_OPENMP \
              -D_OPENACC \
              -DUSENCCL -DUSENCCLP2P\

CPP        = nvfortran -Mpreprocess -Mfree -Mextend -E $(CPP_OPTIONS) $$(FUFFIX)  > $$(SUFFIX)

FC         = ftn -acc -gpu=cc80 -mp -target-accel=nvidia80
FCL        = ftn -acc -gpu=cc80 -c++libs -target-accel=nvidia80

FREE       = -Mfree

FFLAGS     = -Mbackslash -Mlarge_arrays

OFLAG      = -fast

DEBUG      = -Mfree -O0 -traceback

Specify your NV HPC-SDK installation, try to set NVROOT automatically

NVROOT     =$(shell which nvfortran | awk -F /compilers/bin/nvfortran '{ print $$1 }')

...or set NVROOT manually

NVHPC      ?= /opt/nvidia/hpc_sdk
NVVERSION  = 23.9
NVROOT     = $(NVHPC)/Linux_x86_64/$(NVVERSION)

Use NV HPC-SDK provided BLAS and LAPACK libraries

LIBAOCL=/soft/libraries/aocl/3.2.0
BLAS       = /soft/applications/vasp/aol-libs/3.2/amd-blis/lib/LP64/libblis-mt.a
LAPACK     = /soft/applications/vasp/aol-libs/3.2/amd-libflame/lib/LP64/libflame.a

BLACS      =
SCALAPACK  =

SCALAPACK  = -Mscalapack

SCALAPACK  = ${LIBAOCL}/lib/libscalapack.a

CUDA       = -cudalib=cublas,cusolver,cufft,nccl -cuda

LLIBS      = $(SCALAPACK) $(LAPACK) $(BLAS) $(CUDA)

Software emulation of quadruple precsion

QD         ?= $(NVROOT)/compilers/extras/qd
LLIBS      += -L$(QD)/lib -lqdmod -lqd
INCS       += -I$(QD)/include/qd

INCS       += -I/usr/include/linux

INCS       += -I/usr/include/c++/7/tr1

INCS       += -I/usr/include/c++/7

### Human: What is the purpose of the `CPP_OPTIONS` variable in this makefile?

### Assistant: The purpose of the `CPP_OPTIONS` variable is to customize the compilation process for VASP on a Linux system with an NVIDIA GPU, enabling features such as MPI, SCALAPACK, and parallelization using OpenMP and OpenACC.
    "
"
### Context: 
Instructions and samples of makefile.include could be found in the vasp.at wiki page.

The follow makefile.include was tailored for Polaris, originally taken from here.

```makefile

Precompiler options

CPP_OPTIONS = -DHOST=\""LinuxNV\"" \
              -DMPI -DMPI_BLOCK=8000 -Duse_collective \
              -DscaLAPACK \
              -DCACHE_SIZE=4000 \
              -Davoidalloc \
              -Dvasp6 \
              -Duse_bse_te \
              -Dtbdyn \
              -Dqd_emulate \
              -Dfock_dblbuf \
              -D_OPENMP \
              -D_OPENACC \
              -DUSENCCL -DUSENCCLP2P\

CPP        = nvfortran -Mpreprocess -Mfree -Mextend -E $(CPP_OPTIONS) $$(FUFFIX)  > $$(SUFFIX)

FC         = ftn -acc -gpu=cc80 -mp -target-accel=nvidia80
FCL        = ftn -acc -gpu=cc80 -c++libs -target-accel=nvidia80

FREE       = -Mfree

FFLAGS     = -Mbackslash -Mlarge_arrays

OFLAG      = -fast

DEBUG      = -Mfree -O0 -traceback

Specify your NV HPC-SDK installation, try to set NVROOT automatically

NVROOT     =$(shell which nvfortran | awk -F /compilers/bin/nvfortran '{ print $$1 }')

...or set NVROOT manually

NVHPC      ?= /opt/nvidia/hpc_sdk
NVVERSION  = 23.9
NVROOT     = $(NVHPC)/Linux_x86_64/$(NVVERSION)

Use NV HPC-SDK provided BLAS and LAPACK libraries

LIBAOCL=/soft/libraries/aocl/3.2.0
BLAS       = /soft/applications/vasp/aol-libs/3.2/amd-blis/lib/LP64/libblis-mt.a
LAPACK     = /soft/applications/vasp/aol-libs/3.2/amd-libflame/lib/LP64/libflame.a

BLACS      =
SCALAPACK  =

SCALAPACK  = -Mscalapack

SCALAPACK  = ${LIBAOCL}/lib/libscalapack.a

CUDA       = -cudalib=cublas,cusolver,cufft,nccl -cuda

LLIBS      = $(SCALAPACK) $(LAPACK) $(BLAS) $(CUDA)

Software emulation of quadruple precsion

QD         ?= $(NVROOT)/compilers/extras/qd
LLIBS      += -L$(QD)/lib -lqdmod -lqd
INCS       += -I$(QD)/include/qd

INCS       += -I/usr/include/linux

INCS       += -I/usr/include/c++/7/tr1

INCS       += -I/usr/include/c++/7

### Human: How does the `FC` compiler flag specify the target accelerator for compiling VASP codes?

### Assistant: The `FC` compiler flag specifies the target accelerator for compiling VASP codes by using the `-target-accel` option with the value `nvidia80`.
    "
"
### Context: 
Instructions and samples of makefile.include could be found in the vasp.at wiki page.

The follow makefile.include was tailored for Polaris, originally taken from here.

```makefile

Precompiler options

CPP_OPTIONS = -DHOST=\""LinuxNV\"" \
              -DMPI -DMPI_BLOCK=8000 -Duse_collective \
              -DscaLAPACK \
              -DCACHE_SIZE=4000 \
              -Davoidalloc \
              -Dvasp6 \
              -Duse_bse_te \
              -Dtbdyn \
              -Dqd_emulate \
              -Dfock_dblbuf \
              -D_OPENMP \
              -D_OPENACC \
              -DUSENCCL -DUSENCCLP2P\

CPP        = nvfortran -Mpreprocess -Mfree -Mextend -E $(CPP_OPTIONS) $$(FUFFIX)  > $$(SUFFIX)

FC         = ftn -acc -gpu=cc80 -mp -target-accel=nvidia80
FCL        = ftn -acc -gpu=cc80 -c++libs -target-accel=nvidia80

FREE       = -Mfree

FFLAGS     = -Mbackslash -Mlarge_arrays

OFLAG      = -fast

DEBUG      = -Mfree -O0 -traceback

Specify your NV HPC-SDK installation, try to set NVROOT automatically

NVROOT     =$(shell which nvfortran | awk -F /compilers/bin/nvfortran '{ print $$1 }')

...or set NVROOT manually

NVHPC      ?= /opt/nvidia/hpc_sdk
NVVERSION  = 23.9
NVROOT     = $(NVHPC)/Linux_x86_64/$(NVVERSION)

Use NV HPC-SDK provided BLAS and LAPACK libraries

LIBAOCL=/soft/libraries/aocl/3.2.0
BLAS       = /soft/applications/vasp/aol-libs/3.2/amd-blis/lib/LP64/libblis-mt.a
LAPACK     = /soft/applications/vasp/aol-libs/3.2/amd-libflame/lib/LP64/libflame.a

BLACS      =
SCALAPACK  =

SCALAPACK  = -Mscalapack

SCALAPACK  = ${LIBAOCL}/lib/libscalapack.a

CUDA       = -cudalib=cublas,cusolver,cufft,nccl -cuda

LLIBS      = $(SCALAPACK) $(LAPACK) $(BLAS) $(CUDA)

Software emulation of quadruple precsion

QD         ?= $(NVROOT)/compilers/extras/qd
LLIBS      += -L$(QD)/lib -lqdmod -lqd
INCS       += -I$(QD)/include/qd

INCS       += -I/usr/include/linux

INCS       += -I/usr/include/c++/7/tr1

INCS       += -I/usr/include/c++/7

### Human: What is the role of the `NVROOT` variable in setting the installation path for the NV HPC-SDK?

### Assistant: The role of the `NVROOT` variable in setting the installation path for the NV HPC-SDK is to specify either the automatically detected or manually specified installation path.
    "
"
### Context: 
INCS       += -I/usr/include/c++/7/tr1

INCS       += -I/usr/include/c++/7

INCS       += -I/usr/include/x86_64-linux-gnu/c++/7

INCS       += -I/lus/theta-fs0/software/spack/spack-dev/opt/spack/linux-sles15-x86_64/gcc-9.3.0/gcc-10.2.0-r7v3naxd5xgzzaqxoe73jj2ytwuddamr/lib/gcc/x86_64-pc-linux-gnu/10.2.0/include/

Use the FFTs from fftw

FFTW       = /soft/applications/vasp/aol-libs/3.2/amd-fftw
LLIBS      += -L$(FFTW)/lib -lfftw3 -lfftw3_omp -lomp

INCS       += -I/soft/libraries/aocl/3.2.0/include_LP64/

INCS       += -I$(FFTW)/include

OBJECTS    = fftmpiw.o fftmpi_map.o fftw3d.o fft3dlib.o

Redefine the standard list of O1 and O2 objects

SOURCE_O1  := pade_fit.o
SOURCE_O2  := pead.o

For what used to be vasp.5.lib

CPP_LIB    = $(CPP)
FC_LIB     = nvfortran
CC_LIB     = cc
CFLAGS_LIB = -O $(INCS) -c++libs -cuda
FFLAGS_LIB = -O1 -Mfixed
FREE_LIB   = $(FREE)

OBJECTS_LIB= linpack_double.o getshmem.o

For the parser library

CXX_PARS   = nvc++ --no_warnings -I/lus/theta-fs0/software/spack/spack-dev/opt/spack/linux-sles15-x86_64/gcc-9.3.0/gcc-10.2.0-r7v3naxd5xgzzaqxoe73jj2ytwuddamr/include/c++/10.2.0/ -I/lus/theta-fs0/software/spack/spack-dev/opt/spack/linux-sles15-x86_64/gcc-9.3.0/gcc-10.2.0-r7v3nax

d5xgzzaqxoe73jj2ytwuddamr/include/c++/10.2.0/x86_64-pc-linux-gnu -I/lus/theta-fs0/software/spack/spack-dev/opt/spack/linux-sles15-x86_64/gcc-9.3.0/gcc-10.2.0-r7v3naxd5xgzzaqxoe73jj2ytwuddamr/lib/gcc/x86_64-pc-linux-gnu/10.2.0/include -I/lus/theta-fs0/software/spack/spack-dev/opt/
spack/linux-sles15-x86_64/gcc-9.3.0/gcc-10.2.0-r7v3naxd5xgzzaqxoe73jj2ytwuddamr/lib/gcc/x86_64-pc-linux-gnu/10.2.0/include-fixed/
CXX_PARS   = nvc++ --no_warnings

Normally no need to change this

SRCDIR     = ../../src
BINDIR     = ../../bin
```

Setting up compiler and libraries with module

The follow modules will update the include and libraries paths used by the Cray compiler wrapper ftn to load additional math libraries for the CPU.

### Human: What is the purpose of setting up the compiler and libraries with a module?

### Assistant: The purpose of setting up the compiler and libraries with a module is to load additional math libraries for the CPU.
    "
"
### Context: 
INCS       += -I/usr/include/c++/7/tr1

INCS       += -I/usr/include/c++/7

INCS       += -I/usr/include/x86_64-linux-gnu/c++/7

INCS       += -I/lus/theta-fs0/software/spack/spack-dev/opt/spack/linux-sles15-x86_64/gcc-9.3.0/gcc-10.2.0-r7v3naxd5xgzzaqxoe73jj2ytwuddamr/lib/gcc/x86_64-pc-linux-gnu/10.2.0/include/

Use the FFTs from fftw

FFTW       = /soft/applications/vasp/aol-libs/3.2/amd-fftw
LLIBS      += -L$(FFTW)/lib -lfftw3 -lfftw3_omp -lomp

INCS       += -I/soft/libraries/aocl/3.2.0/include_LP64/

INCS       += -I$(FFTW)/include

OBJECTS    = fftmpiw.o fftmpi_map.o fftw3d.o fft3dlib.o

Redefine the standard list of O1 and O2 objects

SOURCE_O1  := pade_fit.o
SOURCE_O2  := pead.o

For what used to be vasp.5.lib

CPP_LIB    = $(CPP)
FC_LIB     = nvfortran
CC_LIB     = cc
CFLAGS_LIB = -O $(INCS) -c++libs -cuda
FFLAGS_LIB = -O1 -Mfixed
FREE_LIB   = $(FREE)

OBJECTS_LIB= linpack_double.o getshmem.o

For the parser library

CXX_PARS   = nvc++ --no_warnings -I/lus/theta-fs0/software/spack/spack-dev/opt/spack/linux-sles15-x86_64/gcc-9.3.0/gcc-10.2.0-r7v3naxd5xgzzaqxoe73jj2ytwuddamr/include/c++/10.2.0/ -I/lus/theta-fs0/software/spack/spack-dev/opt/spack/linux-sles15-x86_64/gcc-9.3.0/gcc-10.2.0-r7v3nax

d5xgzzaqxoe73jj2ytwuddamr/include/c++/10.2.0/x86_64-pc-linux-gnu -I/lus/theta-fs0/software/spack/spack-dev/opt/spack/linux-sles15-x86_64/gcc-9.3.0/gcc-10.2.0-r7v3naxd5xgzzaqxoe73jj2ytwuddamr/lib/gcc/x86_64-pc-linux-gnu/10.2.0/include -I/lus/theta-fs0/software/spack/spack-dev/opt/
spack/linux-sles15-x86_64/gcc-9.3.0/gcc-10.2.0-r7v3naxd5xgzzaqxoe73jj2ytwuddamr/lib/gcc/x86_64-pc-linux-gnu/10.2.0/include-fixed/
CXX_PARS   = nvc++ --no_warnings

Normally no need to change this

SRCDIR     = ../../src
BINDIR     = ../../bin
```

Setting up compiler and libraries with module

The follow modules will update the include and libraries paths used by the Cray compiler wrapper ftn to load additional math libraries for the CPU.

### Human: How do modules update the include and library paths used by the Cray compiler wrapper ftn to load additional math libraries for the CPU?

### Assistant: To update the include and library paths used by the Cray compiler wrapper ftn, we can add more lines to the `INCS` and `LLIBS` variables.
    "
"
### Context: 
INCS       += -I/usr/include/c++/7/tr1

INCS       += -I/usr/include/c++/7

INCS       += -I/usr/include/x86_64-linux-gnu/c++/7

INCS       += -I/lus/theta-fs0/software/spack/spack-dev/opt/spack/linux-sles15-x86_64/gcc-9.3.0/gcc-10.2.0-r7v3naxd5xgzzaqxoe73jj2ytwuddamr/lib/gcc/x86_64-pc-linux-gnu/10.2.0/include/

Use the FFTs from fftw

FFTW       = /soft/applications/vasp/aol-libs/3.2/amd-fftw
LLIBS      += -L$(FFTW)/lib -lfftw3 -lfftw3_omp -lomp

INCS       += -I/soft/libraries/aocl/3.2.0/include_LP64/

INCS       += -I$(FFTW)/include

OBJECTS    = fftmpiw.o fftmpi_map.o fftw3d.o fft3dlib.o

Redefine the standard list of O1 and O2 objects

SOURCE_O1  := pade_fit.o
SOURCE_O2  := pead.o

For what used to be vasp.5.lib

CPP_LIB    = $(CPP)
FC_LIB     = nvfortran
CC_LIB     = cc
CFLAGS_LIB = -O $(INCS) -c++libs -cuda
FFLAGS_LIB = -O1 -Mfixed
FREE_LIB   = $(FREE)

OBJECTS_LIB= linpack_double.o getshmem.o

For the parser library

CXX_PARS   = nvc++ --no_warnings -I/lus/theta-fs0/software/spack/spack-dev/opt/spack/linux-sles15-x86_64/gcc-9.3.0/gcc-10.2.0-r7v3naxd5xgzzaqxoe73jj2ytwuddamr/include/c++/10.2.0/ -I/lus/theta-fs0/software/spack/spack-dev/opt/spack/linux-sles15-x86_64/gcc-9.3.0/gcc-10.2.0-r7v3nax

d5xgzzaqxoe73jj2ytwuddamr/include/c++/10.2.0/x86_64-pc-linux-gnu -I/lus/theta-fs0/software/spack/spack-dev/opt/spack/linux-sles15-x86_64/gcc-9.3.0/gcc-10.2.0-r7v3naxd5xgzzaqxoe73jj2ytwuddamr/lib/gcc/x86_64-pc-linux-gnu/10.2.0/include -I/lus/theta-fs0/software/spack/spack-dev/opt/
spack/linux-sles15-x86_64/gcc-9.3.0/gcc-10.2.0-r7v3naxd5xgzzaqxoe73jj2ytwuddamr/lib/gcc/x86_64-pc-linux-gnu/10.2.0/include-fixed/
CXX_PARS   = nvc++ --no_warnings

Normally no need to change this

SRCDIR     = ../../src
BINDIR     = ../../bin
```

Setting up compiler and libraries with module

The follow modules will update the include and libraries paths used by the Cray compiler wrapper ftn to load additional math libraries for the CPU.

### Human: Can you explain the significance of using `nvc++ --no_warnings` in the CXX_PARS variable?

### Assistant: The significance of using `nvc++ --no_warnings` in CXX_PARS is that it suppresses warning messages while compiling, making it easier to focus on actual errors or issues.
    "
"
### Context: 
```
module restore
module load PrgEnv-nvhpc
module load cray-libsci
module load craype-accel-nvidia80
export NVROOT=${NVIDIA_PATH}
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$NVROOT/compilers/extras/qd/lib
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soft/applications/vasp/aol-libs/3.2/amd-blis/lib/ILP64/
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soft/applications/vasp/aol-libs/3.2/amd-libflame/lib/ILP64/
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soft/applications/vasp/aol-libs/3.2/amd-fftw/lib

```

Compiling VASP

Once the modules are loaded and a makefile.include is in the vasp folder, compiling all the object files and binaries is done with:

make -j1

Running VASP in Polaris

An example of a submission script could be found here /soft/applications/vasp/script.sh , which would looks something similar to:

``` example-script.sh

!/bin/sh

!/bin/sh

PBS -l select=1:system=polaris

PBS -l place=scatter

PBS -l walltime=0:30:00

PBS -l filesystems=home:grand:eagle

PBS -q debug

PBS -A MYPROJECT

module load PrgEnv-nvhpc
module load cray-libsci
module load craype-accel-nvidia80

NVROOT=${NVIDIA_PATH}

export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$NVROOT/compilers/extras/qd/lib
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soft/applications/vasp/aol-libs/3.2/amd-blis/lib/ILP64/
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soft/applications/vasp/aol-libs/3.2/amd-libflame/lib/ILP64/
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soft/applications/vasp/aol-libs/3.2/amd-fftw/lib

export MPICH_GPU_SUPPORT_ENABLED=1
NNODES=wc -l < $PBS_NODEFILE
NRANKS=2
NDEPTH=4
NTHREADS=4
NGPUS=2
NTOTRANKS=$(( NNODES * NRANKS ))

Provide full path to VASP binary

bin=/soft/applications/vasp/vasp.6.4.3/bin/vasp_std

cd $PBS_O_WORKDIR

mpiexec -n ${NTOTRANKS} --ppn ${NRANKS} --depth ${NDEPTH} --cpu-bind depth --env OMP_NUM_THREADS=${NTHREADS} $bin
```

Submission scripts should have executable attibutes to be used with qsub script mode.

chmod +x script.sh
qsub script.sh

### Human: What is required to compile VASP?

### Assistant: To compile VASP, you need to load the necessary modules and set environment variables, then run the `make` command with the `-j1` option.
    "
"
### Context: 
```
module restore
module load PrgEnv-nvhpc
module load cray-libsci
module load craype-accel-nvidia80
export NVROOT=${NVIDIA_PATH}
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$NVROOT/compilers/extras/qd/lib
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soft/applications/vasp/aol-libs/3.2/amd-blis/lib/ILP64/
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soft/applications/vasp/aol-libs/3.2/amd-libflame/lib/ILP64/
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soft/applications/vasp/aol-libs/3.2/amd-fftw/lib

```

Compiling VASP

Once the modules are loaded and a makefile.include is in the vasp folder, compiling all the object files and binaries is done with:

make -j1

Running VASP in Polaris

An example of a submission script could be found here /soft/applications/vasp/script.sh , which would looks something similar to:

``` example-script.sh

!/bin/sh

!/bin/sh

PBS -l select=1:system=polaris

PBS -l place=scatter

PBS -l walltime=0:30:00

PBS -l filesystems=home:grand:eagle

PBS -q debug

PBS -A MYPROJECT

module load PrgEnv-nvhpc
module load cray-libsci
module load craype-accel-nvidia80

NVROOT=${NVIDIA_PATH}

export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$NVROOT/compilers/extras/qd/lib
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soft/applications/vasp/aol-libs/3.2/amd-blis/lib/ILP64/
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soft/applications/vasp/aol-libs/3.2/amd-libflame/lib/ILP64/
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soft/applications/vasp/aol-libs/3.2/amd-fftw/lib

export MPICH_GPU_SUPPORT_ENABLED=1
NNODES=wc -l < $PBS_NODEFILE
NRANKS=2
NDEPTH=4
NTHREADS=4
NGPUS=2
NTOTRANKS=$(( NNODES * NRANKS ))

Provide full path to VASP binary

bin=/soft/applications/vasp/vasp.6.4.3/bin/vasp_std

cd $PBS_O_WORKDIR

mpiexec -n ${NTOTRANKS} --ppn ${NRANKS} --depth ${NDEPTH} --cpu-bind depth --env OMP_NUM_THREADS=${NTHREADS} $bin
```

Submission scripts should have executable attibutes to be used with qsub script mode.

chmod +x script.sh
qsub script.sh

### Human: How can you run VASP in Polaris?

### Assistant: Run VASP in Polaris by compiling it with `make -j1` and then submitting a job script that loads necessary modules, sets environment variables, and runs the VASP binary with `mpiexec`.
    "
"
### Context: 
```
module restore
module load PrgEnv-nvhpc
module load cray-libsci
module load craype-accel-nvidia80
export NVROOT=${NVIDIA_PATH}
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$NVROOT/compilers/extras/qd/lib
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soft/applications/vasp/aol-libs/3.2/amd-blis/lib/ILP64/
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soft/applications/vasp/aol-libs/3.2/amd-libflame/lib/ILP64/
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soft/applications/vasp/aol-libs/3.2/amd-fftw/lib

```

Compiling VASP

Once the modules are loaded and a makefile.include is in the vasp folder, compiling all the object files and binaries is done with:

make -j1

Running VASP in Polaris

An example of a submission script could be found here /soft/applications/vasp/script.sh , which would looks something similar to:

``` example-script.sh

!/bin/sh

!/bin/sh

PBS -l select=1:system=polaris

PBS -l place=scatter

PBS -l walltime=0:30:00

PBS -l filesystems=home:grand:eagle

PBS -q debug

PBS -A MYPROJECT

module load PrgEnv-nvhpc
module load cray-libsci
module load craype-accel-nvidia80

NVROOT=${NVIDIA_PATH}

export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$NVROOT/compilers/extras/qd/lib
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soft/applications/vasp/aol-libs/3.2/amd-blis/lib/ILP64/
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soft/applications/vasp/aol-libs/3.2/amd-libflame/lib/ILP64/
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soft/applications/vasp/aol-libs/3.2/amd-fftw/lib

export MPICH_GPU_SUPPORT_ENABLED=1
NNODES=wc -l < $PBS_NODEFILE
NRANKS=2
NDEPTH=4
NTHREADS=4
NGPUS=2
NTOTRANKS=$(( NNODES * NRANKS ))

Provide full path to VASP binary

bin=/soft/applications/vasp/vasp.6.4.3/bin/vasp_std

cd $PBS_O_WORKDIR

mpiexec -n ${NTOTRANKS} --ppn ${NRANKS} --depth ${NDEPTH} --cpu-bind depth --env OMP_NUM_THREADS=${NTHREADS} $bin
```

Submission scripts should have executable attibutes to be used with qsub script mode.

chmod +x script.sh
qsub script.sh

### Human: What are some of the environment variables that need to be set when running VASP on Polaris?

### Assistant: NVROOT and LD_LIBRARY_PATH
    "
"
### Context: 
Quantum ESPRESSO on Polaris

Quantum ESPRESSO is an integrated suite of Open-Source computer codes for electronic-structure calculations and materials modeling at the nanoscale. It is based on density-functional theory, plane waves, and pseudopotentials.

Prebuilt executables are provided at /soft/applications/quantum_espresso.
The directory of each installation also includes a job submission script example job.sub and a README file documenting the actual build recipe.
We only support building QE using CMake.

### Human: What is Quantum ESPRESSO used for?

### Assistant: Simulating and modeling the behavior of materials at a very small scale (nanoscale).
    "
"
### Context: 
Quantum ESPRESSO on Polaris

Quantum ESPRESSO is an integrated suite of Open-Source computer codes for electronic-structure calculations and materials modeling at the nanoscale. It is based on density-functional theory, plane waves, and pseudopotentials.

Prebuilt executables are provided at /soft/applications/quantum_espresso.
The directory of each installation also includes a job submission script example job.sub and a README file documenting the actual build recipe.
We only support building QE using CMake.

### Human: Can I build QE using CMake?

### Assistant: Yes, you can build QE using CMake.
    "
"
### Context: 
Quantum ESPRESSO on Polaris

Quantum ESPRESSO is an integrated suite of Open-Source computer codes for electronic-structure calculations and materials modeling at the nanoscale. It is based on density-functional theory, plane waves, and pseudopotentials.

Prebuilt executables are provided at /soft/applications/quantum_espresso.
The directory of each installation also includes a job submission script example job.sub and a README file documenting the actual build recipe.
We only support building QE using CMake.

### Human: Where can I find prebuilt executables for Quantum ESPRESSO?

### Assistant: The prebuilt executables for Quantum ESPRESSO can be found in the `/soft/applications/quantum_espresso` directory.
    "
"
### Context: 
Gromacs on Polaris

What is Gromacs?

GROMACS is a versatile package to perform molecular dynamics, i.e. simulate the Newtonian equations of motion for systems with hundreds to millions of particles. It is primarily designed for biochemical molecules like proteins, lipids, and nucleic acids that have a lot of complicated bonded interactions, but since GROMACS is extremely fast at calculating the nonbonded interactions (that usually dominate simulations) many groups are also using it for research on non-biological systems, e.g. polymers.

Using GROMACS at ALCF

ALCF offers assistance with building binaries and compiling instructions for GROMACS. For questions, contact us at support@alcf.anl.gov.

Building Gromacs

Download latest source code: http://manual.gromacs.org/documentation/2022.1/download.html

tar -xzf gromacs-2022.1.tar.gz

module swap PrgEnv-nvhpc PrgEnv-gnu

module load cudatoolkit-standalone/11.2.2

module load gcc/10.3.0

module load cmake

cd gromacs-2022.1

mkdir build

cmake -DCMAKE_C_COMPILER=cc -DCMAKE_CXX_COMPILER=CC \
      -DBUILD_SHARED_LIBS=OFF -DGMX_BUILD_OWN_FFTW=ON \
      -DCMAKE_INSTALL_PREFIX=/path-to/gromacs-2022.1/build \
      -DGMX_MPI=ON -DGMX_OPENMP=ON -DGMX_GPU=CUDA \
      -DCUDA_TOOLKIT_ROOT_DIR=/soft/compilers/cudatoolkit/cuda-11.2.2

make –j 8

make install

The installed binary is build/bin/gmx_mpi.

Running Gromacs on Polaris

Prebuilt Gromacs binaries can be found in the directory /soft/applications/Gromacs/gromacs-2022.1.

A sample pbs script follows that will run GROMACS on two nodes, using 4 MPI ranks per node, and each rank with four OpenMP threads. The PME kernel owns one MPI rank and one GPU per node, while the nonbonded kernel uses 3 MPI ranks and 3 GPUs per node.

```

!/bin/sh

PBS -l select=2:system=polaris

PBS -l place=scatter

PBS -l walltime=0:30:00

PBS -q debug

PBS -A PROJECT

PBS -l filesystems=home:grand:eagle

cd ${PBS_O_WORKDIR}

### Human: What is Gromacs used for?

### Assistant: GROMACS is used for molecular dynamics simulations, primarily designed for biochemical molecules like proteins, lipids, and nucleic acids.
    "
"
### Context: 
Gromacs on Polaris

What is Gromacs?

GROMACS is a versatile package to perform molecular dynamics, i.e. simulate the Newtonian equations of motion for systems with hundreds to millions of particles. It is primarily designed for biochemical molecules like proteins, lipids, and nucleic acids that have a lot of complicated bonded interactions, but since GROMACS is extremely fast at calculating the nonbonded interactions (that usually dominate simulations) many groups are also using it for research on non-biological systems, e.g. polymers.

Using GROMACS at ALCF

ALCF offers assistance with building binaries and compiling instructions for GROMACS. For questions, contact us at support@alcf.anl.gov.

Building Gromacs

Download latest source code: http://manual.gromacs.org/documentation/2022.1/download.html

tar -xzf gromacs-2022.1.tar.gz

module swap PrgEnv-nvhpc PrgEnv-gnu

module load cudatoolkit-standalone/11.2.2

module load gcc/10.3.0

module load cmake

cd gromacs-2022.1

mkdir build

cmake -DCMAKE_C_COMPILER=cc -DCMAKE_CXX_COMPILER=CC \
      -DBUILD_SHARED_LIBS=OFF -DGMX_BUILD_OWN_FFTW=ON \
      -DCMAKE_INSTALL_PREFIX=/path-to/gromacs-2022.1/build \
      -DGMX_MPI=ON -DGMX_OPENMP=ON -DGMX_GPU=CUDA \
      -DCUDA_TOOLKIT_ROOT_DIR=/soft/compilers/cudatoolkit/cuda-11.2.2

make –j 8

make install

The installed binary is build/bin/gmx_mpi.

Running Gromacs on Polaris

Prebuilt Gromacs binaries can be found in the directory /soft/applications/Gromacs/gromacs-2022.1.

A sample pbs script follows that will run GROMACS on two nodes, using 4 MPI ranks per node, and each rank with four OpenMP threads. The PME kernel owns one MPI rank and one GPU per node, while the nonbonded kernel uses 3 MPI ranks and 3 GPUs per node.

```

!/bin/sh

PBS -l select=2:system=polaris

PBS -l place=scatter

PBS -l walltime=0:30:00

PBS -q debug

PBS -A PROJECT

PBS -l filesystems=home:grand:eagle

cd ${PBS_O_WORKDIR}

### Human: How do I compile Gromacs?

### Assistant: Compile GROMACS by downloading the latest source code, loading necessary modules, creating a build directory, running CMake, compiling using `make`, and installing the binary.
    "
"
### Context: 
Gromacs on Polaris

What is Gromacs?

GROMACS is a versatile package to perform molecular dynamics, i.e. simulate the Newtonian equations of motion for systems with hundreds to millions of particles. It is primarily designed for biochemical molecules like proteins, lipids, and nucleic acids that have a lot of complicated bonded interactions, but since GROMACS is extremely fast at calculating the nonbonded interactions (that usually dominate simulations) many groups are also using it for research on non-biological systems, e.g. polymers.

Using GROMACS at ALCF

ALCF offers assistance with building binaries and compiling instructions for GROMACS. For questions, contact us at support@alcf.anl.gov.

Building Gromacs

Download latest source code: http://manual.gromacs.org/documentation/2022.1/download.html

tar -xzf gromacs-2022.1.tar.gz

module swap PrgEnv-nvhpc PrgEnv-gnu

module load cudatoolkit-standalone/11.2.2

module load gcc/10.3.0

module load cmake

cd gromacs-2022.1

mkdir build

cmake -DCMAKE_C_COMPILER=cc -DCMAKE_CXX_COMPILER=CC \
      -DBUILD_SHARED_LIBS=OFF -DGMX_BUILD_OWN_FFTW=ON \
      -DCMAKE_INSTALL_PREFIX=/path-to/gromacs-2022.1/build \
      -DGMX_MPI=ON -DGMX_OPENMP=ON -DGMX_GPU=CUDA \
      -DCUDA_TOOLKIT_ROOT_DIR=/soft/compilers/cudatoolkit/cuda-11.2.2

make –j 8

make install

The installed binary is build/bin/gmx_mpi.

Running Gromacs on Polaris

Prebuilt Gromacs binaries can be found in the directory /soft/applications/Gromacs/gromacs-2022.1.

A sample pbs script follows that will run GROMACS on two nodes, using 4 MPI ranks per node, and each rank with four OpenMP threads. The PME kernel owns one MPI rank and one GPU per node, while the nonbonded kernel uses 3 MPI ranks and 3 GPUs per node.

```

!/bin/sh

PBS -l select=2:system=polaris

PBS -l place=scatter

PBS -l walltime=0:30:00

PBS -q debug

PBS -A PROJECT

PBS -l filesystems=home:grand:eagle

cd ${PBS_O_WORKDIR}

### Human: Can Gromacs run on Polaris?

### Assistant: Yes, Gromacs can run on Polaris.
    "
"
### Context: 
PBS -q debug

PBS -A PROJECT

PBS -l filesystems=home:grand:eagle

cd ${PBS_O_WORKDIR}

module swap PrgEnv-nvhpc PrgEnv-gnu
module load cudatoolkit-standalone/11.2.2

export OMP_NUM_THREADS=4

mpirun --np 8 /soft/applications/Gromacs/gromacs-2022.1/gmx_mpi \
      mdrun -gputasks 0123 -nb gpu -pme gpu -npme 1 -ntomp 4 \
      -dlb yes -resethway -pin on -v deffnm step5_1 -g test.log
```

We strongly suggest that users try combinations of different numbers of nodes, MPI ranks per node, number of GPU tasks/devices, GPU task decomposition between nonbonded and PME kernels, and OMP threads per rank to find the optimal throughput for their particular workload.

### Human: What is the recommended way to optimize performance for a specific workload in Gromacs?

### Assistant: Try different numbers of nodes, MPI ranks per node, number of GPU tasks/devices, and OMP threads per rank to find the optimal throughput for your particular workload.
    "
"
### Context: 
PBS -q debug

PBS -A PROJECT

PBS -l filesystems=home:grand:eagle

cd ${PBS_O_WORKDIR}

module swap PrgEnv-nvhpc PrgEnv-gnu
module load cudatoolkit-standalone/11.2.2

export OMP_NUM_THREADS=4

mpirun --np 8 /soft/applications/Gromacs/gromacs-2022.1/gmx_mpi \
      mdrun -gputasks 0123 -nb gpu -pme gpu -npme 1 -ntomp 4 \
      -dlb yes -resethway -pin on -v deffnm step5_1 -g test.log
```

We strongly suggest that users try combinations of different numbers of nodes, MPI ranks per node, number of GPU tasks/devices, GPU task decomposition between nonbonded and PME kernels, and OMP threads per rank to find the optimal throughput for their particular workload.

### Human: How many nodes and MPI ranks per node do I need to try to find optimal throughput for my simulation?

### Assistant: Try 2-4 nodes with 4-8 MPI ranks per node.
    "
"
### Context: 
PBS -q debug

PBS -A PROJECT

PBS -l filesystems=home:grand:eagle

cd ${PBS_O_WORKDIR}

module swap PrgEnv-nvhpc PrgEnv-gnu
module load cudatoolkit-standalone/11.2.2

export OMP_NUM_THREADS=4

mpirun --np 8 /soft/applications/Gromacs/gromacs-2022.1/gmx_mpi \
      mdrun -gputasks 0123 -nb gpu -pme gpu -npme 1 -ntomp 4 \
      -dlb yes -resethway -pin on -v deffnm step5_1 -g test.log
```

We strongly suggest that users try combinations of different numbers of nodes, MPI ranks per node, number of GPU tasks/devices, GPU task decomposition between nonbonded and PME kernels, and OMP threads per rank to find the optimal throughput for their particular workload.

### Human: What is the purpose of using GPU tasks/devices with nonbonded and PME kernels in MDRUN?

### Assistant: The purpose is to accelerate specific parts of the simulation by offloading computationally intensive tasks to the GPUs.
    "
"
### Context: 
LAMMPS

Overview

LAMMPS is a general-purpose molecular dynamics software package for massively parallel computers. It is written in an exceptionally clean style that makes it one of the more popular codes for users to extend and it currently has dozens of user-developed extensions.

For details about the code and its usage, see the LAMMPS home page. This page provides information specific to running on Polaris at the ALCF.

Using LAMMPS at ALCF

ALCF provides assistance with build instructions, compiling executables, submitting jobs, and providing prebuilt binaries (upon request). A collection of Makefiles and submission scripts are available in the ALCF GettingStarted repo here. For questions, contact us at support@alcf.anl.gov.

How to Obtain the Code

LAMMPS is an open-source code, which can be downloaded from the LAMMPS website.

Building on Polaris

After LAMMPS has been downloaded and unpacked on an ALCF filesystem, users should see a directory whose name is of the form lammps-<version>. One should then see the Makefile lammps-<version>/src/MAKE/MACHINES/Makefile.polaris in recent versions that can be used as a starting point for compilation on Polaris. Copies of Makefiles for building with the GPU/KOKKOS package using CUDA for GPU support with the GNU/NVHPC compiler are available in the ALCF GettingStarted repo here. For older versions of LAMMPS, you may need to take an existing Makefile (e.g. Makefile.mpi) for your specific version of LAMMPS and edit the top portion appropratiately to create a new Makefile.polaris.

KOKKOS package and GNU compilers

The following modules are useful for this particular build. Note, the cmake module is not required if using the GNU Makefile procedure to build LAMMPS. The initial module restore is just setting the default environment as the starting point. Users may find it useful to copy these module commands into a small helper script to assist with compiling and running LAMMPS (e.g. setup_lammps_gnu.sh).

### Human: What is LAMMPS?

### Assistant: LAMMPS is a general-purpose molecular dynamics software package for massively parallel computers that can be downloaded from its website and built on systems like Polaris with the assistance of ALCF.
    "
"
### Context: 
LAMMPS

Overview

LAMMPS is a general-purpose molecular dynamics software package for massively parallel computers. It is written in an exceptionally clean style that makes it one of the more popular codes for users to extend and it currently has dozens of user-developed extensions.

For details about the code and its usage, see the LAMMPS home page. This page provides information specific to running on Polaris at the ALCF.

Using LAMMPS at ALCF

ALCF provides assistance with build instructions, compiling executables, submitting jobs, and providing prebuilt binaries (upon request). A collection of Makefiles and submission scripts are available in the ALCF GettingStarted repo here. For questions, contact us at support@alcf.anl.gov.

How to Obtain the Code

LAMMPS is an open-source code, which can be downloaded from the LAMMPS website.

Building on Polaris

After LAMMPS has been downloaded and unpacked on an ALCF filesystem, users should see a directory whose name is of the form lammps-<version>. One should then see the Makefile lammps-<version>/src/MAKE/MACHINES/Makefile.polaris in recent versions that can be used as a starting point for compilation on Polaris. Copies of Makefiles for building with the GPU/KOKKOS package using CUDA for GPU support with the GNU/NVHPC compiler are available in the ALCF GettingStarted repo here. For older versions of LAMMPS, you may need to take an existing Makefile (e.g. Makefile.mpi) for your specific version of LAMMPS and edit the top portion appropratiately to create a new Makefile.polaris.

KOKKOS package and GNU compilers

The following modules are useful for this particular build. Note, the cmake module is not required if using the GNU Makefile procedure to build LAMMPS. The initial module restore is just setting the default environment as the starting point. Users may find it useful to copy these module commands into a small helper script to assist with compiling and running LAMMPS (e.g. setup_lammps_gnu.sh).

### Human: How do I obtain the LAMMPS code?

### Assistant: You can obtain the LAMMPS code by downloading it from the LAMMPS website.
    "
"
### Context: 
LAMMPS

Overview

LAMMPS is a general-purpose molecular dynamics software package for massively parallel computers. It is written in an exceptionally clean style that makes it one of the more popular codes for users to extend and it currently has dozens of user-developed extensions.

For details about the code and its usage, see the LAMMPS home page. This page provides information specific to running on Polaris at the ALCF.

Using LAMMPS at ALCF

ALCF provides assistance with build instructions, compiling executables, submitting jobs, and providing prebuilt binaries (upon request). A collection of Makefiles and submission scripts are available in the ALCF GettingStarted repo here. For questions, contact us at support@alcf.anl.gov.

How to Obtain the Code

LAMMPS is an open-source code, which can be downloaded from the LAMMPS website.

Building on Polaris

After LAMMPS has been downloaded and unpacked on an ALCF filesystem, users should see a directory whose name is of the form lammps-<version>. One should then see the Makefile lammps-<version>/src/MAKE/MACHINES/Makefile.polaris in recent versions that can be used as a starting point for compilation on Polaris. Copies of Makefiles for building with the GPU/KOKKOS package using CUDA for GPU support with the GNU/NVHPC compiler are available in the ALCF GettingStarted repo here. For older versions of LAMMPS, you may need to take an existing Makefile (e.g. Makefile.mpi) for your specific version of LAMMPS and edit the top portion appropratiately to create a new Makefile.polaris.

KOKKOS package and GNU compilers

The following modules are useful for this particular build. Note, the cmake module is not required if using the GNU Makefile procedure to build LAMMPS. The initial module restore is just setting the default environment as the starting point. Users may find it useful to copy these module commands into a small helper script to assist with compiling and running LAMMPS (e.g. setup_lammps_gnu.sh).

### Human: Can I build LAMMPS on Polaris at ALCF?

### Assistant: Yes, you can build LAMMPS on Polaris at ALCF by using the provided Makefile `Makefile.polaris` as a starting point for compilation.
    "
"
### Context: 
```
module restore
module load craype-accel-nvidia80
module swap PrgEnv-nvhpc PrgEnv-gnu

module use /soft/modulefiles
module load cudatoolkit-standalone

module load spack-pe-base cmake
```

The top portion of Makefile.polaris_gnu_kokkos used to build LAMMPS with the KOKKOS package using GNU as the host-side compiler is shown as an example.

```

polaris_nvhpc_kokkos = Flags for NVIDIA A100, GNU Compiler, MPICH, CUDA

module load craype-accel-nvidia80

module swap PrgEnv-nvhpc PrgEnv-gnu

module use /soft/modulefiles

module load cudatoolkit-standalone

make polaris_gnu_kokkos -j 32

SHELL = /bin/sh

---------------------------------------------------------------------

compiler/linker settings

specify flags and libraries needed for your compiler

KOKKOS_DEVICES = Cuda,OpenMP
KOKKOS_ARCH = Ampere80
KOKKOS_ABSOLUTE_PATH = $(shell cd $(KOKKOS_PATH); pwd)
KOKKOS_CUDA_OPTIONS = ""enable_lambda,disable_malloc_async""
export NVCC_WRAPPER_DEFAULT_COMPILER = nvc++

CC =        $(KOKKOS_ABSOLUTE_PATH)/bin/nvcc_wrapper
CCFLAGS =  -g -O3 -mp -DLAMMPS_MEMALIGN=64

CCFLAGS += -DLAMMPS_BIGBIG

SHFLAGS =   -fPIC
DEPFLAGS =  -M

LINK =      $(CC)
LINKFLAGS = $(CCFLAGS)
LIB =
SIZE =      size
```

With the appropriate LAMMPS Makefile in place an executable can be compiled as in the following example. Note, per-user limits on the login nodes will reduce the maximum parallelism for compilation. Users are encouraged to compile on a compute node in an interactive session if necessary.

cd lammps-<version>/src
make yes-KOKKOS
make polaris_gnu_kokkos -j 32

KOKKOS package and NVHPC compilers

The following modules are useful for this particular build. Note, the cmake module is not required if using the GNU Makefile procedure to build LAMMPS. The initial module restore is just setting the default environment as the starting point. Users may find it useful to copy these module commands into a small helper script to assist with compiling and running LAMMPS (e.g. setup_lammps_nvhpc.sh).

### Human: What is the purpose of loading the craype-accel-nvidia80 module in the Makefile?

### Assistant: The purpose of loading the `craype-accel-nvidia80` module in the Makefile is to specify the NVIDIA A100 accelerator for the build process.
    "
"
### Context: 
```
module restore
module load craype-accel-nvidia80
module swap PrgEnv-nvhpc PrgEnv-gnu

module use /soft/modulefiles
module load cudatoolkit-standalone

module load spack-pe-base cmake
```

The top portion of Makefile.polaris_gnu_kokkos used to build LAMMPS with the KOKKOS package using GNU as the host-side compiler is shown as an example.

```

polaris_nvhpc_kokkos = Flags for NVIDIA A100, GNU Compiler, MPICH, CUDA

module load craype-accel-nvidia80

module swap PrgEnv-nvhpc PrgEnv-gnu

module use /soft/modulefiles

module load cudatoolkit-standalone

make polaris_gnu_kokkos -j 32

SHELL = /bin/sh

---------------------------------------------------------------------

compiler/linker settings

specify flags and libraries needed for your compiler

KOKKOS_DEVICES = Cuda,OpenMP
KOKKOS_ARCH = Ampere80
KOKKOS_ABSOLUTE_PATH = $(shell cd $(KOKKOS_PATH); pwd)
KOKKOS_CUDA_OPTIONS = ""enable_lambda,disable_malloc_async""
export NVCC_WRAPPER_DEFAULT_COMPILER = nvc++

CC =        $(KOKKOS_ABSOLUTE_PATH)/bin/nvcc_wrapper
CCFLAGS =  -g -O3 -mp -DLAMMPS_MEMALIGN=64

CCFLAGS += -DLAMMPS_BIGBIG

SHFLAGS =   -fPIC
DEPFLAGS =  -M

LINK =      $(CC)
LINKFLAGS = $(CCFLAGS)
LIB =
SIZE =      size
```

With the appropriate LAMMPS Makefile in place an executable can be compiled as in the following example. Note, per-user limits on the login nodes will reduce the maximum parallelism for compilation. Users are encouraged to compile on a compute node in an interactive session if necessary.

cd lammps-<version>/src
make yes-KOKKOS
make polaris_gnu_kokkos -j 32

KOKKOS package and NVHPC compilers

The following modules are useful for this particular build. Note, the cmake module is not required if using the GNU Makefile procedure to build LAMMPS. The initial module restore is just setting the default environment as the starting point. Users may find it useful to copy these module commands into a small helper script to assist with compiling and running LAMMPS (e.g. setup_lammps_nvhpc.sh).

### Human: How does the KOKKOS_DEVICES flag impact the compilation process in the Makefile?

### Assistant: The KOKKOS_DEVICES flag specifies the devices or architectures that the KOKKOS package should target for compilation, including NVIDIA GPUs (CUDA) and multi-core CPUs (OpenMP).
    "
"
### Context: 
```
module restore
module load craype-accel-nvidia80
module swap PrgEnv-nvhpc PrgEnv-gnu

module use /soft/modulefiles
module load cudatoolkit-standalone

module load spack-pe-base cmake
```

The top portion of Makefile.polaris_gnu_kokkos used to build LAMMPS with the KOKKOS package using GNU as the host-side compiler is shown as an example.

```

polaris_nvhpc_kokkos = Flags for NVIDIA A100, GNU Compiler, MPICH, CUDA

module load craype-accel-nvidia80

module swap PrgEnv-nvhpc PrgEnv-gnu

module use /soft/modulefiles

module load cudatoolkit-standalone

make polaris_gnu_kokkos -j 32

SHELL = /bin/sh

---------------------------------------------------------------------

compiler/linker settings

specify flags and libraries needed for your compiler

KOKKOS_DEVICES = Cuda,OpenMP
KOKKOS_ARCH = Ampere80
KOKKOS_ABSOLUTE_PATH = $(shell cd $(KOKKOS_PATH); pwd)
KOKKOS_CUDA_OPTIONS = ""enable_lambda,disable_malloc_async""
export NVCC_WRAPPER_DEFAULT_COMPILER = nvc++

CC =        $(KOKKOS_ABSOLUTE_PATH)/bin/nvcc_wrapper
CCFLAGS =  -g -O3 -mp -DLAMMPS_MEMALIGN=64

CCFLAGS += -DLAMMPS_BIGBIG

SHFLAGS =   -fPIC
DEPFLAGS =  -M

LINK =      $(CC)
LINKFLAGS = $(CCFLAGS)
LIB =
SIZE =      size
```

With the appropriate LAMMPS Makefile in place an executable can be compiled as in the following example. Note, per-user limits on the login nodes will reduce the maximum parallelism for compilation. Users are encouraged to compile on a compute node in an interactive session if necessary.

cd lammps-<version>/src
make yes-KOKKOS
make polaris_gnu_kokkos -j 32

KOKKOS package and NVHPC compilers

The following modules are useful for this particular build. Note, the cmake module is not required if using the GNU Makefile procedure to build LAMMPS. The initial module restore is just setting the default environment as the starting point. Users may find it useful to copy these module commands into a small helper script to assist with compiling and running LAMMPS (e.g. setup_lammps_nvhpc.sh).

### Human: Why would a user want to compile LAMMPS on a compute node instead of a login node?

### Assistant: A user would want to compile LAMMPS on a compute node instead of a login node because the login nodes have per-user limits on resources, which can reduce the maximum parallelism for compilation.
    "
"
### Context: 
export MPICH_GPU_SUPPORT_ENABLED=1

NNODES=wc -l < $PBS_NODEFILE

per-node settings

NRANKS=4
NDEPTH=8
NTHREADS=1
NGPUS=4

NTOTRANKS=$(( NNODES * NRANKS ))

. ./setup_lammps_gnu.sh

EXE=/home/knight/bin/lmp_polaris_gnu_kokkos
EXE_ARG=""-in in.reaxc.hns -k on g ${NGPUS} -sf kk -pk kokkos neigh half neigh/qeq full newton on ""

OMP settings mostly to quiet Kokkos messages

MPI_ARG="" -n ${NTOTRANKS} --ppn ${NRANKS} --depth=${NDEPTH} --cpu-bind depth ""
OMP_ARG="" --env OMP_NUM_THREADS=${NTHREADS} --env OMP_PROC_BIND=spread --env OMP_PLACES=cores ""

COMMAND=""mpiexec ${MPI_ARG} ${OMP_ARG} ${EXE} ${EXE_ARG}""
echo ""COMMAND= ${COMMAND}""
${COMMAND}
```

GPU package

The module environments above can be used to build LAMMPS with the GPU package as well. Copies of Makefiles for building with the GPU package using CUDA for GPU support with the GNU and NVHPC compilers are available in the ALCF GettingStarted repo here.

Performance Notes

Some useful information on accelerator packages and expectations can be found on the LAMMPS website here.

### Human: What is the purpose of setting `MPICH_GPU_SUPPORT_ENABLED=1` in this script?

### Assistant: The purpose of setting `MPICH_GPU_SUPPORT_ENABLED=1` is to enable GPU support for building LAMMPS.
    "
"
### Context: 
export MPICH_GPU_SUPPORT_ENABLED=1

NNODES=wc -l < $PBS_NODEFILE

per-node settings

NRANKS=4
NDEPTH=8
NTHREADS=1
NGPUS=4

NTOTRANKS=$(( NNODES * NRANKS ))

. ./setup_lammps_gnu.sh

EXE=/home/knight/bin/lmp_polaris_gnu_kokkos
EXE_ARG=""-in in.reaxc.hns -k on g ${NGPUS} -sf kk -pk kokkos neigh half neigh/qeq full newton on ""

OMP settings mostly to quiet Kokkos messages

MPI_ARG="" -n ${NTOTRANKS} --ppn ${NRANKS} --depth=${NDEPTH} --cpu-bind depth ""
OMP_ARG="" --env OMP_NUM_THREADS=${NTHREADS} --env OMP_PROC_BIND=spread --env OMP_PLACES=cores ""

COMMAND=""mpiexec ${MPI_ARG} ${OMP_ARG} ${EXE} ${EXE_ARG}""
echo ""COMMAND= ${COMMAND}""
${COMMAND}
```

GPU package

The module environments above can be used to build LAMMPS with the GPU package as well. Copies of Makefiles for building with the GPU package using CUDA for GPU support with the GNU and NVHPC compilers are available in the ALCF GettingStarted repo here.

Performance Notes

Some useful information on accelerator packages and expectations can be found on the LAMMPS website here.

### Human: How do I adjust the number of ranks and depth in an LAMMPS simulation to optimize performance?

### Assistant: Adjust `NRANKS` to a value that balances computational efficiency with communication overhead, and adjust `NDEPTH` based on performance measurements.
    "
"
### Context: 
export MPICH_GPU_SUPPORT_ENABLED=1

NNODES=wc -l < $PBS_NODEFILE

per-node settings

NRANKS=4
NDEPTH=8
NTHREADS=1
NGPUS=4

NTOTRANKS=$(( NNODES * NRANKS ))

. ./setup_lammps_gnu.sh

EXE=/home/knight/bin/lmp_polaris_gnu_kokkos
EXE_ARG=""-in in.reaxc.hns -k on g ${NGPUS} -sf kk -pk kokkos neigh half neigh/qeq full newton on ""

OMP settings mostly to quiet Kokkos messages

MPI_ARG="" -n ${NTOTRANKS} --ppn ${NRANKS} --depth=${NDEPTH} --cpu-bind depth ""
OMP_ARG="" --env OMP_NUM_THREADS=${NTHREADS} --env OMP_PROC_BIND=spread --env OMP_PLACES=cores ""

COMMAND=""mpiexec ${MPI_ARG} ${OMP_ARG} ${EXE} ${EXE_ARG}""
echo ""COMMAND= ${COMMAND}""
${COMMAND}
```

GPU package

The module environments above can be used to build LAMMPS with the GPU package as well. Copies of Makefiles for building with the GPU package using CUDA for GPU support with the GNU and NVHPC compilers are available in the ALCF GettingStarted repo here.

Performance Notes

Some useful information on accelerator packages and expectations can be found on the LAMMPS website here.

### Human: Can I use CUDA for GPU support with both the GNU and NVHPC compilers when building LAMMPS with the GPU package?

### Assistant: Yes, you can use CUDA for GPU support with both the GNU and NVHPC compilers when building LAMMPS with the GPU package.
    "
"
### Context: 
OpenMM on Polaris

What is OpenMM?

OpenMM is a high-performance toolkit for molecular simulations that can be used as a stand-alone application or as a library. It provides a combination of flexibility (through custom forces and integrators), openness, and high-performance (especially on recent GPUs).

Using OpenMM at ALCF

ALCF offers assistance with building binaries and compiling instructions for OpenMM. For questions, contact us at support@alcf.anl.gov.

Building OpenMM using Conda module

Update environment
$ module load conda/2022-07-19

Install OpenMM
$ mkdir conda
$ conda create --prefix /path-to/conda/openmm_env
$ conda activate /path-to/conda/openmm_env
$ conda install -c conda-forge openmm cudatoolkit=11.4
$ conda deactivate /path-to/conda/openmm_env

Validate installation: if successful, then info on code version, platform types, CUDA initialization, and force error tolerance will be shown.
$ cd /path-to/conda/openmm_env/share/openmm/examples
$ python -m openmm.testInstallation

Benchmark testing using PBS job script below.
$ cd /path-to/conda/openmm_env/share/openmm/examples
$ qsub ./submit.sh

Running OpenMM Benchmark on Polaris

A sample pbs script follows that will run OpenMM benchmark on one node.

```

!/bin/sh

PBS -l select=1:system=polaris

PBS -l place=scatter

PBS -l walltime=0:30:00

PBS -q debug

PBS -A PROJECT

PBS -l filesystems=home:grand:eagle

cd ${PBS_O_WORKDIR}

module load cudatoolkit-standalone/11.4.4

python benchmark.py --platform=CUDA --test=pme --precision=mixed --seconds=30 --heavy-hydrogens > test.output
```

Building OpenMM from Source

Update environment
$ module load cudatoolkit-standalone/11.4.4
$ module load cray-python/3.9.12.1

Download OpenMM
$ git checkout https://github.com/openmm/openmm.git
$ cd openmm ; mkdir build

Download and build doxygen
$ git clone https://github.com/doxygen/doxygen.git
$ cd doxygen ; cmake ; make ; make install ; cd ../

### Human: How can I install OpenMM using Conda?

### Assistant: Install OpenMM using Conda: `module load conda/20xx-07-19; mkdir conda; conda create --prefix /path-to/conda/openmm_env; conda activate /path-to/conda/openmm_env; conda install -c conda-forge openmm cudatoolkit=11.4; conda deactivate /path-to/conda/openmm_env`.
    "
"
### Context: 
OpenMM on Polaris

What is OpenMM?

OpenMM is a high-performance toolkit for molecular simulations that can be used as a stand-alone application or as a library. It provides a combination of flexibility (through custom forces and integrators), openness, and high-performance (especially on recent GPUs).

Using OpenMM at ALCF

ALCF offers assistance with building binaries and compiling instructions for OpenMM. For questions, contact us at support@alcf.anl.gov.

Building OpenMM using Conda module

Update environment
$ module load conda/2022-07-19

Install OpenMM
$ mkdir conda
$ conda create --prefix /path-to/conda/openmm_env
$ conda activate /path-to/conda/openmm_env
$ conda install -c conda-forge openmm cudatoolkit=11.4
$ conda deactivate /path-to/conda/openmm_env

Validate installation: if successful, then info on code version, platform types, CUDA initialization, and force error tolerance will be shown.
$ cd /path-to/conda/openmm_env/share/openmm/examples
$ python -m openmm.testInstallation

Benchmark testing using PBS job script below.
$ cd /path-to/conda/openmm_env/share/openmm/examples
$ qsub ./submit.sh

Running OpenMM Benchmark on Polaris

A sample pbs script follows that will run OpenMM benchmark on one node.

```

!/bin/sh

PBS -l select=1:system=polaris

PBS -l place=scatter

PBS -l walltime=0:30:00

PBS -q debug

PBS -A PROJECT

PBS -l filesystems=home:grand:eagle

cd ${PBS_O_WORKDIR}

module load cudatoolkit-standalone/11.4.4

python benchmark.py --platform=CUDA --test=pme --precision=mixed --seconds=30 --heavy-hydrogens > test.output
```

Building OpenMM from Source

Update environment
$ module load cudatoolkit-standalone/11.4.4
$ module load cray-python/3.9.12.1

Download OpenMM
$ git checkout https://github.com/openmm/openmm.git
$ cd openmm ; mkdir build

Download and build doxygen
$ git clone https://github.com/doxygen/doxygen.git
$ cd doxygen ; cmake ; make ; make install ; cd ../

### Human: What is the purpose of running the `openmm.testInstallation` command?

### Assistant: The purpose of running the `openmm.testInstallation` command is to validate the installation of OpenMM and check its functionality.
    "
"
### Context: 
OpenMM on Polaris

What is OpenMM?

OpenMM is a high-performance toolkit for molecular simulations that can be used as a stand-alone application or as a library. It provides a combination of flexibility (through custom forces and integrators), openness, and high-performance (especially on recent GPUs).

Using OpenMM at ALCF

ALCF offers assistance with building binaries and compiling instructions for OpenMM. For questions, contact us at support@alcf.anl.gov.

Building OpenMM using Conda module

Update environment
$ module load conda/2022-07-19

Install OpenMM
$ mkdir conda
$ conda create --prefix /path-to/conda/openmm_env
$ conda activate /path-to/conda/openmm_env
$ conda install -c conda-forge openmm cudatoolkit=11.4
$ conda deactivate /path-to/conda/openmm_env

Validate installation: if successful, then info on code version, platform types, CUDA initialization, and force error tolerance will be shown.
$ cd /path-to/conda/openmm_env/share/openmm/examples
$ python -m openmm.testInstallation

Benchmark testing using PBS job script below.
$ cd /path-to/conda/openmm_env/share/openmm/examples
$ qsub ./submit.sh

Running OpenMM Benchmark on Polaris

A sample pbs script follows that will run OpenMM benchmark on one node.

```

!/bin/sh

PBS -l select=1:system=polaris

PBS -l place=scatter

PBS -l walltime=0:30:00

PBS -q debug

PBS -A PROJECT

PBS -l filesystems=home:grand:eagle

cd ${PBS_O_WORKDIR}

module load cudatoolkit-standalone/11.4.4

python benchmark.py --platform=CUDA --test=pme --precision=mixed --seconds=30 --heavy-hydrogens > test.output
```

Building OpenMM from Source

Update environment
$ module load cudatoolkit-standalone/11.4.4
$ module load cray-python/3.9.12.1

Download OpenMM
$ git checkout https://github.com/openmm/openmm.git
$ cd openmm ; mkdir build

Download and build doxygen
$ git clone https://github.com/doxygen/doxygen.git
$ cd doxygen ; cmake ; make ; make install ; cd ../

### Human: How can I run an OpenMM benchmark test using a PBS job script?

### Assistant: Run OpenMM benchmark test using a PBS job script: Create a PBS job script with the specified commands and submit it to the queue.
    "
"
### Context: 
Download and install swig in OpenMM directory.
$ tar xzf swig-4.0.2.tar.gz
$ cd swig-4.0.2
$ ./configure --prefix=/path-to/openmm/swig-4.0.2 ; make -j 8 ; make install

Build OpenMM
$ cmake -DDOXYGEN_EXECUTABLE=/path-to/openmm/doxygen/bin/doxygen \
        -DSWIG_EXECUTABLE=/path-to/openmm/swig-4.0.2/bin/swig \
        -DCMAKE_INSTALL_PREFIX=/path-to/openmm/build \
         -DCUDA_HOME=/soft/compilers/cudatoolkit/cuda-11.4.4 \
         -DCUDA_INCLUDE_DIR=/soft/compilers/cudatoolkit/cuda-11.4.4/include \
         -DCUDA_LIB_DIR=/soft/compilers/cudatoolkit/cuda-11.4.4/lib64
$ make -j 8
$ make install

Validate installation: if successful, then info on code version, platform types, CUDA initialization, and force error tolerance will be shown. 
$ cd /path-to/openmm/examples
$ python -m openmm.testInstallation

Benchmark testing using the PBS job script above.
$ cd /path-to/openmm/examples
$ qsub ./submit.sh

### Human: How do I install SWIG in OpenMM?

### Assistant: Install SWIG in OpenMM by running `tar xzf swig-4.0.2.tar.gz`, `cd swig-4.0.2`, `./configure --prefix=/path-to/openmm/swig-4.0.2`, `make -j 8`, and `make install`.
    "
"
### Context: 
Download and install swig in OpenMM directory.
$ tar xzf swig-4.0.2.tar.gz
$ cd swig-4.0.2
$ ./configure --prefix=/path-to/openmm/swig-4.0.2 ; make -j 8 ; make install

Build OpenMM
$ cmake -DDOXYGEN_EXECUTABLE=/path-to/openmm/doxygen/bin/doxygen \
        -DSWIG_EXECUTABLE=/path-to/openmm/swig-4.0.2/bin/swig \
        -DCMAKE_INSTALL_PREFIX=/path-to/openmm/build \
         -DCUDA_HOME=/soft/compilers/cudatoolkit/cuda-11.4.4 \
         -DCUDA_INCLUDE_DIR=/soft/compilers/cudatoolkit/cuda-11.4.4/include \
         -DCUDA_LIB_DIR=/soft/compilers/cudatoolkit/cuda-11.4.4/lib64
$ make -j 8
$ make install

Validate installation: if successful, then info on code version, platform types, CUDA initialization, and force error tolerance will be shown. 
$ cd /path-to/openmm/examples
$ python -m openmm.testInstallation

Benchmark testing using the PBS job script above.
$ cd /path-to/openmm/examples
$ qsub ./submit.sh

### Human: What are the steps to build OpenMM?

### Assistant: The steps to build OpenMM are: download and install swig, run cmake with the necessary options, run make to build OpenMM, install OpenMM, validate the installation, and run benchmark testing.
    "
"
### Context: 
Download and install swig in OpenMM directory.
$ tar xzf swig-4.0.2.tar.gz
$ cd swig-4.0.2
$ ./configure --prefix=/path-to/openmm/swig-4.0.2 ; make -j 8 ; make install

Build OpenMM
$ cmake -DDOXYGEN_EXECUTABLE=/path-to/openmm/doxygen/bin/doxygen \
        -DSWIG_EXECUTABLE=/path-to/openmm/swig-4.0.2/bin/swig \
        -DCMAKE_INSTALL_PREFIX=/path-to/openmm/build \
         -DCUDA_HOME=/soft/compilers/cudatoolkit/cuda-11.4.4 \
         -DCUDA_INCLUDE_DIR=/soft/compilers/cudatoolkit/cuda-11.4.4/include \
         -DCUDA_LIB_DIR=/soft/compilers/cudatoolkit/cuda-11.4.4/lib64
$ make -j 8
$ make install

Validate installation: if successful, then info on code version, platform types, CUDA initialization, and force error tolerance will be shown. 
$ cd /path-to/openmm/examples
$ python -m openmm.testInstallation

Benchmark testing using the PBS job script above.
$ cd /path-to/openmm/examples
$ qsub ./submit.sh

### Human: How do I validate the installation of OpenMM?

### Assistant: The installation of OpenMM is validated by running the Python script `openmm.testInstallation` and checking for output about code version, platform types, CUDA initialization, and force error tolerance.
    "
"
### Context: 
QMCPACK on Polaris

QMCPACK, is a modern high-performance open-source Quantum Monte Carlo (QMC) simulation code. Its main applications are electronic structure calculations of molecular, quasi-2D and solid-state systems. Variational Monte Carlo (VMC), diffusion Monte Carlo (DMC) and a number of other advanced QMC algorithms are implemented. Orbital space auxiliary field QMC (AFQMC) has recently been added. By directly solving the Schrodinger equation, QMC methods offer greater accuracy than methods such as density functional theory, but at a trade-off of much greater computational expense.

Prebuilt executables are provided at /soft/applications/qmcpack.
The directory of each installation also includes a job submission script example qmcpack-polaris.job.
Update build recipe is provided on GitHub.

### Human: What type of simulation code is QMCPACK?

### Assistant: Quantum Monte Carlo (QMC) simulation code.
    "
"
### Context: 
Spack PE

Spack is an HPC-oriented package manager which ALCF uses to install software for
the user environment.

ALCF's Spack PE is a Spack-managed software stack which provides various build
tools, utilities, and libraries. It consists of a base stack (spack-pe-base)
and PrgEnv-dependent stacks (currently spack-pe-gnu).

spack-pe-base contains commonplace software compiled for CPU with the system
GCC compilers. Accordingly, the software in spack-pe-base can be used
regardless of programming environment.

spack-pe-gnu is based on the E4S Project and
provides performant HPC libraries built with PrgEnv-gnu and the nvcc CUDA
compiler driver for GPU code. spack-pe-gnu is dependent on both
spack-pe-base and PrgEnv-gnu.

Using software from the Spack PE

The base suite of software tools and libraries can be accessed by loading the
spack-pe-base module. This adds a path to $MODULEPATH which contains
numerous modules.

For example, to load cmake starting from the default environment, a user
should run the following commands:
module use /soft/modulefiles
module load spack-pe-base
module load cmake

The spack-pe-base module adds paths to the user's MODULEPATH; individual packages are subsequently loaded through the newly available modules. The full list of available packages can be viewed by running module avail or module --show-hidden avail for a complete listing. Packages are loaded in the same way from spack-pe-gnu.

Inspecting packages

When a module in the Spack PE is loaded, several environment variables are
updated to integrate the package into the user's environment. Additionally, the
PACKAGE_ROOT variable is set to the path to the installation prefix of the
package. For example, after loading cmake as above:

$ echo $CMAKE_ROOT
/soft/spack/gcc/0.6.1/install/linux-sles15-x86_64/gcc-12.3.0/cmake-3.27.7-a435jtzvweeos2es6enirbxdjdqhqgdp/
$ ls -a $CMAKE_ROOT
.  ..  bin  doc  share  .spack

### Human: What is Spack PE?

### Assistant: Spack PE is an HPC-oriented package manager used by ALCF to install software for the user environment.
    "
"
### Context: 
Spack PE

Spack is an HPC-oriented package manager which ALCF uses to install software for
the user environment.

ALCF's Spack PE is a Spack-managed software stack which provides various build
tools, utilities, and libraries. It consists of a base stack (spack-pe-base)
and PrgEnv-dependent stacks (currently spack-pe-gnu).

spack-pe-base contains commonplace software compiled for CPU with the system
GCC compilers. Accordingly, the software in spack-pe-base can be used
regardless of programming environment.

spack-pe-gnu is based on the E4S Project and
provides performant HPC libraries built with PrgEnv-gnu and the nvcc CUDA
compiler driver for GPU code. spack-pe-gnu is dependent on both
spack-pe-base and PrgEnv-gnu.

Using software from the Spack PE

The base suite of software tools and libraries can be accessed by loading the
spack-pe-base module. This adds a path to $MODULEPATH which contains
numerous modules.

For example, to load cmake starting from the default environment, a user
should run the following commands:
module use /soft/modulefiles
module load spack-pe-base
module load cmake

The spack-pe-base module adds paths to the user's MODULEPATH; individual packages are subsequently loaded through the newly available modules. The full list of available packages can be viewed by running module avail or module --show-hidden avail for a complete listing. Packages are loaded in the same way from spack-pe-gnu.

Inspecting packages

When a module in the Spack PE is loaded, several environment variables are
updated to integrate the package into the user's environment. Additionally, the
PACKAGE_ROOT variable is set to the path to the installation prefix of the
package. For example, after loading cmake as above:

$ echo $CMAKE_ROOT
/soft/spack/gcc/0.6.1/install/linux-sles15-x86_64/gcc-12.3.0/cmake-3.27.7-a435jtzvweeos2es6enirbxdjdqhqgdp/
$ ls -a $CMAKE_ROOT
.  ..  bin  doc  share  .spack

### Human: How do I access the base suite of software tools and libraries in Spack PE?

### Assistant: Load the spack-pe-base module by running ""module load spack-pe-base"" and then view available packages with ""module avail"" or ""module --show-hidden avail"".
    "
"
### Context: 
Spack PE

Spack is an HPC-oriented package manager which ALCF uses to install software for
the user environment.

ALCF's Spack PE is a Spack-managed software stack which provides various build
tools, utilities, and libraries. It consists of a base stack (spack-pe-base)
and PrgEnv-dependent stacks (currently spack-pe-gnu).

spack-pe-base contains commonplace software compiled for CPU with the system
GCC compilers. Accordingly, the software in spack-pe-base can be used
regardless of programming environment.

spack-pe-gnu is based on the E4S Project and
provides performant HPC libraries built with PrgEnv-gnu and the nvcc CUDA
compiler driver for GPU code. spack-pe-gnu is dependent on both
spack-pe-base and PrgEnv-gnu.

Using software from the Spack PE

The base suite of software tools and libraries can be accessed by loading the
spack-pe-base module. This adds a path to $MODULEPATH which contains
numerous modules.

For example, to load cmake starting from the default environment, a user
should run the following commands:
module use /soft/modulefiles
module load spack-pe-base
module load cmake

The spack-pe-base module adds paths to the user's MODULEPATH; individual packages are subsequently loaded through the newly available modules. The full list of available packages can be viewed by running module avail or module --show-hidden avail for a complete listing. Packages are loaded in the same way from spack-pe-gnu.

Inspecting packages

When a module in the Spack PE is loaded, several environment variables are
updated to integrate the package into the user's environment. Additionally, the
PACKAGE_ROOT variable is set to the path to the installation prefix of the
package. For example, after loading cmake as above:

$ echo $CMAKE_ROOT
/soft/spack/gcc/0.6.1/install/linux-sles15-x86_64/gcc-12.3.0/cmake-3.27.7-a435jtzvweeos2es6enirbxdjdqhqgdp/
$ ls -a $CMAKE_ROOT
.  ..  bin  doc  share  .spack

### Human: What environment variables are updated when a module in the Spack PE is loaded?

### Assistant: The PACKAGE_ROOT variable is updated when a module in the Spack PE is loaded.
    "
"
### Context: 
This variable can be used to inspect software installations and find header or
library paths. Additionally, Spack packages have a .spack directory in the
installation prefix which contains build information and logs.

Building software with Spack

Spack is a powerful package manager designed for HPC.
The Spack PE is installed and managed with Spack; users can also install Spack
in their own home or project directory to manage their software builds. Spack
has a steep learning curve, but it may benefit workflows involving frequent
builds with complex dependencies.

For users who wish to use Spack to install their own software, we provide
configuration files corresponding to the Spack PE deployments. These
configuration files can be found in config directories in /soft/spack within
the respective Spack PE installation directories. For example, the
spack-pe-base/0.6.1 configurations are in /soft/spack/gcc/0.6.1/config. Not
all of these settings will be useful for all builds and it is not recommended to
adopt these wholesale as global settings. The recommended method is to include
these settings ad hoc in a spack environment to control what information spack
uses for its builds.

Support requests and feedback should be directed to
support@alcf.anl.gov. For general Spack
questions, users are encouraged to consult the following resources:

Spack development website

Spack documentation

Spack tutorial

Spack Slack channel

### Human: What is Spack used for in HPC?

### Assistant: Spack is used for building software with complex dependencies in HPC.
    "
"
### Context: 
This variable can be used to inspect software installations and find header or
library paths. Additionally, Spack packages have a .spack directory in the
installation prefix which contains build information and logs.

Building software with Spack

Spack is a powerful package manager designed for HPC.
The Spack PE is installed and managed with Spack; users can also install Spack
in their own home or project directory to manage their software builds. Spack
has a steep learning curve, but it may benefit workflows involving frequent
builds with complex dependencies.

For users who wish to use Spack to install their own software, we provide
configuration files corresponding to the Spack PE deployments. These
configuration files can be found in config directories in /soft/spack within
the respective Spack PE installation directories. For example, the
spack-pe-base/0.6.1 configurations are in /soft/spack/gcc/0.6.1/config. Not
all of these settings will be useful for all builds and it is not recommended to
adopt these wholesale as global settings. The recommended method is to include
these settings ad hoc in a spack environment to control what information spack
uses for its builds.

Support requests and feedback should be directed to
support@alcf.anl.gov. For general Spack
questions, users are encouraged to consult the following resources:

Spack development website

Spack documentation

Spack tutorial

Spack Slack channel

### Human: How do you manage software builds with Spack?

### Assistant: To manage software builds with Spack, users can install Spack in their own home or project directory, find configuration files corresponding to the Spack PE deployments, and include these settings ad hoc in a spack environment.
    "
"
### Context: 
This variable can be used to inspect software installations and find header or
library paths. Additionally, Spack packages have a .spack directory in the
installation prefix which contains build information and logs.

Building software with Spack

Spack is a powerful package manager designed for HPC.
The Spack PE is installed and managed with Spack; users can also install Spack
in their own home or project directory to manage their software builds. Spack
has a steep learning curve, but it may benefit workflows involving frequent
builds with complex dependencies.

For users who wish to use Spack to install their own software, we provide
configuration files corresponding to the Spack PE deployments. These
configuration files can be found in config directories in /soft/spack within
the respective Spack PE installation directories. For example, the
spack-pe-base/0.6.1 configurations are in /soft/spack/gcc/0.6.1/config. Not
all of these settings will be useful for all builds and it is not recommended to
adopt these wholesale as global settings. The recommended method is to include
these settings ad hoc in a spack environment to control what information spack
uses for its builds.

Support requests and feedback should be directed to
support@alcf.anl.gov. For general Spack
questions, users are encouraged to consult the following resources:

Spack development website

Spack documentation

Spack tutorial

Spack Slack channel

### Human: Where can I find configuration files for using Spack?

### Assistant: The configuration files for using Spack can be found in `/soft/spack` within the respective Spack PE installation directories, specifically in `config` directories.
    "
"
### Context: 
Cabana

Cabana

Cabana is built atop Kokkos. It provides class templates useful for
implementing particle codes

Cabana Documentation

Cabana Wiki

Cabana github

Cabana on Polaris

Following the Polaris upgrade to HPCM
1.10,
the module setup to use the prebuilt Kokkos changed.

Built against the prebuilt Kokkos on
polaris, the prebuilt Cabana
includes 3 backends: Serial and OpenMP for CPU execution and CUDA for GPU
execution. To use it, run

module load craype-x86-milan
module load craype-accel-nvidia80
module swap PrgEnv-nvhpc PrgEnv-gnu
module use /soft/modulefiles
module load cuda-PrgEnv-nvidia/12.2.91
module load kokkos cabana

Cabana is a headers-only package; there are no actual libraries installed.

### Human: What types of backends does Cabana provide for CPU execution?

### Assistant: Cabana provides two types of backends for CPU execution: Serial and OpenMP.
    "
"
### Context: 
Cabana

Cabana

Cabana is built atop Kokkos. It provides class templates useful for
implementing particle codes

Cabana Documentation

Cabana Wiki

Cabana github

Cabana on Polaris

Following the Polaris upgrade to HPCM
1.10,
the module setup to use the prebuilt Kokkos changed.

Built against the prebuilt Kokkos on
polaris, the prebuilt Cabana
includes 3 backends: Serial and OpenMP for CPU execution and CUDA for GPU
execution. To use it, run

module load craype-x86-milan
module load craype-accel-nvidia80
module swap PrgEnv-nvhpc PrgEnv-gnu
module use /soft/modulefiles
module load cuda-PrgEnv-nvidia/12.2.91
module load kokkos cabana

Cabana is a headers-only package; there are no actual libraries installed.

### Human: How can I use Cabana on Polaris after the 1.10 upgrade?

### Assistant: Use the provided module commands to load the necessary modules and use Cabana on Polaris after the 1.10 upgrade.
    "
"
### Context: 
Cabana

Cabana

Cabana is built atop Kokkos. It provides class templates useful for
implementing particle codes

Cabana Documentation

Cabana Wiki

Cabana github

Cabana on Polaris

Following the Polaris upgrade to HPCM
1.10,
the module setup to use the prebuilt Kokkos changed.

Built against the prebuilt Kokkos on
polaris, the prebuilt Cabana
includes 3 backends: Serial and OpenMP for CPU execution and CUDA for GPU
execution. To use it, run

module load craype-x86-milan
module load craype-accel-nvidia80
module swap PrgEnv-nvhpc PrgEnv-gnu
module use /soft/modulefiles
module load cuda-PrgEnv-nvidia/12.2.91
module load kokkos cabana

Cabana is a headers-only package; there are no actual libraries installed.

### Human: Is Cabana a headers-only package, and if so, what implications does this have?

### Assistant: Yes, Cabana is a headers-only package.
    "
"
### Context: 
Math Libraries

BLAS, LAPACK, and ScaLAPACK for CPUs

Some math libraries targeting CPUs are made available as part of the nvhpc modules and are based on the OpenBLAS project. Additional documentation is available from NVIDIA.

BLAS & LAPACK can be found in the $NVIDIA_PATH/compilers/lib directory.

ScaLAPACK can be found in the $NVIDIA_PATH/comm_libs directory.

GNU Scientific Library, GSL-2.7 available as module help math_libs/gsl

AMD Optiming CPU Libraries, AOCL v4.2 available as module help math_libs/aocl

Other Cray-based math libs such as Libsci, FFTW were made available by module load cray-libsci & module load cray-fftw

NVIDIA Math Libraries for GPUs

Math libraries from NVIDIA are made available via the nvhpc modules. Many of the libraries users typically use can be found in the $NVIDIA_PATH/math_libs directory. Some examples follow and additional documentation is available from NVIDIA.

libcublas

libcufft

libcurand

libcusolver

libcusparse

### Human: What are some examples of CPU-based math libraries that can be found in the $NVIDIA_PATH/compilers/lib directory?

### Assistant: BLAS, LAPACK, GSL-2.7, AOCL v4.2
    "
"
### Context: 
Math Libraries

BLAS, LAPACK, and ScaLAPACK for CPUs

Some math libraries targeting CPUs are made available as part of the nvhpc modules and are based on the OpenBLAS project. Additional documentation is available from NVIDIA.

BLAS & LAPACK can be found in the $NVIDIA_PATH/compilers/lib directory.

ScaLAPACK can be found in the $NVIDIA_PATH/comm_libs directory.

GNU Scientific Library, GSL-2.7 available as module help math_libs/gsl

AMD Optiming CPU Libraries, AOCL v4.2 available as module help math_libs/aocl

Other Cray-based math libs such as Libsci, FFTW were made available by module load cray-libsci & module load cray-fftw

NVIDIA Math Libraries for GPUs

Math libraries from NVIDIA are made available via the nvhpc modules. Many of the libraries users typically use can be found in the $NVIDIA_PATH/math_libs directory. Some examples follow and additional documentation is available from NVIDIA.

libcublas

libcufft

libcurand

libcusolver

libcusparse

### Human: Which NVIDIA math library is used for GPU-based linear algebra operations?

### Assistant: libcusolver
    "
"
### Context: 
Math Libraries

BLAS, LAPACK, and ScaLAPACK for CPUs

Some math libraries targeting CPUs are made available as part of the nvhpc modules and are based on the OpenBLAS project. Additional documentation is available from NVIDIA.

BLAS & LAPACK can be found in the $NVIDIA_PATH/compilers/lib directory.

ScaLAPACK can be found in the $NVIDIA_PATH/comm_libs directory.

GNU Scientific Library, GSL-2.7 available as module help math_libs/gsl

AMD Optiming CPU Libraries, AOCL v4.2 available as module help math_libs/aocl

Other Cray-based math libs such as Libsci, FFTW were made available by module load cray-libsci & module load cray-fftw

NVIDIA Math Libraries for GPUs

Math libraries from NVIDIA are made available via the nvhpc modules. Many of the libraries users typically use can be found in the $NVIDIA_PATH/math_libs directory. Some examples follow and additional documentation is available from NVIDIA.

libcublas

libcufft

libcurand

libcusolver

libcusparse

### Human: How do I load and use the Libsci and FFTW libraries, which are Cray-based math libraries?

### Assistant: Load Libsci and FFTW libraries by running ""module load cray-libsci"" and ""module load cray-fftw"", then verify with ""module list"".
    "
"
### Context: 
CUDA-GDB

References

NVIDIA CUDA-GDB Documentation

Introduction

CUDA-GDB is the NVIDIA tool for debugging CUDA applications running on Polaris. CUDA-GDB is an extension to GDB, the GNU Project debugger. The tool provides developers with a mechanism for debugging CUDA applications running on actual hardware. This enables developers to debug applications without the potential variations introduced by simulation and emulation environments.

Step-by-step guide

Debug Compilation

NVCC, the NVIDIA CUDA compiler driver, provides a mechanism for generating the debugging information necessary for CUDA-GDB to work properly. The -g -G option pair must be passed to NVCC when an application is compiled for ease of debugging with CUDA-GDB; for example,
nvcc -g -G foo.cu -o foo
Using this line to compile the CUDA application foo.cu
* forces -O0 compilation, with the exception of very limited dead-code eliminations and register-spilling optimizations.
* makes the compiler include debug information in the executable

Running CUDA-gdb on Polaris compute nodes

Start an interactive job mode on Polaris as follows:

```
$ qsub -I -l select=1 -l walltime=1:00:00

$ cuda-gdb --version
NVIDIA (R) CUDA Debugger
11.4 release
Portions Copyright (C) 2007-2021 NVIDIA Corporation
GNU gdb (GDB) 10.1
Copyright (C) 2020 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later http://gnu.org/licenses/gpl.html
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

$ cuda-gdb foo
```

A quick example with a stream benchmark on a Polaris compute node

```
jkwack@polaris-login-02:~> qsub -I -l select=1 -l walltime=1:00:00
qsub: waiting for job 308834.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov to start
qsub: job 308834.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov ready

### Human: How do I compile a CUDA application for debugging with CUDA-GDB?

### Assistant: Compile the CUDA application with `nvcc -g -G foo.cu -o foo` and then run CUDA-GDB on a Polaris compute node.
    "
"
### Context: 
CUDA-GDB

References

NVIDIA CUDA-GDB Documentation

Introduction

CUDA-GDB is the NVIDIA tool for debugging CUDA applications running on Polaris. CUDA-GDB is an extension to GDB, the GNU Project debugger. The tool provides developers with a mechanism for debugging CUDA applications running on actual hardware. This enables developers to debug applications without the potential variations introduced by simulation and emulation environments.

Step-by-step guide

Debug Compilation

NVCC, the NVIDIA CUDA compiler driver, provides a mechanism for generating the debugging information necessary for CUDA-GDB to work properly. The -g -G option pair must be passed to NVCC when an application is compiled for ease of debugging with CUDA-GDB; for example,
nvcc -g -G foo.cu -o foo
Using this line to compile the CUDA application foo.cu
* forces -O0 compilation, with the exception of very limited dead-code eliminations and register-spilling optimizations.
* makes the compiler include debug information in the executable

Running CUDA-gdb on Polaris compute nodes

Start an interactive job mode on Polaris as follows:

```
$ qsub -I -l select=1 -l walltime=1:00:00

$ cuda-gdb --version
NVIDIA (R) CUDA Debugger
11.4 release
Portions Copyright (C) 2007-2021 NVIDIA Corporation
GNU gdb (GDB) 10.1
Copyright (C) 2020 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later http://gnu.org/licenses/gpl.html
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

$ cuda-gdb foo
```

A quick example with a stream benchmark on a Polaris compute node

```
jkwack@polaris-login-02:~> qsub -I -l select=1 -l walltime=1:00:00
qsub: waiting for job 308834.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov to start
qsub: job 308834.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov ready

### Human: What options should I use when compiling a CUDA application to include debug information using NVCC?

### Assistant: The options to use when compiling a CUDA application to include debug information using NVCC are -g -G.
    "
"
### Context: 
CUDA-GDB

References

NVIDIA CUDA-GDB Documentation

Introduction

CUDA-GDB is the NVIDIA tool for debugging CUDA applications running on Polaris. CUDA-GDB is an extension to GDB, the GNU Project debugger. The tool provides developers with a mechanism for debugging CUDA applications running on actual hardware. This enables developers to debug applications without the potential variations introduced by simulation and emulation environments.

Step-by-step guide

Debug Compilation

NVCC, the NVIDIA CUDA compiler driver, provides a mechanism for generating the debugging information necessary for CUDA-GDB to work properly. The -g -G option pair must be passed to NVCC when an application is compiled for ease of debugging with CUDA-GDB; for example,
nvcc -g -G foo.cu -o foo
Using this line to compile the CUDA application foo.cu
* forces -O0 compilation, with the exception of very limited dead-code eliminations and register-spilling optimizations.
* makes the compiler include debug information in the executable

Running CUDA-gdb on Polaris compute nodes

Start an interactive job mode on Polaris as follows:

```
$ qsub -I -l select=1 -l walltime=1:00:00

$ cuda-gdb --version
NVIDIA (R) CUDA Debugger
11.4 release
Portions Copyright (C) 2007-2021 NVIDIA Corporation
GNU gdb (GDB) 10.1
Copyright (C) 2020 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later http://gnu.org/licenses/gpl.html
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

$ cuda-gdb foo
```

A quick example with a stream benchmark on a Polaris compute node

```
jkwack@polaris-login-02:~> qsub -I -l select=1 -l walltime=1:00:00
qsub: waiting for job 308834.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov to start
qsub: job 308834.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov ready

### Human: How do I start an interactive job mode on Polaris compute nodes and run CUDA-gdb?

### Assistant: Start an interactive job mode on Polaris using `qsub -I -l select=1 -l walltime=1:00:00`, then run `cuda-gdb --version` and finally `cuda-gdb foo`.
    "
"
### Context: 
CMake

CMake

CMake is a build configuration system that uses higher-level description files
to automatically generate Makefiles.

CMake Documentation

CMake website

CMake on Polaris

To use CMake on Polaris, run

module use /soft/modulefiles
module load spack-pe-base cmake

### Human: What is CMake used for?

### Assistant: CMake is used for building and configuring software projects.
    "
"
### Context: 
CMake

CMake

CMake is a build configuration system that uses higher-level description files
to automatically generate Makefiles.

CMake Documentation

CMake website

CMake on Polaris

To use CMake on Polaris, run

module use /soft/modulefiles
module load spack-pe-base cmake

### Human: How do you install CMake on Polaris?

### Assistant: module use /soft/modulefiles; module load spack-pe-base cmake
    "
"
### Context: 
CMake

CMake

CMake is a build configuration system that uses higher-level description files
to automatically generate Makefiles.

CMake Documentation

CMake website

CMake on Polaris

To use CMake on Polaris, run

module use /soft/modulefiles
module load spack-pe-base cmake

### Human: What type of files does CMake generate?

### Assistant: CMake generates Makefiles and other build-related files.
    "
"
### Context: 
Visualization on Polaris

Starting in January 2024, Polaris will serve as the primary production resource for visualization and analysis.

Below is a list of the available visualization tools along with links to their corresponding documentation.

ParaView: ParaView is an open-source visualization engine that seamlessly integrates with your existing tools and workflows. It allows you to construct visualization pipelines for quick data analysis. Whether interactively exploring large datasets in 3D or performing batch processing programmatically, ParaView provides versatile capabilities. For additional information, visit the Kitware website.

VisIt: VisIt is an open-source, interactive, and scalable visualization, animation, and analysis tool. Users can rapidly generate visualizations, animate them over time, apply various operators and mathematical expressions, and save resulting images and animations for presentations. VisIt supports a diverse range of visualization features, enabling users to view data, including scalar and vector fields, on 2D and 3D structured, adaptive, and unstructured meshes. Thanks to its customizable plugin design, VisIt can visualize data from over 120 different scientific data formats. For more information, check the VisIt project GitHub page.

FFmpeg: FFmpeg is a complete solution to record, convert, and stream audio and video. For more information, visit the FFmpeg webpage

ImageMagick: ImageMagick is a free, open-source software suite, used for editing and manipulating digital images. It can be used to create, edit, compose, or convert bitmap images, and supports a wide range of file formats, including JPEG, PNG, GIF, TIFF, and PDF. More information in the ImageMagick webpage.

### Human: What is the primary purpose of the ParaView tool within the Polaris resource?

### Assistant: The primary purpose of ParaView is to facilitate data analysis through visualization.
    "
"
### Context: 
Visualization on Polaris

Starting in January 2024, Polaris will serve as the primary production resource for visualization and analysis.

Below is a list of the available visualization tools along with links to their corresponding documentation.

ParaView: ParaView is an open-source visualization engine that seamlessly integrates with your existing tools and workflows. It allows you to construct visualization pipelines for quick data analysis. Whether interactively exploring large datasets in 3D or performing batch processing programmatically, ParaView provides versatile capabilities. For additional information, visit the Kitware website.

VisIt: VisIt is an open-source, interactive, and scalable visualization, animation, and analysis tool. Users can rapidly generate visualizations, animate them over time, apply various operators and mathematical expressions, and save resulting images and animations for presentations. VisIt supports a diverse range of visualization features, enabling users to view data, including scalar and vector fields, on 2D and 3D structured, adaptive, and unstructured meshes. Thanks to its customizable plugin design, VisIt can visualize data from over 120 different scientific data formats. For more information, check the VisIt project GitHub page.

FFmpeg: FFmpeg is a complete solution to record, convert, and stream audio and video. For more information, visit the FFmpeg webpage

ImageMagick: ImageMagick is a free, open-source software suite, used for editing and manipulating digital images. It can be used to create, edit, compose, or convert bitmap images, and supports a wide range of file formats, including JPEG, PNG, GIF, TIFF, and PDF. More information in the ImageMagick webpage.

### Human: Which of the available visualization tools on Polaris allows for rapid generation of visualizations and animation over time?

### Assistant: VisIt
    "
"
### Context: 
Visualization on Polaris

Starting in January 2024, Polaris will serve as the primary production resource for visualization and analysis.

Below is a list of the available visualization tools along with links to their corresponding documentation.

ParaView: ParaView is an open-source visualization engine that seamlessly integrates with your existing tools and workflows. It allows you to construct visualization pipelines for quick data analysis. Whether interactively exploring large datasets in 3D or performing batch processing programmatically, ParaView provides versatile capabilities. For additional information, visit the Kitware website.

VisIt: VisIt is an open-source, interactive, and scalable visualization, animation, and analysis tool. Users can rapidly generate visualizations, animate them over time, apply various operators and mathematical expressions, and save resulting images and animations for presentations. VisIt supports a diverse range of visualization features, enabling users to view data, including scalar and vector fields, on 2D and 3D structured, adaptive, and unstructured meshes. Thanks to its customizable plugin design, VisIt can visualize data from over 120 different scientific data formats. For more information, check the VisIt project GitHub page.

FFmpeg: FFmpeg is a complete solution to record, convert, and stream audio and video. For more information, visit the FFmpeg webpage

ImageMagick: ImageMagick is a free, open-source software suite, used for editing and manipulating digital images. It can be used to create, edit, compose, or convert bitmap images, and supports a wide range of file formats, including JPEG, PNG, GIF, TIFF, and PDF. More information in the ImageMagick webpage.

### Human: Can you use FFmpeg on Polaris to stream audio and video in addition to converting and recording formats?

### Assistant: Yes, you can use FFmpeg on Polaris to stream audio and video in addition to converting and recording formats.
    "
"
### Context: 
ParaView on Polaris

The recommended way of running ParaView on Polaris is in client/server mode. This consists of running the ParaView client on your local resource, and the ParaView server on the Polaris compute nodes. The ParaView client needs to first be installed on your local resource, and needs to match the version that you run on Polaris.

There are multiple versions of ParaView installed on Polaris. To find the versions of ParaView currently available on Polaris run the following command on a login node: 
module use /soft/modulefiles
module avail paraview

Binary and source packages of the ParaView client for Linux, MacOS, and Windows are available from the ParaView Download Page.

Connecting to the ParaView server on Polaris

This section describes how to launch the ParaView server on Polaris from a local ParaView client.

Start ParaView Client

First, launch the ParaView client on your local resource. You will need to configure some server settings in the client. This initial set up should only need to be done once, and can be reused each time you want to run ParaView on Polaris.

Server Configuration

1. Select Connect

From the ParaView client choose to connect to a server by either clicking on the ""Connect"" icon in the menu bar

or selecting File->Connect from the main menu

2. Set Up Servers (first time only)

The first time you want to run a server on Polaris and have it connect to your local ParaView client, you will need to set up a Server. Once this server is set up, you can reuse it each time you run the ParaView client with the ParaView server on Polaris.

Kitware, the developers of ParaView, maintain a database of server configurations which you can retrieve through the ParaView client. In the File->Connect menu press the button named ""Fetch Servers"" and select POLARIS@ANL. Windows users should select ""windows to POLARIS@ANL"". Press ""Import Selected""

3. Use ParaView

### Human: What is the recommended way of running ParaView on Polaris?

### Assistant: The recommended way of running ParaView on Polaris is in client/server mode by launching the ParaView client on your local resource and setting up a Server configuration.
    "
"
### Context: 
ParaView on Polaris

The recommended way of running ParaView on Polaris is in client/server mode. This consists of running the ParaView client on your local resource, and the ParaView server on the Polaris compute nodes. The ParaView client needs to first be installed on your local resource, and needs to match the version that you run on Polaris.

There are multiple versions of ParaView installed on Polaris. To find the versions of ParaView currently available on Polaris run the following command on a login node: 
module use /soft/modulefiles
module avail paraview

Binary and source packages of the ParaView client for Linux, MacOS, and Windows are available from the ParaView Download Page.

Connecting to the ParaView server on Polaris

This section describes how to launch the ParaView server on Polaris from a local ParaView client.

Start ParaView Client

First, launch the ParaView client on your local resource. You will need to configure some server settings in the client. This initial set up should only need to be done once, and can be reused each time you want to run ParaView on Polaris.

Server Configuration

1. Select Connect

From the ParaView client choose to connect to a server by either clicking on the ""Connect"" icon in the menu bar

or selecting File->Connect from the main menu

2. Set Up Servers (first time only)

The first time you want to run a server on Polaris and have it connect to your local ParaView client, you will need to set up a Server. Once this server is set up, you can reuse it each time you run the ParaView client with the ParaView server on Polaris.

Kitware, the developers of ParaView, maintain a database of server configurations which you can retrieve through the ParaView client. In the File->Connect menu press the button named ""Fetch Servers"" and select POLARIS@ANL. Windows users should select ""windows to POLARIS@ANL"". Press ""Import Selected""

3. Use ParaView

### Human: How do I find the available versions of ParaView on Polaris?

### Assistant: The available versions of ParaView on Polaris can be found by running `module use /soft/modulefiles` and then `module avail paraview`.
    "
"
### Context: 
ParaView on Polaris

The recommended way of running ParaView on Polaris is in client/server mode. This consists of running the ParaView client on your local resource, and the ParaView server on the Polaris compute nodes. The ParaView client needs to first be installed on your local resource, and needs to match the version that you run on Polaris.

There are multiple versions of ParaView installed on Polaris. To find the versions of ParaView currently available on Polaris run the following command on a login node: 
module use /soft/modulefiles
module avail paraview

Binary and source packages of the ParaView client for Linux, MacOS, and Windows are available from the ParaView Download Page.

Connecting to the ParaView server on Polaris

This section describes how to launch the ParaView server on Polaris from a local ParaView client.

Start ParaView Client

First, launch the ParaView client on your local resource. You will need to configure some server settings in the client. This initial set up should only need to be done once, and can be reused each time you want to run ParaView on Polaris.

Server Configuration

1. Select Connect

From the ParaView client choose to connect to a server by either clicking on the ""Connect"" icon in the menu bar

or selecting File->Connect from the main menu

2. Set Up Servers (first time only)

The first time you want to run a server on Polaris and have it connect to your local ParaView client, you will need to set up a Server. Once this server is set up, you can reuse it each time you run the ParaView client with the ParaView server on Polaris.

Kitware, the developers of ParaView, maintain a database of server configurations which you can retrieve through the ParaView client. In the File->Connect menu press the button named ""Fetch Servers"" and select POLARIS@ANL. Windows users should select ""windows to POLARIS@ANL"". Press ""Import Selected""

3. Use ParaView

### Human: What should I do to connect my local ParaView client to the ParaView server on Polaris for the first time setup?

### Assistant: To connect your local ParaView client to the ParaView server on Polaris for the first time setup, start the ParaView client, configure some server settings, set up a Server (first time only), and fetch servers by selecting POLARIS@ANL.
    "
"
### Context: 
3. Use ParaView

After the previous step, you can now select POLARIS@ANL in the File->Connect menu and press Connect

At this point a new window will pop up

There are a number of parameters that you must enter manually here:

Xterm executable: the path of a terminal on your system. The figure shows the case of a Mac with XQuartz. You may need to change these values for Windows or Linux.

SSH executable: the name of your ssh command. It may be different on Windows depending on the ssh client installed (i.e putty)

Remote machine: leave this value at polaris.alcf.anl.gov

Username: your ALCF user name

ParaView version: the version of Paraview that you want to use. Verify first that this version is installed on the system (as described at the top of this document). You will also need to add a -EGL suffix.

Example:
5.12.0-EGL

Client port: it is safe to use the default value

Server port: is is safe to use the default value

Number of nodes to reserve: enter the number of Polaris compute nodes you want to use for your job

Number of ranks per node: enter the number of ranks per node

Number of minutes to reserve: the duration of your job in minutes

Account: enter here the name of your ALCF allocation

Queue: the name of the Polaris queue you would like to use (i.e: debug for small, quick jobs, prod, preemptable)

File Systems: enter here the file systems you need for your job, separated with colons, no spaces. Keep in mind that your job may not run if one of these file systems is not available at that time, so enter these values carefully

Job name: safe to use default value. The PBS scheduler will assign this name to your job

Now you can press OK to establish the connection with a ParaView server on Polaris.

An ssh connection will be established with a Polaris login node and a password will be requested in a terminal, similar to the process you normally use to connect and work on the system.

### Human: What parameters need to be entered manually when connecting to POLARIS@ANL in ParaView?

### Assistant: Xterm executable, SSH executable, Remote machine, Username, ParaView version, Number of nodes to reserve, Number of ranks per node, Number of minutes to reserve, Account, Queue, File Systems, and Job name.
    "
"
### Context: 
3. Use ParaView

After the previous step, you can now select POLARIS@ANL in the File->Connect menu and press Connect

At this point a new window will pop up

There are a number of parameters that you must enter manually here:

Xterm executable: the path of a terminal on your system. The figure shows the case of a Mac with XQuartz. You may need to change these values for Windows or Linux.

SSH executable: the name of your ssh command. It may be different on Windows depending on the ssh client installed (i.e putty)

Remote machine: leave this value at polaris.alcf.anl.gov

Username: your ALCF user name

ParaView version: the version of Paraview that you want to use. Verify first that this version is installed on the system (as described at the top of this document). You will also need to add a -EGL suffix.

Example:
5.12.0-EGL

Client port: it is safe to use the default value

Server port: is is safe to use the default value

Number of nodes to reserve: enter the number of Polaris compute nodes you want to use for your job

Number of ranks per node: enter the number of ranks per node

Number of minutes to reserve: the duration of your job in minutes

Account: enter here the name of your ALCF allocation

Queue: the name of the Polaris queue you would like to use (i.e: debug for small, quick jobs, prod, preemptable)

File Systems: enter here the file systems you need for your job, separated with colons, no spaces. Keep in mind that your job may not run if one of these file systems is not available at that time, so enter these values carefully

Job name: safe to use default value. The PBS scheduler will assign this name to your job

Now you can press OK to establish the connection with a ParaView server on Polaris.

An ssh connection will be established with a Polaris login node and a password will be requested in a terminal, similar to the process you normally use to connect and work on the system.

### Human: How do I specify the number of nodes to reserve and ranks per node when submitting a job in ParaView?

### Assistant: Number of nodes to reserve: <number>, Number of ranks per node: <number>.
    "
"
### Context: 
3. Use ParaView

After the previous step, you can now select POLARIS@ANL in the File->Connect menu and press Connect

At this point a new window will pop up

There are a number of parameters that you must enter manually here:

Xterm executable: the path of a terminal on your system. The figure shows the case of a Mac with XQuartz. You may need to change these values for Windows or Linux.

SSH executable: the name of your ssh command. It may be different on Windows depending on the ssh client installed (i.e putty)

Remote machine: leave this value at polaris.alcf.anl.gov

Username: your ALCF user name

ParaView version: the version of Paraview that you want to use. Verify first that this version is installed on the system (as described at the top of this document). You will also need to add a -EGL suffix.

Example:
5.12.0-EGL

Client port: it is safe to use the default value

Server port: is is safe to use the default value

Number of nodes to reserve: enter the number of Polaris compute nodes you want to use for your job

Number of ranks per node: enter the number of ranks per node

Number of minutes to reserve: the duration of your job in minutes

Account: enter here the name of your ALCF allocation

Queue: the name of the Polaris queue you would like to use (i.e: debug for small, quick jobs, prod, preemptable)

File Systems: enter here the file systems you need for your job, separated with colons, no spaces. Keep in mind that your job may not run if one of these file systems is not available at that time, so enter these values carefully

Job name: safe to use default value. The PBS scheduler will assign this name to your job

Now you can press OK to establish the connection with a ParaView server on Polaris.

An ssh connection will be established with a Polaris login node and a password will be requested in a terminal, similar to the process you normally use to connect and work on the system.

### Human: What are some important things to consider when entering file systems for a job in ParaView?

### Assistant: File Systems to be entered are the ones required for your job, separated with colons and no spaces.
    "
"
### Context: 
After you enter your password, a job will be queued and you will see a window like this:

When the job is launched on the compute nodes, the previous window will go away and ParaView will show it is connected to Polaris in its Pipeline Browser:

At this point you can open datasets stored on the ALCF file systems and use ParaView normally.

Additional Information

ParaView Documentation

ParaView Community Support

### Human: What happens after entering your password in the job queueing system?

### Assistant: The job is queued, the previous window goes away, and ParaView shows it is connected to Polaris in its Pipeline Browser.
    "
"
### Context: 
After you enter your password, a job will be queued and you will see a window like this:

When the job is launched on the compute nodes, the previous window will go away and ParaView will show it is connected to Polaris in its Pipeline Browser:

At this point you can open datasets stored on the ALCF file systems and use ParaView normally.

Additional Information

ParaView Documentation

ParaView Community Support

### Human: How do I connect to Polaris using ParaView's Pipeline Browser?

### Assistant: Connect by launching a job on the compute nodes.
    "
"
### Context: 
After you enter your password, a job will be queued and you will see a window like this:

When the job is launched on the compute nodes, the previous window will go away and ParaView will show it is connected to Polaris in its Pipeline Browser:

At this point you can open datasets stored on the ALCF file systems and use ParaView normally.

Additional Information

ParaView Documentation

ParaView Community Support

### Human: Where can you store and open datasets using ParaView?

### Assistant: You can store and open datasets using ParaView by storing them on the ALCF file systems and then opening them after connecting to Polaris in the Pipeline Browser.
    "
"
### Context: 
ParaView Tutorial

Overview

This tutorial is intended to be a hands-on resource for users interested in learning the basic concepts of ParaView. The examples can easily be run on a laptop, using the example data set provided.

Tour of ParaView

Show range of visualization methods

Walk through various visualization techniques, hopefully illustrate how these can apply to your own data

Feel for ParaView ""way""

Terminology and step-by-step process peculiar to ParaView, which may differ from other packages, e.g. VisIt

Data

The data used for this tutorial is:
- Blood flow simulation data
- Multiple data types
  - Continuum data field (unstructured mesh, tetrahedral): fluid field, plasma
  - Particle data (unstructured points): individual particles moving in the flow
  - Red Blood Cells (RBC, unstructured mesh, triangle): mesh of the surface of an RBC
    - Healthy
    - Diseased
- Generated using an integrated Nektar/LAMMPS simulation code
- Courtesy of George Karniadakis and Leopold Grinberg of Brown University

The data is available for download here (~27MB compressed, ~39MB uncompressed):
Data set for ParaView Red Blood Cell Tutorial

1. Load Multi-component Dataset

From the Filemenu, (you can also click the file folder icon, shown above) open each of the following data sets (select then click ""OK"")

The files will then appear in the Pipeline Browser

Click Apply in the Object Inspector

You will need to do this one at a time:

continuum...vtu

particles...vtu

rbc_...vtu

bad_rbc...vtu
Note: The ""..."" in the name, and the arrow in the file browser, indicates that there are multiple time steps for each of these files

2. Select which data to view

### Human: What types of data formats can I load into ParaView?

### Assistant: VTK (VTU) files, which include continuum data fields (unstructured mesh, tetrahedral), particle data (unstructured points), and Red Blood Cells (RBC, unstructured mesh, triangle).
    "
"
### Context: 
ParaView Tutorial

Overview

This tutorial is intended to be a hands-on resource for users interested in learning the basic concepts of ParaView. The examples can easily be run on a laptop, using the example data set provided.

Tour of ParaView

Show range of visualization methods

Walk through various visualization techniques, hopefully illustrate how these can apply to your own data

Feel for ParaView ""way""

Terminology and step-by-step process peculiar to ParaView, which may differ from other packages, e.g. VisIt

Data

The data used for this tutorial is:
- Blood flow simulation data
- Multiple data types
  - Continuum data field (unstructured mesh, tetrahedral): fluid field, plasma
  - Particle data (unstructured points): individual particles moving in the flow
  - Red Blood Cells (RBC, unstructured mesh, triangle): mesh of the surface of an RBC
    - Healthy
    - Diseased
- Generated using an integrated Nektar/LAMMPS simulation code
- Courtesy of George Karniadakis and Leopold Grinberg of Brown University

The data is available for download here (~27MB compressed, ~39MB uncompressed):
Data set for ParaView Red Blood Cell Tutorial

1. Load Multi-component Dataset

From the Filemenu, (you can also click the file folder icon, shown above) open each of the following data sets (select then click ""OK"")

The files will then appear in the Pipeline Browser

Click Apply in the Object Inspector

You will need to do this one at a time:

continuum...vtu

particles...vtu

rbc_...vtu

bad_rbc...vtu
Note: The ""..."" in the name, and the arrow in the file browser, indicates that there are multiple time steps for each of these files

2. Select which data to view

### Human: How do I apply visualization techniques in ParaView to my own data set?

### Assistant: To apply visualization techniques in ParaView to your own data set, load your multi-component dataset, select which data to view, apply visualization techniques, customize your view, and save your visualization.
    "
"
### Context: 
ParaView Tutorial

Overview

This tutorial is intended to be a hands-on resource for users interested in learning the basic concepts of ParaView. The examples can easily be run on a laptop, using the example data set provided.

Tour of ParaView

Show range of visualization methods

Walk through various visualization techniques, hopefully illustrate how these can apply to your own data

Feel for ParaView ""way""

Terminology and step-by-step process peculiar to ParaView, which may differ from other packages, e.g. VisIt

Data

The data used for this tutorial is:
- Blood flow simulation data
- Multiple data types
  - Continuum data field (unstructured mesh, tetrahedral): fluid field, plasma
  - Particle data (unstructured points): individual particles moving in the flow
  - Red Blood Cells (RBC, unstructured mesh, triangle): mesh of the surface of an RBC
    - Healthy
    - Diseased
- Generated using an integrated Nektar/LAMMPS simulation code
- Courtesy of George Karniadakis and Leopold Grinberg of Brown University

The data is available for download here (~27MB compressed, ~39MB uncompressed):
Data set for ParaView Red Blood Cell Tutorial

1. Load Multi-component Dataset

From the Filemenu, (you can also click the file folder icon, shown above) open each of the following data sets (select then click ""OK"")

The files will then appear in the Pipeline Browser

Click Apply in the Object Inspector

You will need to do this one at a time:

continuum...vtu

particles...vtu

rbc_...vtu

bad_rbc...vtu
Note: The ""..."" in the name, and the arrow in the file browser, indicates that there are multiple time steps for each of these files

2. Select which data to view

### Human: Can I select multiple time steps for each data file when loading it into ParaView?

### Assistant: Yes, you can select multiple time steps for each data file when loading it into ParaView.
    "
"
### Context: 
2. Select which data to view

Let's start by looking at the continuum.000*data. This is an unstructured mesh that has velocity and count (density) values.
- Hide other data sets using the Eyeball icon next their names in the Pipeline Browser.
  - Black = visible, Grey = hidden
- Select continuum.000*(name is highlighted) in the Pipeline Browser
  - Click on the name to highlight it
- When manipulating appearance or applying filters, these always affect the selected data set
- Switch to the Display tab in the Object Inspector
- Under Color by, select Velocity from the dropdown
  - There is also a shortcut to Color by in the menu bar near the top of the GUI
  -

3. Manipulating the Color Map

To change the colors used to represent the Velocity:
- Under Color byclick the Edit Color Map... button
- On the Color Scale Editor window click the Choose Preset button
- On the Preset Color Scales window, select: Blue to Red Rainbow, and click OK. Then click Close on the Color Scale Editor window
- You can also create and save your own color maps

4. Data Representation

In order to be able to see the particles and red blood cells inside the cylinder, we need to be able to see through it. If we scroll down a bit in the Object Inspector view:
- Group of controls labeled Style
- In the Representation dropdown, select Wireframe

5. Generate Streamlines

ParaView enables the generation of different types of data from existing data sets in the Pipeline

Streamlines: Generated from vectors of the flow field. These curves show the direction a fluid element will travel in at any point in time

Make sure that the continuum.000*data is selected in the Pipeline Browser

From the main menu select: Filters->Alphabetical->Stream Tracer, or click on the Stream Tracer icon from the menu bar

In the Object Inspector make sure the Properties tab is selected.

Scroll down to seeds, and change Seed Type to Line Source

Click the Y Axis button to set the seed line to run along the Y axis.

### Human: What is the purpose of selecting the 'Wireframe' representation in the Style group of controls?

### Assistant: The purpose is to allow visualization of internal structures.
    "
"
### Context: 
2. Select which data to view

Let's start by looking at the continuum.000*data. This is an unstructured mesh that has velocity and count (density) values.
- Hide other data sets using the Eyeball icon next their names in the Pipeline Browser.
  - Black = visible, Grey = hidden
- Select continuum.000*(name is highlighted) in the Pipeline Browser
  - Click on the name to highlight it
- When manipulating appearance or applying filters, these always affect the selected data set
- Switch to the Display tab in the Object Inspector
- Under Color by, select Velocity from the dropdown
  - There is also a shortcut to Color by in the menu bar near the top of the GUI
  -

3. Manipulating the Color Map

To change the colors used to represent the Velocity:
- Under Color byclick the Edit Color Map... button
- On the Color Scale Editor window click the Choose Preset button
- On the Preset Color Scales window, select: Blue to Red Rainbow, and click OK. Then click Close on the Color Scale Editor window
- You can also create and save your own color maps

4. Data Representation

In order to be able to see the particles and red blood cells inside the cylinder, we need to be able to see through it. If we scroll down a bit in the Object Inspector view:
- Group of controls labeled Style
- In the Representation dropdown, select Wireframe

5. Generate Streamlines

ParaView enables the generation of different types of data from existing data sets in the Pipeline

Streamlines: Generated from vectors of the flow field. These curves show the direction a fluid element will travel in at any point in time

Make sure that the continuum.000*data is selected in the Pipeline Browser

From the main menu select: Filters->Alphabetical->Stream Tracer, or click on the Stream Tracer icon from the menu bar

In the Object Inspector make sure the Properties tab is selected.

Scroll down to seeds, and change Seed Type to Line Source

Click the Y Axis button to set the seed line to run along the Y axis.

### Human: How do you change the color map to represent velocity data in ParaView?

### Assistant: Change color map to represent velocity data by selecting Velocity in the Color by dropdown and choosing a preset color scale.
    "
"
### Context: 
2. Select which data to view

Let's start by looking at the continuum.000*data. This is an unstructured mesh that has velocity and count (density) values.
- Hide other data sets using the Eyeball icon next their names in the Pipeline Browser.
  - Black = visible, Grey = hidden
- Select continuum.000*(name is highlighted) in the Pipeline Browser
  - Click on the name to highlight it
- When manipulating appearance or applying filters, these always affect the selected data set
- Switch to the Display tab in the Object Inspector
- Under Color by, select Velocity from the dropdown
  - There is also a shortcut to Color by in the menu bar near the top of the GUI
  -

3. Manipulating the Color Map

To change the colors used to represent the Velocity:
- Under Color byclick the Edit Color Map... button
- On the Color Scale Editor window click the Choose Preset button
- On the Preset Color Scales window, select: Blue to Red Rainbow, and click OK. Then click Close on the Color Scale Editor window
- You can also create and save your own color maps

4. Data Representation

In order to be able to see the particles and red blood cells inside the cylinder, we need to be able to see through it. If we scroll down a bit in the Object Inspector view:
- Group of controls labeled Style
- In the Representation dropdown, select Wireframe

5. Generate Streamlines

ParaView enables the generation of different types of data from existing data sets in the Pipeline

Streamlines: Generated from vectors of the flow field. These curves show the direction a fluid element will travel in at any point in time

Make sure that the continuum.000*data is selected in the Pipeline Browser

From the main menu select: Filters->Alphabetical->Stream Tracer, or click on the Stream Tracer icon from the menu bar

In the Object Inspector make sure the Properties tab is selected.

Scroll down to seeds, and change Seed Type to Line Source

Click the Y Axis button to set the seed line to run along the Y axis.

### Human: What type of data can be generated from existing data sets using ParaView's Stream Tracer filter?

### Assistant: Streamlines.
    "
"
### Context: 
Click the Y Axis button to set the seed line to run along the Y axis.

The default Resolution is set to 100. This will make things a bit cluttered, especially when we start adding in the other data, so let's reduce this to 25

Click the Apply button

6. Streamlines as Tubes

The streamlines are just that, lines. We can use the Tubes filter to represent them as 3D objects, rather than just lines.
- With StreamTracer1selected in the Pipeline Browser, from the main menu select: Filters->Alphabetical->Tube
- In the Object Inspector make sure the Properties tab is selected
- The default value for the Radius is a bit too large for this data, let's set that value to 0
- Click the Apply button
- Notice that the StreamLine1 object has automatically been hidden
- There are many different ways to color these tubes
- With Tubes1 selected, switch to the Display tab in the Object Inspector
- The Color bydropdown lets you choose from a handful of different variables

7. Cutting Planes (Slices)

Now let's add some cutting plans, or slices, to see what the cross-section of the continuum data looks like.
- Again, be sure that the continuum.000*data is selected in the Pipeline Browser
- Filters->Alphabetical->Slice or Click on the Slice icon from the menu bar
- In the Object Inspector make sure the Propertiestab is selected
- At the bottom on the Object Inspector is a section titled Slice Offset Values. Here we can generate values for multiple slices to be made
- First click the Delete All button to remove initial values
- Next, click the New Range button. This will bring up an Add Range dialog box.
- Set the number of Steps to 7. Click OK
- Click the Apply button
- With Slice1 selected in the Object Inspector, switch to the Display tab
- Set Color by value to Velocity

8. Data Representation: Opacity

### Human: How do you represent streamlines as tubes in VTK?

### Assistant: Represent streamlines as tubes by selecting StreamTracer1, going to Filters > Alphabetical > Tube, setting Radius to 0, applying changes, and choosing a color variable.
    "
"
### Context: 
Click the Y Axis button to set the seed line to run along the Y axis.

The default Resolution is set to 100. This will make things a bit cluttered, especially when we start adding in the other data, so let's reduce this to 25

Click the Apply button

6. Streamlines as Tubes

The streamlines are just that, lines. We can use the Tubes filter to represent them as 3D objects, rather than just lines.
- With StreamTracer1selected in the Pipeline Browser, from the main menu select: Filters->Alphabetical->Tube
- In the Object Inspector make sure the Properties tab is selected
- The default value for the Radius is a bit too large for this data, let's set that value to 0
- Click the Apply button
- Notice that the StreamLine1 object has automatically been hidden
- There are many different ways to color these tubes
- With Tubes1 selected, switch to the Display tab in the Object Inspector
- The Color bydropdown lets you choose from a handful of different variables

7. Cutting Planes (Slices)

Now let's add some cutting plans, or slices, to see what the cross-section of the continuum data looks like.
- Again, be sure that the continuum.000*data is selected in the Pipeline Browser
- Filters->Alphabetical->Slice or Click on the Slice icon from the menu bar
- In the Object Inspector make sure the Propertiestab is selected
- At the bottom on the Object Inspector is a section titled Slice Offset Values. Here we can generate values for multiple slices to be made
- First click the Delete All button to remove initial values
- Next, click the New Range button. This will bring up an Add Range dialog box.
- Set the number of Steps to 7. Click OK
- Click the Apply button
- With Slice1 selected in the Object Inspector, switch to the Display tab
- Set Color by value to Velocity

8. Data Representation: Opacity

### Human: Can you show me how to add cutting planes or slices to visualize cross-sectional data in VTK?

### Assistant: To add cutting planes or slices to visualize cross-sectional data in VTK, select the continuum.000*data, reduce the resolution, use the Tubes filter, add a Slice filter, set the Slice Offset Values, and adjust the Color by value and opacity as needed.
    "
"
### Context: 
Click the Y Axis button to set the seed line to run along the Y axis.

The default Resolution is set to 100. This will make things a bit cluttered, especially when we start adding in the other data, so let's reduce this to 25

Click the Apply button

6. Streamlines as Tubes

The streamlines are just that, lines. We can use the Tubes filter to represent them as 3D objects, rather than just lines.
- With StreamTracer1selected in the Pipeline Browser, from the main menu select: Filters->Alphabetical->Tube
- In the Object Inspector make sure the Properties tab is selected
- The default value for the Radius is a bit too large for this data, let's set that value to 0
- Click the Apply button
- Notice that the StreamLine1 object has automatically been hidden
- There are many different ways to color these tubes
- With Tubes1 selected, switch to the Display tab in the Object Inspector
- The Color bydropdown lets you choose from a handful of different variables

7. Cutting Planes (Slices)

Now let's add some cutting plans, or slices, to see what the cross-section of the continuum data looks like.
- Again, be sure that the continuum.000*data is selected in the Pipeline Browser
- Filters->Alphabetical->Slice or Click on the Slice icon from the menu bar
- In the Object Inspector make sure the Propertiestab is selected
- At the bottom on the Object Inspector is a section titled Slice Offset Values. Here we can generate values for multiple slices to be made
- First click the Delete All button to remove initial values
- Next, click the New Range button. This will bring up an Add Range dialog box.
- Set the number of Steps to 7. Click OK
- Click the Apply button
- With Slice1 selected in the Object Inspector, switch to the Display tab
- Set Color by value to Velocity

8. Data Representation: Opacity

### Human: What are some ways to color the tubes in VTK, and how do you change the opacity of data representations?

### Assistant: To change the opacity of data representations, adjust the Opacity value in the Display tab of the Object Inspector.
    "
"
### Context: 
8. Data Representation: Opacity

Even with the continuum data represented as wireframe, there is still considerable occlusion of the interior structures. In order to further reduce this occlusion by the wireframe, we can make it more transparent.

Again, be sure that the continuum.000*data is selected in the Pipeline Browser

In the Object Inspector make sure the Display tab is selected

In the Object Inspector there is a section titled Style

Set Opacity to 0.2

9. Animating Simulation Data

Since our data has multiple time steps, we can easily animate through them to see how the data changes over time.

Simply click the Play button on the animation bar at the top of the GUI

Pause to make it stop

Loop: With this button toggled on, animation will repeat until stopped

10. Animations

Animations can be saved to disk as a movie file, to be played back later.

From the main menu: File->Save Animation

Animation Settings Dialog: Save Animation

Files of type: AVI files (*.avi)

Enter a name in File name:

Click OK

Movie can be played back with standard media players (Windows Media Player, QuickTime, VLC, etc.)

11. Particles as Glyphs

Glyphs are another way of visually representing data where the attributes of a graphical element are dictated by attributes of the data.

All of the particles are displayed as red points in the graphics window. There are ~39K particles in this particular data set, which makes the display a bit cluttered. In order to both filter some of these out, and create 3D representations for them, let's apply a glyph filter to this data.

Now let's add some of our other data back into the scene. Let's start with the particle data.

All of the particles are displayed as red points in the graphics window. There are ~39K particles in this particular data set, which makes the display rather cluttered. In order to both filter some of these out, and create 3D representations for them, we will apply the glyph filter to this data.

### Human: How can I reduce occlusion by the wireframe in continuum data representation?

### Assistant: Reduce occlusion by setting Wireframe Opacity to 0.2.
    "
"
### Context: 
8. Data Representation: Opacity

Even with the continuum data represented as wireframe, there is still considerable occlusion of the interior structures. In order to further reduce this occlusion by the wireframe, we can make it more transparent.

Again, be sure that the continuum.000*data is selected in the Pipeline Browser

In the Object Inspector make sure the Display tab is selected

In the Object Inspector there is a section titled Style

Set Opacity to 0.2

9. Animating Simulation Data

Since our data has multiple time steps, we can easily animate through them to see how the data changes over time.

Simply click the Play button on the animation bar at the top of the GUI

Pause to make it stop

Loop: With this button toggled on, animation will repeat until stopped

10. Animations

Animations can be saved to disk as a movie file, to be played back later.

From the main menu: File->Save Animation

Animation Settings Dialog: Save Animation

Files of type: AVI files (*.avi)

Enter a name in File name:

Click OK

Movie can be played back with standard media players (Windows Media Player, QuickTime, VLC, etc.)

11. Particles as Glyphs

Glyphs are another way of visually representing data where the attributes of a graphical element are dictated by attributes of the data.

All of the particles are displayed as red points in the graphics window. There are ~39K particles in this particular data set, which makes the display a bit cluttered. In order to both filter some of these out, and create 3D representations for them, let's apply a glyph filter to this data.

Now let's add some of our other data back into the scene. Let's start with the particle data.

All of the particles are displayed as red points in the graphics window. There are ~39K particles in this particular data set, which makes the display rather cluttered. In order to both filter some of these out, and create 3D representations for them, we will apply the glyph filter to this data.

### Human: Can animations be saved to disk as a movie file, and how is it done?

### Assistant: To save animations to disk as a movie file, go to ""File"" -> ""Save Animation"", select the file type as AVI files, enter a name for the file, and click OK.
    "
"
### Context: 
8. Data Representation: Opacity

Even with the continuum data represented as wireframe, there is still considerable occlusion of the interior structures. In order to further reduce this occlusion by the wireframe, we can make it more transparent.

Again, be sure that the continuum.000*data is selected in the Pipeline Browser

In the Object Inspector make sure the Display tab is selected

In the Object Inspector there is a section titled Style

Set Opacity to 0.2

9. Animating Simulation Data

Since our data has multiple time steps, we can easily animate through them to see how the data changes over time.

Simply click the Play button on the animation bar at the top of the GUI

Pause to make it stop

Loop: With this button toggled on, animation will repeat until stopped

10. Animations

Animations can be saved to disk as a movie file, to be played back later.

From the main menu: File->Save Animation

Animation Settings Dialog: Save Animation

Files of type: AVI files (*.avi)

Enter a name in File name:

Click OK

Movie can be played back with standard media players (Windows Media Player, QuickTime, VLC, etc.)

11. Particles as Glyphs

Glyphs are another way of visually representing data where the attributes of a graphical element are dictated by attributes of the data.

All of the particles are displayed as red points in the graphics window. There are ~39K particles in this particular data set, which makes the display a bit cluttered. In order to both filter some of these out, and create 3D representations for them, let's apply a glyph filter to this data.

Now let's add some of our other data back into the scene. Let's start with the particle data.

All of the particles are displayed as red points in the graphics window. There are ~39K particles in this particular data set, which makes the display rather cluttered. In order to both filter some of these out, and create 3D representations for them, we will apply the glyph filter to this data.

### Human: What are glyphs in visualizing data, and how do they represent particle data attributes?

### Assistant: Glyphs in visualizing data represent particle data attributes by assigning graphical element attributes to the particles' attributes.
    "
"
### Context: 
Note: that the particles.000* is still visible.

Unhide the particles.000*data: click Eye icon

Select particles.000*data: click on name

Filters->Alphabetical->Glyph or click on the Glyph icon from the menu bar

Glyph Type: Sphere

Radius:. 0.15

Orient: Unchecked

Scale Mode: off

Set Scale Factor: 1 - Edit: Checked

Maximum Number of Points: 3000

Mask Points: Checked

Random Mode: Unchecked

Click the Apply button

Since our goal was to unclutter the display, let's hide the particles.000*by toggling them off, by clicking on the Eye icon next to it in the Pipeline Browser

Let's also switch to the Display tab in the Object Inspector, with Glyph1 selected, and change the Color by value to GlyphVector. Since the GlyphVector value is based on the velocity. We can Edit Color Map...and choose the same Blue to Red Rainbow preset that we previously chose for velocity

12. Enter: Red Blood Cells

Now let's add in both of the other data sets, which are polygonal meshes which make up Red Blood Cells (RBCs).

These two data sets are essentially the same kind of data, so we can apply the same filters and make the same types of representation changes to each of them. However, some of the RBCs are marked by the simulation that generated them as healthy (rbc.000) and some of them are marked as diseased (bad_rbc.000).

Unhide the rbc.000 and bad_rbc.000 data sets by clicking the Eye icon next to each of them to make them visible

13. Using Color to Differentiate Data

To enable us to distinguish these two types of data from one other, we can vary their representations.

One way to do this is by setting the color of the two data sets to different colors. Repeat this process for each of rbc.000 and bad_rbc.000, picking different colors.

Select one of the rbc data sets in the Pipeline Browser

Go to the Displaytab in the Object Inspector

In the Color by:dropdown select Solid Color

Click on the Set Solid Color... button

Select a color from the Select Colordialog that appears

### Human: How do you enable or disable the visibility of particles.000* data in the pipeline browser?

### Assistant: Disable by clicking Eye icon.
    "
"
### Context: 
Note: that the particles.000* is still visible.

Unhide the particles.000*data: click Eye icon

Select particles.000*data: click on name

Filters->Alphabetical->Glyph or click on the Glyph icon from the menu bar

Glyph Type: Sphere

Radius:. 0.15

Orient: Unchecked

Scale Mode: off

Set Scale Factor: 1 - Edit: Checked

Maximum Number of Points: 3000

Mask Points: Checked

Random Mode: Unchecked

Click the Apply button

Since our goal was to unclutter the display, let's hide the particles.000*by toggling them off, by clicking on the Eye icon next to it in the Pipeline Browser

Let's also switch to the Display tab in the Object Inspector, with Glyph1 selected, and change the Color by value to GlyphVector. Since the GlyphVector value is based on the velocity. We can Edit Color Map...and choose the same Blue to Red Rainbow preset that we previously chose for velocity

12. Enter: Red Blood Cells

Now let's add in both of the other data sets, which are polygonal meshes which make up Red Blood Cells (RBCs).

These two data sets are essentially the same kind of data, so we can apply the same filters and make the same types of representation changes to each of them. However, some of the RBCs are marked by the simulation that generated them as healthy (rbc.000) and some of them are marked as diseased (bad_rbc.000).

Unhide the rbc.000 and bad_rbc.000 data sets by clicking the Eye icon next to each of them to make them visible

13. Using Color to Differentiate Data

To enable us to distinguish these two types of data from one other, we can vary their representations.

One way to do this is by setting the color of the two data sets to different colors. Repeat this process for each of rbc.000 and bad_rbc.000, picking different colors.

Select one of the rbc data sets in the Pipeline Browser

Go to the Displaytab in the Object Inspector

In the Color by:dropdown select Solid Color

Click on the Set Solid Color... button

Select a color from the Select Colordialog that appears

### Human: What is the purpose of setting the Scale Factor to 1 and Mask Points while generating spheres as glyphs for particles.000* data?

### Assistant: The purpose of setting the Scale Factor to 1 and Mask Points is to generate spheres as glyphs for particles.000* data, allowing us to visualize the particles more effectively.
    "
"
### Context: 
Note: that the particles.000* is still visible.

Unhide the particles.000*data: click Eye icon

Select particles.000*data: click on name

Filters->Alphabetical->Glyph or click on the Glyph icon from the menu bar

Glyph Type: Sphere

Radius:. 0.15

Orient: Unchecked

Scale Mode: off

Set Scale Factor: 1 - Edit: Checked

Maximum Number of Points: 3000

Mask Points: Checked

Random Mode: Unchecked

Click the Apply button

Since our goal was to unclutter the display, let's hide the particles.000*by toggling them off, by clicking on the Eye icon next to it in the Pipeline Browser

Let's also switch to the Display tab in the Object Inspector, with Glyph1 selected, and change the Color by value to GlyphVector. Since the GlyphVector value is based on the velocity. We can Edit Color Map...and choose the same Blue to Red Rainbow preset that we previously chose for velocity

12. Enter: Red Blood Cells

Now let's add in both of the other data sets, which are polygonal meshes which make up Red Blood Cells (RBCs).

These two data sets are essentially the same kind of data, so we can apply the same filters and make the same types of representation changes to each of them. However, some of the RBCs are marked by the simulation that generated them as healthy (rbc.000) and some of them are marked as diseased (bad_rbc.000).

Unhide the rbc.000 and bad_rbc.000 data sets by clicking the Eye icon next to each of them to make them visible

13. Using Color to Differentiate Data

To enable us to distinguish these two types of data from one other, we can vary their representations.

One way to do this is by setting the color of the two data sets to different colors. Repeat this process for each of rbc.000 and bad_rbc.000, picking different colors.

Select one of the rbc data sets in the Pipeline Browser

Go to the Displaytab in the Object Inspector

In the Color by:dropdown select Solid Color

Click on the Set Solid Color... button

Select a color from the Select Colordialog that appears

### Human: Can you explain how to differentiate between healthy and diseased red blood cells (RBCs) by varying their representations using color?

### Assistant: To differentiate between healthy and diseased red blood cells (RBCs) by varying their representations using color, select one of the rbc data sets in the Pipeline Browser, go to the Display tab in the Object Inspector, set the Color by: dropdown to Solid Color, and choose a color from the Select Color dialog. Repeat this process for each of the rbc.000 and bad_rbc.000 data sets, picking different colors to differentiate between healthy and diseased RBCs.
    "
"
### Context: 
Click on the Set Solid Color... button

Select a color from the Select Colordialog that appears

Repeat for the other RBC data set, choosing a different color

14. Further Exploration: Highlight the Mesh

Change the representation of one of the RBC data sets.

In this example, the continuum.000* data is also hidden to reduce confusion with showing multiple overlapping meshes.

Select on of the RBC data sets

Go to the Displaytab in the Object Inspector

For the Representationselect Surface With Edges

In the Edge Style section click on the Set Edge Color...button to select a different color from the Select Color dialog

15. Further Exploration: Highlight the Vertices

Add glyphs to illustrate the position of the vertices of one of the RBC data sets.

Select one of the RBC data sets

Select the Glyphfilter

Since this filter was used recently, can also be found under: Filters->Recent->Glyph

As in the earlier example, set the various configuration options for the glyph attributes

Note: that this time, we want to show all of the vertices of the RBC, so we should uncheckthe Mask Points option

16. Further Exploration: Color by Variable

Try playing around with the viewing options and representations of the other data objects.

Change the:
- Color by values
- Opacity
- Representation
- Etc.

17. Background Color

Background color is an important part of final visualization

From the main menu choose: Edit->View Settings...

Under General in the View Settings dialog box, select Choose Color

Select Color: OK

Apply, then OK

This tutorial was developed with support from National Science Foundation Grant OCI-0904190, and from the Argonne Leadership Computing Facility at Argonne National Laboratory, which is supported by the Office of Science of the U.S. Department of Energy under contract DE-AC02-06CH11357.

### Human: How do you change the edge color of an RBC data set in ParaView?

### Assistant: Change the edge color by selecting one of the RBC data sets, going to the Display tab in the Object Inspector, selecting Surface With Edges for the Representation, and then clicking on the Set Edge Color button.
    "
"
### Context: 
Click on the Set Solid Color... button

Select a color from the Select Colordialog that appears

Repeat for the other RBC data set, choosing a different color

14. Further Exploration: Highlight the Mesh

Change the representation of one of the RBC data sets.

In this example, the continuum.000* data is also hidden to reduce confusion with showing multiple overlapping meshes.

Select on of the RBC data sets

Go to the Displaytab in the Object Inspector

For the Representationselect Surface With Edges

In the Edge Style section click on the Set Edge Color...button to select a different color from the Select Color dialog

15. Further Exploration: Highlight the Vertices

Add glyphs to illustrate the position of the vertices of one of the RBC data sets.

Select one of the RBC data sets

Select the Glyphfilter

Since this filter was used recently, can also be found under: Filters->Recent->Glyph

As in the earlier example, set the various configuration options for the glyph attributes

Note: that this time, we want to show all of the vertices of the RBC, so we should uncheckthe Mask Points option

16. Further Exploration: Color by Variable

Try playing around with the viewing options and representations of the other data objects.

Change the:
- Color by values
- Opacity
- Representation
- Etc.

17. Background Color

Background color is an important part of final visualization

From the main menu choose: Edit->View Settings...

Under General in the View Settings dialog box, select Choose Color

Select Color: OK

Apply, then OK

This tutorial was developed with support from National Science Foundation Grant OCI-0904190, and from the Argonne Leadership Computing Facility at Argonne National Laboratory, which is supported by the Office of Science of the U.S. Department of Energy under contract DE-AC02-06CH11357.

### Human: What is the purpose of using the ""Surface With Edges"" representation in RBC data visualization?

### Assistant: The purpose of using the ""Surface With Edges"" representation in RBC data visualization is to highlight the edges or boundaries of the surface.
    "
"
### Context: 
Click on the Set Solid Color... button

Select a color from the Select Colordialog that appears

Repeat for the other RBC data set, choosing a different color

14. Further Exploration: Highlight the Mesh

Change the representation of one of the RBC data sets.

In this example, the continuum.000* data is also hidden to reduce confusion with showing multiple overlapping meshes.

Select on of the RBC data sets

Go to the Displaytab in the Object Inspector

For the Representationselect Surface With Edges

In the Edge Style section click on the Set Edge Color...button to select a different color from the Select Color dialog

15. Further Exploration: Highlight the Vertices

Add glyphs to illustrate the position of the vertices of one of the RBC data sets.

Select one of the RBC data sets

Select the Glyphfilter

Since this filter was used recently, can also be found under: Filters->Recent->Glyph

As in the earlier example, set the various configuration options for the glyph attributes

Note: that this time, we want to show all of the vertices of the RBC, so we should uncheckthe Mask Points option

16. Further Exploration: Color by Variable

Try playing around with the viewing options and representations of the other data objects.

Change the:
- Color by values
- Opacity
- Representation
- Etc.

17. Background Color

Background color is an important part of final visualization

From the main menu choose: Edit->View Settings...

Under General in the View Settings dialog box, select Choose Color

Select Color: OK

Apply, then OK

This tutorial was developed with support from National Science Foundation Grant OCI-0904190, and from the Argonne Leadership Computing Facility at Argonne National Laboratory, which is supported by the Office of Science of the U.S. Department of Energy under contract DE-AC02-06CH11357.

### Human: In ParaView, how can you add glyphs to illustrate the position of the vertices in an RBC data set?

### Assistant: Add glyphs by selecting the Glyph filter and configuring its attributes.
    "
"
### Context: 
VisIt on Polaris

Getting Started

The latest VisIt versions installed on Polaris are 3.3.3 and 3.4.0.

Please note that at the time of this writing VisIt version 3.4.0 does not yet have a client for Mac available.

Follow these steps to install VisIt on your local machine:

Download and install VisIt for your local platform (MacOS, Windows, Linux). The version you download must match the server version installed on Polaris. Use this page

Download the Polaris host profile for VisIt (you may need to right-click and choose ""Save link as..."" or ""Save target as..."")

Copy this file to a file called ~/.visit/hosts/host_anl_polaris.xml on Mac or Linux. [ We need to also specify this path for for Windows]

Note: VisIt allows the user to download host profiles for ANL, but all these settings are outdated. We are working with the VisIt developers to update the ANL host list.

Additional information for using VisIt in client/server mode here

Running VisIt

Start up VisIt on your local machine

Click File -> Open File and choose ""ANL Polaris"" from the ""Host"" dropdown

You'll be prompted for your password; enter your ALCF authenticator app response

When you open a selected file, it will launch a job on Polaris
You will need to specify the ""Bank"" (Project) to use when VisIt submits jobs to the queue on Polaris. Specify a project in the Options box.
If your environment doesn't get sourced correctly with non-interactive SSH, you can set the default project to use under Options -> Host profiles

Additional Information

Additional Information

VisIt user manual

VisIt wiki

### Human: What versions of VisIt are available on Polaris?

### Assistant: The available versions of VisIt on Polaris are 3.3.3 and 3.4.0.
    "
"
### Context: 
VisIt on Polaris

Getting Started

The latest VisIt versions installed on Polaris are 3.3.3 and 3.4.0.

Please note that at the time of this writing VisIt version 3.4.0 does not yet have a client for Mac available.

Follow these steps to install VisIt on your local machine:

Download and install VisIt for your local platform (MacOS, Windows, Linux). The version you download must match the server version installed on Polaris. Use this page

Download the Polaris host profile for VisIt (you may need to right-click and choose ""Save link as..."" or ""Save target as..."")

Copy this file to a file called ~/.visit/hosts/host_anl_polaris.xml on Mac or Linux. [ We need to also specify this path for for Windows]

Note: VisIt allows the user to download host profiles for ANL, but all these settings are outdated. We are working with the VisIt developers to update the ANL host list.

Additional information for using VisIt in client/server mode here

Running VisIt

Start up VisIt on your local machine

Click File -> Open File and choose ""ANL Polaris"" from the ""Host"" dropdown

You'll be prompted for your password; enter your ALCF authenticator app response

When you open a selected file, it will launch a job on Polaris
You will need to specify the ""Bank"" (Project) to use when VisIt submits jobs to the queue on Polaris. Specify a project in the Options box.
If your environment doesn't get sourced correctly with non-interactive SSH, you can set the default project to use under Options -> Host profiles

Additional Information

Additional Information

VisIt user manual

VisIt wiki

### Human: How do I set up VisIt on my local machine to access Polaris?

### Assistant: To set up VisIt on your local machine to access Polaris, download and install VisIt for your local platform, copy the Polaris host profile to the correct location, start up VisIt, choose ""ANL Polaris"" from the ""Host"" dropdown, enter your password, and specify the project to use when submitting jobs.
    "
"
### Context: 
VisIt on Polaris

Getting Started

The latest VisIt versions installed on Polaris are 3.3.3 and 3.4.0.

Please note that at the time of this writing VisIt version 3.4.0 does not yet have a client for Mac available.

Follow these steps to install VisIt on your local machine:

Download and install VisIt for your local platform (MacOS, Windows, Linux). The version you download must match the server version installed on Polaris. Use this page

Download the Polaris host profile for VisIt (you may need to right-click and choose ""Save link as..."" or ""Save target as..."")

Copy this file to a file called ~/.visit/hosts/host_anl_polaris.xml on Mac or Linux. [ We need to also specify this path for for Windows]

Note: VisIt allows the user to download host profiles for ANL, but all these settings are outdated. We are working with the VisIt developers to update the ANL host list.

Additional information for using VisIt in client/server mode here

Running VisIt

Start up VisIt on your local machine

Click File -> Open File and choose ""ANL Polaris"" from the ""Host"" dropdown

You'll be prompted for your password; enter your ALCF authenticator app response

When you open a selected file, it will launch a job on Polaris
You will need to specify the ""Bank"" (Project) to use when VisIt submits jobs to the queue on Polaris. Specify a project in the Options box.
If your environment doesn't get sourced correctly with non-interactive SSH, you can set the default project to use under Options -> Host profiles

Additional Information

Additional Information

VisIt user manual

VisIt wiki

### Human: What is required to open a file with VisIt in client/server mode?

### Assistant: To open a file with VisIt in client/server mode, download and install VisIt, download the Polaris host profile, copy it to the correct location on your local machine, start up VisIt, choose ""ANL Polaris"" as the host, enter your password, specify the project, and set the default project if necessary.
    "
"
### Context: 
ImageMagick on Polaris

To use ImageMagick on Polaris first load the corresponding module:

module use /soft/modulefiles
module load spack-pe-base imagemagick

### Human: What software package does the provided tutorial for using ImageMagick on Polaris load?

### Assistant: imagemagick
    "
"
### Context: 
ImageMagick on Polaris

To use ImageMagick on Polaris first load the corresponding module:

module use /soft/modulefiles
module load spack-pe-base imagemagick

### Human: Where can you find the command to load the necessary module for running ImageMagick on Polaris?

### Assistant: module load spack-pe-base imagemagick
    "
"
### Context: 
ImageMagick on Polaris

To use ImageMagick on Polaris first load the corresponding module:

module use /soft/modulefiles
module load spack-pe-base imagemagick

### Human: What does the ""module load"" command do in the context of using ImageMagick on Polaris?

### Assistant: The ""module load"" command loads the ImageMagick module on Polaris.
    "
"
### Context: 
Manually launching a ParaView server on Polaris

Sometimes it is convenient to manually launch an instance of the ParaView server. In this section we will explain an alternative method to run the ParaView server on Polaris using an interactive job, where the user can launch the ParaView server from the command line interface.

Note: this is a method better suited for experienced users. If you are just starting with ParaView, we recommend the client/server mode as your primary method for using this tool.

Setting up ParaView

From your local client select Connect, either from the File menu, or by clicking on the icon circled below:

A new window will open where you can configure a server. Click on Add Server:

Give your server a name, select Client/Server, localhost, and a TCP port (8000 in this example)

Click ""Configure"". In the next window there is an option to set up how ParaView server will be launched, and the default is ""Manual"". Leave it on ""Manual"" and click ""Save"".

You will use these settings when establishing the connection.

Launching the ParaView server on Polaris

You can launch an interactive session on Polaris compute nodes with the following command (adjust parameters as needed to match your allocation, desired number of nodes, queue, walltime, and filesystems):

shell
qsub -l walltime=01:00:00 -l select=2 -A yourallocation -q debug -I -l filesystems=home:grand

When the job starts you will receive a prompt on your head node like this:

username@x3005c0s7b0n0:~>

Make a note of the node hostname (x3005c0s7b0n0 in the example above). You can also get this information from qstat -fx jobID

Now load the ParaView module

username@x3005c0s7b0n0:~> module use /soft/modulefiles 
username@x3005c0s7b0n0:~> module load visualization/paraview/paraview-5.12.0-EGL

and launch the ParaView server with

### Human: How do you manually launch an instance of the ParaView server on Polaris?

### Assistant: Launch the ParaView server with ""pvserver -force-offscreen-rendering"" command.
```
    "
"
### Context: 
Manually launching a ParaView server on Polaris

Sometimes it is convenient to manually launch an instance of the ParaView server. In this section we will explain an alternative method to run the ParaView server on Polaris using an interactive job, where the user can launch the ParaView server from the command line interface.

Note: this is a method better suited for experienced users. If you are just starting with ParaView, we recommend the client/server mode as your primary method for using this tool.

Setting up ParaView

From your local client select Connect, either from the File menu, or by clicking on the icon circled below:

A new window will open where you can configure a server. Click on Add Server:

Give your server a name, select Client/Server, localhost, and a TCP port (8000 in this example)

Click ""Configure"". In the next window there is an option to set up how ParaView server will be launched, and the default is ""Manual"". Leave it on ""Manual"" and click ""Save"".

You will use these settings when establishing the connection.

Launching the ParaView server on Polaris

You can launch an interactive session on Polaris compute nodes with the following command (adjust parameters as needed to match your allocation, desired number of nodes, queue, walltime, and filesystems):

shell
qsub -l walltime=01:00:00 -l select=2 -A yourallocation -q debug -I -l filesystems=home:grand

When the job starts you will receive a prompt on your head node like this:

username@x3005c0s7b0n0:~>

Make a note of the node hostname (x3005c0s7b0n0 in the example above). You can also get this information from qstat -fx jobID

Now load the ParaView module

username@x3005c0s7b0n0:~> module use /soft/modulefiles 
username@x3005c0s7b0n0:~> module load visualization/paraview/paraview-5.12.0-EGL

and launch the ParaView server with

### Human: What is the default setting for how ParaView server will be launched when establishing a connection?

### Assistant: Manual
    "
"
### Context: 
Manually launching a ParaView server on Polaris

Sometimes it is convenient to manually launch an instance of the ParaView server. In this section we will explain an alternative method to run the ParaView server on Polaris using an interactive job, where the user can launch the ParaView server from the command line interface.

Note: this is a method better suited for experienced users. If you are just starting with ParaView, we recommend the client/server mode as your primary method for using this tool.

Setting up ParaView

From your local client select Connect, either from the File menu, or by clicking on the icon circled below:

A new window will open where you can configure a server. Click on Add Server:

Give your server a name, select Client/Server, localhost, and a TCP port (8000 in this example)

Click ""Configure"". In the next window there is an option to set up how ParaView server will be launched, and the default is ""Manual"". Leave it on ""Manual"" and click ""Save"".

You will use these settings when establishing the connection.

Launching the ParaView server on Polaris

You can launch an interactive session on Polaris compute nodes with the following command (adjust parameters as needed to match your allocation, desired number of nodes, queue, walltime, and filesystems):

shell
qsub -l walltime=01:00:00 -l select=2 -A yourallocation -q debug -I -l filesystems=home:grand

When the job starts you will receive a prompt on your head node like this:

username@x3005c0s7b0n0:~>

Make a note of the node hostname (x3005c0s7b0n0 in the example above). You can also get this information from qstat -fx jobID

Now load the ParaView module

username@x3005c0s7b0n0:~> module use /soft/modulefiles 
username@x3005c0s7b0n0:~> module load visualization/paraview/paraview-5.12.0-EGL

and launch the ParaView server with

### Human: What command should I use to launch an interactive session on Polaris compute nodes and establish a connection with ParaView?

### Assistant: $pvserver -force-offscreen-rendering
```
    "
"
### Context: 
and launch the ParaView server with

srizzi@x3005c0s7b0n0:~> mpirun -n 8 pvserver --server-port=8000
Waiting for client...
Connection URL: cs://x3005c0s7b0n0:8000
Accepting connection(s): x3005c0s7b0n0:8000

In this case pvserver will be listening on TCP port 8000 of your head node. You can change this port if you want.

Creating a tunnel over ssh

We need to establish an ssh tunnel to connect client to server. On your local machine open a new terminal and type:

ssh -v -N -L 8000:x3005c0s7b0n0:8000 polaris.alcf.anl.gov

where 8000 is a TCP port and x3005c0s7b0n0 the name of your head node. Adjust these values accordingly.

Among multiple lines with debug information,  you should see something like:

debug1: Local connections to LOCALHOST:8000 forwarded to remote address x3005c0s7b0n0:8000

Keep this terminal open for the duration of your session to keep the ssh tunnel active.

Now you are ready to launch your ParaView client locally. Keep in mind that client and servers versions must match. The ParaView version currently deployed on Polaris is 5.12.0

Connecting to ParaView server

Connect your ParaView client to the server configuration you created above. You can select Connect, either from the File menu, or the icon circled in the figure:

and selecting the configuration you created in a previous step.

The connection should point to:

localhost:8000

In the terminal where you launched the server you will see now that the connection is established. Note that ParaView may take a few seconds to connect. This is normal behavior.

username@x3005c0s7b0n0:~> mpirun -n 8 pvserver --server-port=8000
Waiting for client...
Connection URL: cs://x3005c0s7b0n0:8000
Accepting connection(s): x3005c0s7b0n0:8000
Client connected.

At this point you can use ParaView normally.

### Human: What is the command to launch the ParaView server?

### Assistant: mpirun -n 8 pvserver --server-port=8000
    "
"
### Context: 
and launch the ParaView server with

srizzi@x3005c0s7b0n0:~> mpirun -n 8 pvserver --server-port=8000
Waiting for client...
Connection URL: cs://x3005c0s7b0n0:8000
Accepting connection(s): x3005c0s7b0n0:8000

In this case pvserver will be listening on TCP port 8000 of your head node. You can change this port if you want.

Creating a tunnel over ssh

We need to establish an ssh tunnel to connect client to server. On your local machine open a new terminal and type:

ssh -v -N -L 8000:x3005c0s7b0n0:8000 polaris.alcf.anl.gov

where 8000 is a TCP port and x3005c0s7b0n0 the name of your head node. Adjust these values accordingly.

Among multiple lines with debug information,  you should see something like:

debug1: Local connections to LOCALHOST:8000 forwarded to remote address x3005c0s7b0n0:8000

Keep this terminal open for the duration of your session to keep the ssh tunnel active.

Now you are ready to launch your ParaView client locally. Keep in mind that client and servers versions must match. The ParaView version currently deployed on Polaris is 5.12.0

Connecting to ParaView server

Connect your ParaView client to the server configuration you created above. You can select Connect, either from the File menu, or the icon circled in the figure:

and selecting the configuration you created in a previous step.

The connection should point to:

localhost:8000

In the terminal where you launched the server you will see now that the connection is established. Note that ParaView may take a few seconds to connect. This is normal behavior.

username@x3005c0s7b0n0:~> mpirun -n 8 pvserver --server-port=8000
Waiting for client...
Connection URL: cs://x3005c0s7b0n0:8000
Accepting connection(s): x3005c0s7b0n0:8000
Client connected.

At this point you can use ParaView normally.

### Human: How do I connect my local ParaView client to the remote ParaView server?

### Assistant: Connect your local ParaView client to the remote ParaView server by launching the server on the head node, establishing an SSH tunnel, and connecting to the server configuration with the correct connection URL.
    "
"
### Context: 
and launch the ParaView server with

srizzi@x3005c0s7b0n0:~> mpirun -n 8 pvserver --server-port=8000
Waiting for client...
Connection URL: cs://x3005c0s7b0n0:8000
Accepting connection(s): x3005c0s7b0n0:8000

In this case pvserver will be listening on TCP port 8000 of your head node. You can change this port if you want.

Creating a tunnel over ssh

We need to establish an ssh tunnel to connect client to server. On your local machine open a new terminal and type:

ssh -v -N -L 8000:x3005c0s7b0n0:8000 polaris.alcf.anl.gov

where 8000 is a TCP port and x3005c0s7b0n0 the name of your head node. Adjust these values accordingly.

Among multiple lines with debug information,  you should see something like:

debug1: Local connections to LOCALHOST:8000 forwarded to remote address x3005c0s7b0n0:8000

Keep this terminal open for the duration of your session to keep the ssh tunnel active.

Now you are ready to launch your ParaView client locally. Keep in mind that client and servers versions must match. The ParaView version currently deployed on Polaris is 5.12.0

Connecting to ParaView server

Connect your ParaView client to the server configuration you created above. You can select Connect, either from the File menu, or the icon circled in the figure:

and selecting the configuration you created in a previous step.

The connection should point to:

localhost:8000

In the terminal where you launched the server you will see now that the connection is established. Note that ParaView may take a few seconds to connect. This is normal behavior.

username@x3005c0s7b0n0:~> mpirun -n 8 pvserver --server-port=8000
Waiting for client...
Connection URL: cs://x3005c0s7b0n0:8000
Accepting connection(s): x3005c0s7b0n0:8000
Client connected.

At this point you can use ParaView normally.

### Human: What is the TCP port that the ParaView server will be listening on by default?

### Assistant: 8000
    "
"
### Context: 
FFmpeg on Polaris

NOTE: FFmpeg module is currently missing on Polaris after a recent upgrade. A spack build of ffmpeg will be available soon

To use FFmpeg on Polaris first load the corresponding module:

module load ffmpeg

This is a typical command line to create a movie from a series of snapshots in PNG format:

ffmpeg -r 15 -i frames.%03d.png -r 25 -pix_fmt yuv420p movie.mp4

where:

r 15 is the input frame rate. Experiment with values smaller than the output frame rate for longer movies.
-r 25 is the output frame rate (use this value for standard 25 frames per second)
-i frames.%03d.png reads the input frames in sequence
-pix_fmt yuv420p is needed for movies to play in browsers
movie.mp4 is the resulting movie

### Human: How do I use FFmpeg on Polaris?

### Assistant: Load the FFmpeg module with ""module load ffmpeg"" and then use the command ""ffmpeg -r 15 -i frames.%03d.png -r 25 -pix_fmt yuv420p movie.mp4"" to create a movie from PNG snapshots.
    "
"
### Context: 
FFmpeg on Polaris

NOTE: FFmpeg module is currently missing on Polaris after a recent upgrade. A spack build of ffmpeg will be available soon

To use FFmpeg on Polaris first load the corresponding module:

module load ffmpeg

This is a typical command line to create a movie from a series of snapshots in PNG format:

ffmpeg -r 15 -i frames.%03d.png -r 25 -pix_fmt yuv420p movie.mp4

where:

r 15 is the input frame rate. Experiment with values smaller than the output frame rate for longer movies.
-r 25 is the output frame rate (use this value for standard 25 frames per second)
-i frames.%03d.png reads the input frames in sequence
-pix_fmt yuv420p is needed for movies to play in browsers
movie.mp4 is the resulting movie

### Human: What command line should I use to create a movie from PNG snapshots using FFmpeg on Polaris?

### Assistant: ffmpeg -r 15 -i frames.%03d.png -r 25 -pix_fmt yuv420p movie.mp4
    "
"
### Context: 
FFmpeg on Polaris

NOTE: FFmpeg module is currently missing on Polaris after a recent upgrade. A spack build of ffmpeg will be available soon

To use FFmpeg on Polaris first load the corresponding module:

module load ffmpeg

This is a typical command line to create a movie from a series of snapshots in PNG format:

ffmpeg -r 15 -i frames.%03d.png -r 25 -pix_fmt yuv420p movie.mp4

where:

r 15 is the input frame rate. Experiment with values smaller than the output frame rate for longer movies.
-r 25 is the output frame rate (use this value for standard 25 frames per second)
-i frames.%03d.png reads the input frames in sequence
-pix_fmt yuv420p is needed for movies to play in browsers
movie.mp4 is the resulting movie

### Human: What is the purpose of ""-r 25"" in the FFmpeg command line on Polaris?

### Assistant: The purpose of ""-r 25"" is to specify the output frame rate.
    "
"
### Context: 
Compile and Run

bash
$ mpicxx -L/opt/cray/pe/mpich/8.1.28/gtl/lib -lmpi_gtl_cuda -std=c++17 -fsycl -fsycl-targets=nvptx64-nvidia-cuda -Xsycl-target-backend --cuda-gpu-arch=sm_80 main.cpp
$ mpiexec -n 2 --ppn 2 --depth=1 --cpu-bind depth ./set_affinity_gpu_polaris.sh ./a.out
For further details regarding the arguments passed to mpiexec command shown above, please visit the Job Scheduling and Execution section. A simple example describing the details and execution of the set_affinity_gpu_polaris.sh file can be found here.

Note: By default, there is no GPU-aware MPI library linking support.  The example above shows how the user can enable the linking by specifying the path to the GTL (GPU Transport Layer) library (libmpi_gtl_cuda) to the link line.

oneAPI Math Kernel Library (oneMKL) Interfaces

oneMKL Interfaces is an open-source implementation of the oneMKL Data Parallel C++ (DPC++) interface according to the oneMKL specification. It works with multiple devices (backends) using device-specific libraries underneath.

oneMKL is part of oneAPI. Various backend supported are shown below. More Information here.

User Application Third-Party Library cuBLAS oneMKL interface cuSOLVER cuRAND

Example (using onemkl::gemm)

The following snippet shows how to compile and run a SYCL code with oneMKL library. For instance, a GPU-based GEMM is performed using mkl::gemm API and the results are compared to a CPU-based GEMM performed using the traditional blas (e.g., AOCL-BLIS) library.
```c++

include

include

include

include   // ONEMKL GPU header

include          // BLIS   CPU header

// Matrix size constants

define SIZE 4800 // Must be a multiple of 8.

define M SIZE / 8

define N SIZE / 4

define P SIZE / 2

//////////////////////////////////////////////////////////////////////////////////////////

bool ValueSame(double a, double b) { return std::fabs(a - b) < 1.0e-08; }
int VerifyResult(double c_A, double c_B) {
  bool MismatchFound = false;

### Human: What is a supercomputer used for?

### Assistant: A supercomputer is typically used for complex scientific simulations, data analysis, and other computationally intensive tasks that require massive processing power.
    "
"
### Context: 
Compile and Run

bash
$ mpicxx -L/opt/cray/pe/mpich/8.1.28/gtl/lib -lmpi_gtl_cuda -std=c++17 -fsycl -fsycl-targets=nvptx64-nvidia-cuda -Xsycl-target-backend --cuda-gpu-arch=sm_80 main.cpp
$ mpiexec -n 2 --ppn 2 --depth=1 --cpu-bind depth ./set_affinity_gpu_polaris.sh ./a.out
For further details regarding the arguments passed to mpiexec command shown above, please visit the Job Scheduling and Execution section. A simple example describing the details and execution of the set_affinity_gpu_polaris.sh file can be found here.

Note: By default, there is no GPU-aware MPI library linking support.  The example above shows how the user can enable the linking by specifying the path to the GTL (GPU Transport Layer) library (libmpi_gtl_cuda) to the link line.

oneAPI Math Kernel Library (oneMKL) Interfaces

oneMKL Interfaces is an open-source implementation of the oneMKL Data Parallel C++ (DPC++) interface according to the oneMKL specification. It works with multiple devices (backends) using device-specific libraries underneath.

oneMKL is part of oneAPI. Various backend supported are shown below. More Information here.

User Application Third-Party Library cuBLAS oneMKL interface cuSOLVER cuRAND

Example (using onemkl::gemm)

The following snippet shows how to compile and run a SYCL code with oneMKL library. For instance, a GPU-based GEMM is performed using mkl::gemm API and the results are compared to a CPU-based GEMM performed using the traditional blas (e.g., AOCL-BLIS) library.
```c++

include

include

include

include   // ONEMKL GPU header

include          // BLIS   CPU header

// Matrix size constants

define SIZE 4800 // Must be a multiple of 8.

define M SIZE / 8

define N SIZE / 4

define P SIZE / 2

//////////////////////////////////////////////////////////////////////////////////////////

bool ValueSame(double a, double b) { return std::fabs(a - b) < 1.0e-08; }
int VerifyResult(double c_A, double c_B) {
  bool MismatchFound = false;

### Human: How does a supercomputer differ from a regular computer?

### Assistant: A supercomputer differs from a regular computer in that it is designed for high-performance computing, has thousands of processing cores, advanced memory systems, and specialized hardware accelerators, whereas regular computers are designed for general-purpose computing.
    "
"
### Context: 
Compile and Run

bash
$ mpicxx -L/opt/cray/pe/mpich/8.1.28/gtl/lib -lmpi_gtl_cuda -std=c++17 -fsycl -fsycl-targets=nvptx64-nvidia-cuda -Xsycl-target-backend --cuda-gpu-arch=sm_80 main.cpp
$ mpiexec -n 2 --ppn 2 --depth=1 --cpu-bind depth ./set_affinity_gpu_polaris.sh ./a.out
For further details regarding the arguments passed to mpiexec command shown above, please visit the Job Scheduling and Execution section. A simple example describing the details and execution of the set_affinity_gpu_polaris.sh file can be found here.

Note: By default, there is no GPU-aware MPI library linking support.  The example above shows how the user can enable the linking by specifying the path to the GTL (GPU Transport Layer) library (libmpi_gtl_cuda) to the link line.

oneAPI Math Kernel Library (oneMKL) Interfaces

oneMKL Interfaces is an open-source implementation of the oneMKL Data Parallel C++ (DPC++) interface according to the oneMKL specification. It works with multiple devices (backends) using device-specific libraries underneath.

oneMKL is part of oneAPI. Various backend supported are shown below. More Information here.

User Application Third-Party Library cuBLAS oneMKL interface cuSOLVER cuRAND

Example (using onemkl::gemm)

The following snippet shows how to compile and run a SYCL code with oneMKL library. For instance, a GPU-based GEMM is performed using mkl::gemm API and the results are compared to a CPU-based GEMM performed using the traditional blas (e.g., AOCL-BLIS) library.
```c++

include

include

include

include   // ONEMKL GPU header

include          // BLIS   CPU header

// Matrix size constants

define SIZE 4800 // Must be a multiple of 8.

define M SIZE / 8

define N SIZE / 4

define P SIZE / 2

//////////////////////////////////////////////////////////////////////////////////////////

bool ValueSame(double a, double b) { return std::fabs(a - b) < 1.0e-08; }
int VerifyResult(double c_A, double c_B) {
  bool MismatchFound = false;

### Human: What kind of processing power does a supercomputer typically have?

### Assistant: A supercomputer typically has a large number of processing cores and supports parallel processing, with the ability to enable GPU-aware MPI libraries for performing calculations on GPUs.

Answer: $A supercomputer typically has a large number of processing cores and supports parallel processing, with the ability to enable GPU-aware MPI libraries for performing calculations on GPUs.
    "
"
### Context: 
for (size_t i = 0; i < M; i++) {
    for (size_t j = 0; j < P; j++) {
      if (!ValueSame(c_A[i * P + j], c_B[i * P + j])) {
        std::cout << ""fail - The result is incorrect for element: ["" << i << "", "" << j
                  << ""], expected: "" << c_A[i * P + j] << "" , but got: "" << c_B[i * P + j]
                  << std::endl;
        MismatchFound = true;
      }
    }
  }

if (!MismatchFound) {
    std::cout << ""SUCCESS - The results are correct!"" << std::endl;
    return 0;
  } else {
    std::cout << ""FAIL - The results mis-match!"" << std::endl;
    return -1;
  }
}

//////////////////////////////////////////////////////////////////////////////////////////

int main() {
  std::random_device rd;  // Will be used to obtain a seed for the random number engine
  std::mt19937 gen(rd()); // Standard mersenne_twister_engine seeded with rd()
  std::uniform_real_distribution<> dis(1.0, 2.0);

// C = alpha * op(A) * op(B)  + beta * C
  oneapi::mkl::transpose transA = oneapi::mkl::transpose::nontrans;
  oneapi::mkl::transpose transB = oneapi::mkl::transpose::nontrans;

// matrix data sizes
  int m = M;
  int n = P;
  int k = N;

// leading dimensions of data
  int ldA = k;
  int ldB = n;
  int ldC = n;

// set scalar fp values
  double alpha = 1.0;
  double beta = 0.0;

// 1D arrays on host side
  double A;
  double B;
  double C_host_onemkl, C_cblas;

A = new double[M * N]{};
  B = new double[N * P]{};
  C_cblas = new double[M * P]{};
  C_host_onemkl = new double[M * P]{};

// prepare matrix data with ROW-major style
  // A(M, N)
  for (size_t i = 0; i < M; i++)
    for (size_t j = 0; j < N; j++)
      A[i * N + j] = dis(gen);
  // B(N, P)
  for (size_t i = 0; i < N; i++)
    for (size_t j = 0; j < P; j++)
      B[i * P + j] = dis(gen);

std::cout << ""Problem size: c("" << M << "","" << P << "") = a("" << M << "","" << N << "") * b("" << N
            << "","" << P << "")"" << std::endl;

### Human: What is the purpose of the `MismatchFound` variable in the code snippet?

### Assistant: The purpose of the `MismatchFound` variable is to track whether any mismatches are found between the expected and actual results during the comparison process.
    "
"
### Context: 
for (size_t i = 0; i < M; i++) {
    for (size_t j = 0; j < P; j++) {
      if (!ValueSame(c_A[i * P + j], c_B[i * P + j])) {
        std::cout << ""fail - The result is incorrect for element: ["" << i << "", "" << j
                  << ""], expected: "" << c_A[i * P + j] << "" , but got: "" << c_B[i * P + j]
                  << std::endl;
        MismatchFound = true;
      }
    }
  }

if (!MismatchFound) {
    std::cout << ""SUCCESS - The results are correct!"" << std::endl;
    return 0;
  } else {
    std::cout << ""FAIL - The results mis-match!"" << std::endl;
    return -1;
  }
}

//////////////////////////////////////////////////////////////////////////////////////////

int main() {
  std::random_device rd;  // Will be used to obtain a seed for the random number engine
  std::mt19937 gen(rd()); // Standard mersenne_twister_engine seeded with rd()
  std::uniform_real_distribution<> dis(1.0, 2.0);

// C = alpha * op(A) * op(B)  + beta * C
  oneapi::mkl::transpose transA = oneapi::mkl::transpose::nontrans;
  oneapi::mkl::transpose transB = oneapi::mkl::transpose::nontrans;

// matrix data sizes
  int m = M;
  int n = P;
  int k = N;

// leading dimensions of data
  int ldA = k;
  int ldB = n;
  int ldC = n;

// set scalar fp values
  double alpha = 1.0;
  double beta = 0.0;

// 1D arrays on host side
  double A;
  double B;
  double C_host_onemkl, C_cblas;

A = new double[M * N]{};
  B = new double[N * P]{};
  C_cblas = new double[M * P]{};
  C_host_onemkl = new double[M * P]{};

// prepare matrix data with ROW-major style
  // A(M, N)
  for (size_t i = 0; i < M; i++)
    for (size_t j = 0; j < N; j++)
      A[i * N + j] = dis(gen);
  // B(N, P)
  for (size_t i = 0; i < N; i++)
    for (size_t j = 0; j < P; j++)
      B[i * P + j] = dis(gen);

std::cout << ""Problem size: c("" << M << "","" << P << "") = a("" << M << "","" << N << "") * b("" << N
            << "","" << P << "")"" << std::endl;

### Human: What type of distribution is used to generate random values for matrices A and B?

### Assistant: The type of distribution used to generate random values for matrices A and B is a uniform real distribution with a range of 1.0 to 2.0.
    "
"
### Context: 
for (size_t i = 0; i < M; i++) {
    for (size_t j = 0; j < P; j++) {
      if (!ValueSame(c_A[i * P + j], c_B[i * P + j])) {
        std::cout << ""fail - The result is incorrect for element: ["" << i << "", "" << j
                  << ""], expected: "" << c_A[i * P + j] << "" , but got: "" << c_B[i * P + j]
                  << std::endl;
        MismatchFound = true;
      }
    }
  }

if (!MismatchFound) {
    std::cout << ""SUCCESS - The results are correct!"" << std::endl;
    return 0;
  } else {
    std::cout << ""FAIL - The results mis-match!"" << std::endl;
    return -1;
  }
}

//////////////////////////////////////////////////////////////////////////////////////////

int main() {
  std::random_device rd;  // Will be used to obtain a seed for the random number engine
  std::mt19937 gen(rd()); // Standard mersenne_twister_engine seeded with rd()
  std::uniform_real_distribution<> dis(1.0, 2.0);

// C = alpha * op(A) * op(B)  + beta * C
  oneapi::mkl::transpose transA = oneapi::mkl::transpose::nontrans;
  oneapi::mkl::transpose transB = oneapi::mkl::transpose::nontrans;

// matrix data sizes
  int m = M;
  int n = P;
  int k = N;

// leading dimensions of data
  int ldA = k;
  int ldB = n;
  int ldC = n;

// set scalar fp values
  double alpha = 1.0;
  double beta = 0.0;

// 1D arrays on host side
  double A;
  double B;
  double C_host_onemkl, C_cblas;

A = new double[M * N]{};
  B = new double[N * P]{};
  C_cblas = new double[M * P]{};
  C_host_onemkl = new double[M * P]{};

// prepare matrix data with ROW-major style
  // A(M, N)
  for (size_t i = 0; i < M; i++)
    for (size_t j = 0; j < N; j++)
      A[i * N + j] = dis(gen);
  // B(N, P)
  for (size_t i = 0; i < N; i++)
    for (size_t j = 0; j < P; j++)
      B[i * P + j] = dis(gen);

std::cout << ""Problem size: c("" << M << "","" << P << "") = a("" << M << "","" << N << "") * b("" << N
            << "","" << P << "")"" << std::endl;

### Human: What are the leading dimensions of data for matrices A, B, and C?

### Assistant: ldA: $k$, ldB: $n$, ldC: $n$
    "
"
### Context: 
// Resultant matrix: C_cblas
  cblas_dgemm(CblasRowMajor, CblasNoTrans, CblasNoTrans, m, n, k, alpha, A, ldA, B, ldB, beta,
              C_cblas, ldC);

// Resultant matrix: C_onemkl
  sycl::queue q(sycl::property_list{sycl::property::queue::in_order{}});
  std::cout << ""Device: "" << q.get_device().get_info() << std::endl << std::endl;

double A_dev        = sycl::malloc_device(MN, q);
  double B_dev        = sycl::malloc_device(NP, q);
  double C_dev_onemkl = sycl::malloc_device(MP, q);

q.memcpy(A_dev, A, (MN) * sizeof(double));
  q.memcpy(B_dev, B, (NP) * sizeof(double));

auto gemm_event = oneapi::mkl::blas::column_major::gemm(q, transB, transA, n, m, k, alpha, B_dev, ldB, A_dev, ldA, beta, C_dev_onemkl, ldC);

q.memcpy(C_host_onemkl, C_dev_onemkl, (M*P) * sizeof(double));

q.wait();
  std::cout << ""Verify results between OneMKL & CBLAS: "";
  int result_cblas = VerifyResult(C_cblas, C_host_onemkl);

delete[] A;
  delete[] B;
  delete[] C_cblas;
  delete[] C_host_onemkl;
  sycl::free(A_dev, q);
  sycl::free(B_dev, q);
  sycl::free(C_dev_onemkl, q);
  return result_cblas;
}
```

Compile and Run

The user would need to provide paths the math-libraris as shown below. Also please provide AOCL library for CPU GEMM by module load aocl.
Environment variables MKLROOT is defined with oneapi module & AOCL_ROOT is defined with aocl module.
Note: Please pay attention to the linker options for AOCL & oneMKL libraries.
bash
$ clang++ -std=c++17 -sycl-std=2020 -O3 -fsycl -fsycl-targets=nvptx64-nvidia-cuda -Xsycl-target-backend --cuda-gpu-arch=sm_80 -L$AOCL_ROOT/lib -lblis -L$MKLROOT/lib -lonemkl sycl_onemkl_gemm.cpp -o sycl_onemkl_gemm.out

### Human: What is OneMKL?

### Assistant: OneMKL is a library or framework for performing linear algebra operations, specifically matrix-matrix multiplications.
    "
"
### Context: 
// Resultant matrix: C_cblas
  cblas_dgemm(CblasRowMajor, CblasNoTrans, CblasNoTrans, m, n, k, alpha, A, ldA, B, ldB, beta,
              C_cblas, ldC);

// Resultant matrix: C_onemkl
  sycl::queue q(sycl::property_list{sycl::property::queue::in_order{}});
  std::cout << ""Device: "" << q.get_device().get_info() << std::endl << std::endl;

double A_dev        = sycl::malloc_device(MN, q);
  double B_dev        = sycl::malloc_device(NP, q);
  double C_dev_onemkl = sycl::malloc_device(MP, q);

q.memcpy(A_dev, A, (MN) * sizeof(double));
  q.memcpy(B_dev, B, (NP) * sizeof(double));

auto gemm_event = oneapi::mkl::blas::column_major::gemm(q, transB, transA, n, m, k, alpha, B_dev, ldB, A_dev, ldA, beta, C_dev_onemkl, ldC);

q.memcpy(C_host_onemkl, C_dev_onemkl, (M*P) * sizeof(double));

q.wait();
  std::cout << ""Verify results between OneMKL & CBLAS: "";
  int result_cblas = VerifyResult(C_cblas, C_host_onemkl);

delete[] A;
  delete[] B;
  delete[] C_cblas;
  delete[] C_host_onemkl;
  sycl::free(A_dev, q);
  sycl::free(B_dev, q);
  sycl::free(C_dev_onemkl, q);
  return result_cblas;
}
```

Compile and Run

The user would need to provide paths the math-libraris as shown below. Also please provide AOCL library for CPU GEMM by module load aocl.
Environment variables MKLROOT is defined with oneapi module & AOCL_ROOT is defined with aocl module.
Note: Please pay attention to the linker options for AOCL & oneMKL libraries.
bash
$ clang++ -std=c++17 -sycl-std=2020 -O3 -fsycl -fsycl-targets=nvptx64-nvidia-cuda -Xsycl-target-backend --cuda-gpu-arch=sm_80 -L$AOCL_ROOT/lib -lblis -L$MKLROOT/lib -lonemkl sycl_onemkl_gemm.cpp -o sycl_onemkl_gemm.out

### Human: How does the `gemm` function in the code differ from the CBLAS version?

### Assistant: The main differences between the `gemm` function in the code and the CBLAS version are memory allocation using `sycl::malloc_device`, data transfer using `q.memcpy`, and parallelization for multi-core CPUs or accelerators.
    "
"
### Context: 
// Resultant matrix: C_cblas
  cblas_dgemm(CblasRowMajor, CblasNoTrans, CblasNoTrans, m, n, k, alpha, A, ldA, B, ldB, beta,
              C_cblas, ldC);

// Resultant matrix: C_onemkl
  sycl::queue q(sycl::property_list{sycl::property::queue::in_order{}});
  std::cout << ""Device: "" << q.get_device().get_info() << std::endl << std::endl;

double A_dev        = sycl::malloc_device(MN, q);
  double B_dev        = sycl::malloc_device(NP, q);
  double C_dev_onemkl = sycl::malloc_device(MP, q);

q.memcpy(A_dev, A, (MN) * sizeof(double));
  q.memcpy(B_dev, B, (NP) * sizeof(double));

auto gemm_event = oneapi::mkl::blas::column_major::gemm(q, transB, transA, n, m, k, alpha, B_dev, ldB, A_dev, ldA, beta, C_dev_onemkl, ldC);

q.memcpy(C_host_onemkl, C_dev_onemkl, (M*P) * sizeof(double));

q.wait();
  std::cout << ""Verify results between OneMKL & CBLAS: "";
  int result_cblas = VerifyResult(C_cblas, C_host_onemkl);

delete[] A;
  delete[] B;
  delete[] C_cblas;
  delete[] C_host_onemkl;
  sycl::free(A_dev, q);
  sycl::free(B_dev, q);
  sycl::free(C_dev_onemkl, q);
  return result_cblas;
}
```

Compile and Run

The user would need to provide paths the math-libraris as shown below. Also please provide AOCL library for CPU GEMM by module load aocl.
Environment variables MKLROOT is defined with oneapi module & AOCL_ROOT is defined with aocl module.
Note: Please pay attention to the linker options for AOCL & oneMKL libraries.
bash
$ clang++ -std=c++17 -sycl-std=2020 -O3 -fsycl -fsycl-targets=nvptx64-nvidia-cuda -Xsycl-target-backend --cuda-gpu-arch=sm_80 -L$AOCL_ROOT/lib -lblis -L$MKLROOT/lib -lonemkl sycl_onemkl_gemm.cpp -o sycl_onemkl_gemm.out

### Human: What are some common uses of the `sycl::queue` class in this context?

### Assistant: The common uses of the `sycl::queue` class in this context are allocating memory on the device, copying data from host to device, executing kernels, and copying data from device to host.
    "
"
### Context: 
set(top_SRCS
  ${buildExample_SOURCE_DIR}/example1.cpp)

set(SOURCE_FILES ${top_SRCS})

add_executable(example1_sycl_aot ${SOURCE_FILES})
target_link_libraries(example1_sycl_aot Kokkos::kokkoscore)
target_include_directories(example1_sycl_aot PUBLIC ${buildExample_SOURCE_DIR})
```

Configure and build it like this:

mkdir build
cd build
cmake -DCMAKE_CXX_COMPILER=CC -DCMAKE_C_COMPILER=cc ..
make

Building a Kokkos Application Using make

Here's an example Makefile:

```

KOKKOS_HOME set via:

module load kokkos

You can look at the first lines of $KOKKOS_HOME/KokkosConfigCommon.cmake to

see the flags used in cmake configuration of the kokkos library build. The

default Kokkos module on Polaris was built with PrgEnv-nvhpc and includes

Serial, OpenMP (threads) and CUDA backends. So you should have that

environment module loaded and include compiler flags for cuda and openmp:

Cray MPI wrapper for C++ and C compilers:

CXX=CC
CC=cc

CPPFLAGS=-cuda -fopenmp
LDFLAGS=

LDFLAGS=$(CPPFLAGS) $(LDFLAGS)
LDLIBS=-L$(KOKKOS_HOME)/lib64 -lkokkoscore -lkokkossimd -lpthread

SRCS=example1.cpp
OBJS=$(subst .cpp,.o,$(SRCS))

all: example1_polaris

example1_polaris: $(OBJS)
        $(CXX) $(LDFLAGS) -o example1_polaris $(OBJS) $(LDLIBS)

example1.o: example1.cpp

clean:
        rm -f $(OBJS)

distclean: clean
        rm -f example1_polaris
```

Configuring Your Own Kokkos Build on Polaris

Here are recommended environment settings and configuration to build your own
kokkos libraries on Polaris:

Environment

To match what was done in the centrally-built kokkos associated with the
modules discussed above, use the programming environment
PrgEnv-gnu, and use the Cray wrapper CC as the C++ compiler. You'll also
need to explicitly load the Cuda toolkit version 12.2.91 as shown:

### Human: What is Kokkos and why is it used in high-performance computing?

### Assistant: Kokkos is a high-performance computing library used in high-performance computing applications, supporting parallel processing with multiple backends such as CUDA and OpenMP.
    "
"
### Context: 
set(top_SRCS
  ${buildExample_SOURCE_DIR}/example1.cpp)

set(SOURCE_FILES ${top_SRCS})

add_executable(example1_sycl_aot ${SOURCE_FILES})
target_link_libraries(example1_sycl_aot Kokkos::kokkoscore)
target_include_directories(example1_sycl_aot PUBLIC ${buildExample_SOURCE_DIR})
```

Configure and build it like this:

mkdir build
cd build
cmake -DCMAKE_CXX_COMPILER=CC -DCMAKE_C_COMPILER=cc ..
make

Building a Kokkos Application Using make

Here's an example Makefile:

```

KOKKOS_HOME set via:

module load kokkos

You can look at the first lines of $KOKKOS_HOME/KokkosConfigCommon.cmake to

see the flags used in cmake configuration of the kokkos library build. The

default Kokkos module on Polaris was built with PrgEnv-nvhpc and includes

Serial, OpenMP (threads) and CUDA backends. So you should have that

environment module loaded and include compiler flags for cuda and openmp:

Cray MPI wrapper for C++ and C compilers:

CXX=CC
CC=cc

CPPFLAGS=-cuda -fopenmp
LDFLAGS=

LDFLAGS=$(CPPFLAGS) $(LDFLAGS)
LDLIBS=-L$(KOKKOS_HOME)/lib64 -lkokkoscore -lkokkossimd -lpthread

SRCS=example1.cpp
OBJS=$(subst .cpp,.o,$(SRCS))

all: example1_polaris

example1_polaris: $(OBJS)
        $(CXX) $(LDFLAGS) -o example1_polaris $(OBJS) $(LDLIBS)

example1.o: example1.cpp

clean:
        rm -f $(OBJS)

distclean: clean
        rm -f example1_polaris
```

Configuring Your Own Kokkos Build on Polaris

Here are recommended environment settings and configuration to build your own
kokkos libraries on Polaris:

Environment

To match what was done in the centrally-built kokkos associated with the
modules discussed above, use the programming environment
PrgEnv-gnu, and use the Cray wrapper CC as the C++ compiler. You'll also
need to explicitly load the Cuda toolkit version 12.2.91 as shown:

### Human: How do I configure and build a Kokkos application using CMake and Make?

### Assistant: Configure and build a Kokkos application using CMake and Make by running `cmake` and then `make`.
    "
"
### Context: 
set(top_SRCS
  ${buildExample_SOURCE_DIR}/example1.cpp)

set(SOURCE_FILES ${top_SRCS})

add_executable(example1_sycl_aot ${SOURCE_FILES})
target_link_libraries(example1_sycl_aot Kokkos::kokkoscore)
target_include_directories(example1_sycl_aot PUBLIC ${buildExample_SOURCE_DIR})
```

Configure and build it like this:

mkdir build
cd build
cmake -DCMAKE_CXX_COMPILER=CC -DCMAKE_C_COMPILER=cc ..
make

Building a Kokkos Application Using make

Here's an example Makefile:

```

KOKKOS_HOME set via:

module load kokkos

You can look at the first lines of $KOKKOS_HOME/KokkosConfigCommon.cmake to

see the flags used in cmake configuration of the kokkos library build. The

default Kokkos module on Polaris was built with PrgEnv-nvhpc and includes

Serial, OpenMP (threads) and CUDA backends. So you should have that

environment module loaded and include compiler flags for cuda and openmp:

Cray MPI wrapper for C++ and C compilers:

CXX=CC
CC=cc

CPPFLAGS=-cuda -fopenmp
LDFLAGS=

LDFLAGS=$(CPPFLAGS) $(LDFLAGS)
LDLIBS=-L$(KOKKOS_HOME)/lib64 -lkokkoscore -lkokkossimd -lpthread

SRCS=example1.cpp
OBJS=$(subst .cpp,.o,$(SRCS))

all: example1_polaris

example1_polaris: $(OBJS)
        $(CXX) $(LDFLAGS) -o example1_polaris $(OBJS) $(LDLIBS)

example1.o: example1.cpp

clean:
        rm -f $(OBJS)

distclean: clean
        rm -f example1_polaris
```

Configuring Your Own Kokkos Build on Polaris

Here are recommended environment settings and configuration to build your own
kokkos libraries on Polaris:

Environment

To match what was done in the centrally-built kokkos associated with the
modules discussed above, use the programming environment
PrgEnv-gnu, and use the Cray wrapper CC as the C++ compiler. You'll also
need to explicitly load the Cuda toolkit version 12.2.91 as shown:

### Human: What are the minimum requirements for building a Kokkos application, including compiler flags and libraries?

### Assistant: The minimum requirements for building a Kokkos application, including compiler flags and libraries, are: `-cuda -fopenmp` as the compiler flags, and `-L$(KOKKOS_HOME)/lib64 -lkokkoscore -lkokkossimd -lpthread` as the required libraries.
    "
"
### Context: 
module restore
module load craype-x86-milan
module load craype-accel-nvidia80
module swap PrgEnv-nvhpc PrgEnv-gnu
module use /soft/modulefiles
module load cuda-PrgEnv-nvidia/12.2.91
module load spack-pe-base cmake

CMake Configuration

This example builds three backends: OpenMP, Serial, and Cuda.

```
git clone git@github.com:kokkos/kokkos.git
cd kokkos
mkdir build
cd build

cmake\
 -DCMAKE_BUILD_TYPE=RelWithDebInfo\
 -DCMAKE_INSTALL_PREFIX=""./install""\
 -DCMAKE_CXX_COMPILER=CC\
 -DKokkos_ENABLE_OPENMP=ON\
 -DKokkos_ENABLE_SERIAL=ON\
 -DKokkos_ARCH_ZEN3=ON\
 -DKokkos_ARCH_AMPERE80=ON\
 -DKokkos_ENABLE_CUDA=ON\
 -DKokkos_ENABLE_AGGRESSIVE_VECTORIZATION=ON\
 -DKokkos_ENABLE_TESTS=OFF\
 -DBUILD_TESTING=OFF\
 -DKokkos_ENABLE_CUDA_LAMBDA=ON\
 -DKokkos_ENABLE_IMPL_DESUL_ATOMICS=OFF\
 -DCMAKE_CXX_STANDARD=17\
 -DCMAKE_EXE_LINKER_FLAGS=-no-gcc-rpath\
 ..

make -j8 install
```

### Human: What are the three backends built in this configuration?

### Assistant: OpenMP, Serial, and Cuda
    "
"
### Context: 
module restore
module load craype-x86-milan
module load craype-accel-nvidia80
module swap PrgEnv-nvhpc PrgEnv-gnu
module use /soft/modulefiles
module load cuda-PrgEnv-nvidia/12.2.91
module load spack-pe-base cmake

CMake Configuration

This example builds three backends: OpenMP, Serial, and Cuda.

```
git clone git@github.com:kokkos/kokkos.git
cd kokkos
mkdir build
cd build

cmake\
 -DCMAKE_BUILD_TYPE=RelWithDebInfo\
 -DCMAKE_INSTALL_PREFIX=""./install""\
 -DCMAKE_CXX_COMPILER=CC\
 -DKokkos_ENABLE_OPENMP=ON\
 -DKokkos_ENABLE_SERIAL=ON\
 -DKokkos_ARCH_ZEN3=ON\
 -DKokkos_ARCH_AMPERE80=ON\
 -DKokkos_ENABLE_CUDA=ON\
 -DKokkos_ENABLE_AGGRESSIVE_VECTORIZATION=ON\
 -DKokkos_ENABLE_TESTS=OFF\
 -DBUILD_TESTING=OFF\
 -DKokkos_ENABLE_CUDA_LAMBDA=ON\
 -DKokkos_ENABLE_IMPL_DESUL_ATOMICS=OFF\
 -DCMAKE_CXX_STANDARD=17\
 -DCMAKE_EXE_LINKER_FLAGS=-no-gcc-rpath\
 ..

make -j8 install
```

### Human: Which compiler is used for building Kokkos?

### Assistant: $CC

Note: The actual value of `$CC` might depend on the specific Cray environment and compiler configuration being used.
    "
"
### Context: 
module restore
module load craype-x86-milan
module load craype-accel-nvidia80
module swap PrgEnv-nvhpc PrgEnv-gnu
module use /soft/modulefiles
module load cuda-PrgEnv-nvidia/12.2.91
module load spack-pe-base cmake

CMake Configuration

This example builds three backends: OpenMP, Serial, and Cuda.

```
git clone git@github.com:kokkos/kokkos.git
cd kokkos
mkdir build
cd build

cmake\
 -DCMAKE_BUILD_TYPE=RelWithDebInfo\
 -DCMAKE_INSTALL_PREFIX=""./install""\
 -DCMAKE_CXX_COMPILER=CC\
 -DKokkos_ENABLE_OPENMP=ON\
 -DKokkos_ENABLE_SERIAL=ON\
 -DKokkos_ARCH_ZEN3=ON\
 -DKokkos_ARCH_AMPERE80=ON\
 -DKokkos_ENABLE_CUDA=ON\
 -DKokkos_ENABLE_AGGRESSIVE_VECTORIZATION=ON\
 -DKokkos_ENABLE_TESTS=OFF\
 -DBUILD_TESTING=OFF\
 -DKokkos_ENABLE_CUDA_LAMBDA=ON\
 -DKokkos_ENABLE_IMPL_DESUL_ATOMICS=OFF\
 -DCMAKE_CXX_STANDARD=17\
 -DCMAKE_EXE_LINKER_FLAGS=-no-gcc-rpath\
 ..

make -j8 install
```

### Human: How many jobs does the ""make"" command run concurrently?

### Assistant: The ""make"" command runs 8 jobs concurrently.
    "
"
### Context: 
Building on Polaris

The following table shows what compiler and flags to use with which PrgEnv:

module compiler flags PrgEnv-nvhpc cc/CC/ftn (nvc/nvc++/nvfortran) -mp=gpu -gpu=cc80 llvm mpicc/mpicxx (clang/clang++) -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda PrgEnv-gnu cc/CC/ftn (gcc/g++/gfortran) -fopenmp PrgEnv-cray cc/CC/ftn -fopenmp

For example to compile a simple code hello.cpp:

For PrgEnv-nvhpc, after loading the modules as discussed above we would use:

CC -mp=gpu -gpu=cc80 hello.cpp
ftn -mp=gpu -gpu=cc80 hello.F90

For LLVM, after loading the modules as discussed above:

mpicxx -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda hello.cpp

For PrgEnv-gnu, after loading the modules as discussed above we would use:

CC -fopenmp hello.cpp
ftn -fopenmp hello.F90

For PrgEnv-cray, after loading the modules as discussed above we would use:

CC -fopenmp hello.cpp
ftn -fopenmp hello.F90

Running on Polaris

To run, you can run the produced executable or with mpiexec in a job script, and then submit the script to the Polaris queue, like:

```
$ cat submit.sh

!/bin/sh

PBS -l select=1:system=polaris

PBS -l walltime=0:30:00

PBS -q debug

PBS -A Catalyst

PBS -l filesystems=home:eagle

cd ${PBS_O_WORKDIR}
 mpiexec -n 1 ./executable
$ # submit to the queue:
$ qsub -l select=1:system=polaris -l walltime=0:30:00 -l filesystems=home:eagle -q debug -A Catalyst ./submit.sh
```

In the above, having the PBS options in the script and on the command line is redundant, but we put it there to show both ways of launching. This submits the script to one node in the debug queue on Polaris, requesting 30 min and the eagle and home filesystems. It will charge project Catalyst for the time.

More details for setting up the job script are in Job Scheduling and Execution section.

Example

```
$ cat hello.cpp

include

include

int main( int argv, char** argc ) {

printf( ""Number of devices: %d\n"", omp_get_num_devices() );

### Human: What compiler flags do I use with PrgEnv-nvhpc?

### Assistant: To use compiler flags with PrgEnv-nvhpc, you would use `cc/CC/ftn (nvc/nvc++/nvfortran) -mp=gpu -gpu=cc80`.

Here's the step-by-step reasoning:

1. The context states that for PrgEnv-nvhpc, we need to use `cc/CC/ftn (nvc/nvc++/nvfortran)` as the compiler.
2. It also specifies that we need to add the flags `-mp=gpu -gpu=cc80` to compile our code.

Therefore, to answer the question, I would recommend using the following command:

```
CC -mp=gpu -gpu=cc80 hello.cpp
ftn -mp=gpu -gpu=cc80 hello.F90
```

This is because `CC` is the compiler for C/C++/Fortran code and we need to add the flags `-mp=gpu -gpu=cc80` to compile our code using PrgEnv-nvhpc.
    "
"
### Context: 
Building on Polaris

The following table shows what compiler and flags to use with which PrgEnv:

module compiler flags PrgEnv-nvhpc cc/CC/ftn (nvc/nvc++/nvfortran) -mp=gpu -gpu=cc80 llvm mpicc/mpicxx (clang/clang++) -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda PrgEnv-gnu cc/CC/ftn (gcc/g++/gfortran) -fopenmp PrgEnv-cray cc/CC/ftn -fopenmp

For example to compile a simple code hello.cpp:

For PrgEnv-nvhpc, after loading the modules as discussed above we would use:

CC -mp=gpu -gpu=cc80 hello.cpp
ftn -mp=gpu -gpu=cc80 hello.F90

For LLVM, after loading the modules as discussed above:

mpicxx -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda hello.cpp

For PrgEnv-gnu, after loading the modules as discussed above we would use:

CC -fopenmp hello.cpp
ftn -fopenmp hello.F90

For PrgEnv-cray, after loading the modules as discussed above we would use:

CC -fopenmp hello.cpp
ftn -fopenmp hello.F90

Running on Polaris

To run, you can run the produced executable or with mpiexec in a job script, and then submit the script to the Polaris queue, like:

```
$ cat submit.sh

!/bin/sh

PBS -l select=1:system=polaris

PBS -l walltime=0:30:00

PBS -q debug

PBS -A Catalyst

PBS -l filesystems=home:eagle

cd ${PBS_O_WORKDIR}
 mpiexec -n 1 ./executable
$ # submit to the queue:
$ qsub -l select=1:system=polaris -l walltime=0:30:00 -l filesystems=home:eagle -q debug -A Catalyst ./submit.sh
```

In the above, having the PBS options in the script and on the command line is redundant, but we put it there to show both ways of launching. This submits the script to one node in the debug queue on Polaris, requesting 30 min and the eagle and home filesystems. It will charge project Catalyst for the time.

More details for setting up the job script are in Job Scheduling and Execution section.

Example

```
$ cat hello.cpp

include

include

int main( int argv, char** argc ) {

printf( ""Number of devices: %d\n"", omp_get_num_devices() );

### Human: How can I compile a simple code like hello.cpp using PrgEnv-cray?

### Assistant: CC -fopenmp hello.cpp
    "
"
### Context: 
Building on Polaris

The following table shows what compiler and flags to use with which PrgEnv:

module compiler flags PrgEnv-nvhpc cc/CC/ftn (nvc/nvc++/nvfortran) -mp=gpu -gpu=cc80 llvm mpicc/mpicxx (clang/clang++) -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda PrgEnv-gnu cc/CC/ftn (gcc/g++/gfortran) -fopenmp PrgEnv-cray cc/CC/ftn -fopenmp

For example to compile a simple code hello.cpp:

For PrgEnv-nvhpc, after loading the modules as discussed above we would use:

CC -mp=gpu -gpu=cc80 hello.cpp
ftn -mp=gpu -gpu=cc80 hello.F90

For LLVM, after loading the modules as discussed above:

mpicxx -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda hello.cpp

For PrgEnv-gnu, after loading the modules as discussed above we would use:

CC -fopenmp hello.cpp
ftn -fopenmp hello.F90

For PrgEnv-cray, after loading the modules as discussed above we would use:

CC -fopenmp hello.cpp
ftn -fopenmp hello.F90

Running on Polaris

To run, you can run the produced executable or with mpiexec in a job script, and then submit the script to the Polaris queue, like:

```
$ cat submit.sh

!/bin/sh

PBS -l select=1:system=polaris

PBS -l walltime=0:30:00

PBS -q debug

PBS -A Catalyst

PBS -l filesystems=home:eagle

cd ${PBS_O_WORKDIR}
 mpiexec -n 1 ./executable
$ # submit to the queue:
$ qsub -l select=1:system=polaris -l walltime=0:30:00 -l filesystems=home:eagle -q debug -A Catalyst ./submit.sh
```

In the above, having the PBS options in the script and on the command line is redundant, but we put it there to show both ways of launching. This submits the script to one node in the debug queue on Polaris, requesting 30 min and the eagle and home filesystems. It will charge project Catalyst for the time.

More details for setting up the job script are in Job Scheduling and Execution section.

Example

```
$ cat hello.cpp

include

include

int main( int argv, char** argc ) {

printf( ""Number of devices: %d\n"", omp_get_num_devices() );

### Human: What are some examples of job scripts to run on Polaris?

### Assistant: Some examples of job scripts to run on Polaris are:

1. For PrgEnv-nvhpc:
```
$ cat submit.sh
#!/bin/sh
PBS -l select=1:system=polaris
PBS -l walltime=0:30:00
PBS -q debug
PBS -A Catalyst
PBS -l filesystems=home:eagle
cd ${PBS_O_WORKDIR}
CC -mp=gpu -gpu=cc80 hello.cpp
$ # submit to the queue:
$ qsub -l select=1:system=polaris -l walltime=0:30:00 -l filesystems=home:eagle -q debug -A Catalyst ./submit.sh
```

2. For LLVM:
```
$ cat submit.sh
#!/bin/sh
PBS -l select=1:system=polaris
PBS -l walltime=0:30:00
PBS -q debug
PBS -A Catalyst
PBS -l filesystems=home:eagle
cd ${PBS_O_WORKDIR}
mpicxx -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda hello.cpp
$ # submit to the queue:
$ qsub -l select=1:system=polaris -l walltime=0:30:00 -l filesystems=home:eagle -q debug -A Catalyst ./submit.sh
```

3. For PrgEnv-gnu and PrgEnv-cray:
```
$ cat submit.sh
#!/bin/sh
PBS -l select=1:system=polaris
PBS -l walltime=0:30:00
PBS -q debug
PBS -A Catalyst
PBS -l filesystems=home:eagle
cd ${PBS_O_WORKDIR}
CC -fopenmp hello.cpp
$ # submit to the queue:
$ qsub -l select=1:system=polaris -l walltime=0:30:00 -l filesystems=home:eagle -q debug -A Catalyst ./submit.sh
```

These job scripts can be used as a starting point for running jobs on Polaris. The specific compiler and flags will depend on the PrgEnv being used, as shown in the table provided in the context.
    "
"
### Context: 
int main( int argv, char** argc ) {

printf( ""Number of devices: %d\n"", omp_get_num_devices() );

#pragma omp target
  {
    if( !omp_is_initial_device() )
      printf( ""Hello world from accelerator.\n"" );
    else
      printf( ""Hello world from host.\n"" );
  }
  return 0;
}

$ cat hello.F90
program  main
  use omp_lib
  implicit none
  integer flag

write(,) ""Number of devices:"", omp_get_num_devices()

!$omp target map(from:flag)
    if( .not. omp_is_initial_device() ) then
      flag = 1
    else
      flag = 0
   endif
  !$omp end target

if( flag == 1 ) then
      print , ""Hello world from accelerator""
   else
      print , ""Hello world from host""
   endif

end program main

$ # To compile
$ CC -mp=gpu -gpu=cc80 hello.cpp -o c_test
$ ftn -mp=gpu -gpu=cc80 hello.F90 -o f_test

$ # To run 
$ mpiexec -n 1 ./c_test
Number of devices: 4
Hello world from accelerator.
$ mpiexec -n 1 ./f_test
 Number of devices:            4
 Hello world from accelerator

```

### Human: How do you determine the number of devices in an OpenMP application?

### Assistant: Number of devices: 4
    "
"
### Context: 
int main( int argv, char** argc ) {

printf( ""Number of devices: %d\n"", omp_get_num_devices() );

#pragma omp target
  {
    if( !omp_is_initial_device() )
      printf( ""Hello world from accelerator.\n"" );
    else
      printf( ""Hello world from host.\n"" );
  }
  return 0;
}

$ cat hello.F90
program  main
  use omp_lib
  implicit none
  integer flag

write(,) ""Number of devices:"", omp_get_num_devices()

!$omp target map(from:flag)
    if( .not. omp_is_initial_device() ) then
      flag = 1
    else
      flag = 0
   endif
  !$omp end target

if( flag == 1 ) then
      print , ""Hello world from accelerator""
   else
      print , ""Hello world from host""
   endif

end program main

$ # To compile
$ CC -mp=gpu -gpu=cc80 hello.cpp -o c_test
$ ftn -mp=gpu -gpu=cc80 hello.F90 -o f_test

$ # To run 
$ mpiexec -n 1 ./c_test
Number of devices: 4
Hello world from accelerator.
$ mpiexec -n 1 ./f_test
 Number of devices:            4
 Hello world from accelerator

```

### Human: Can you provide an example of how to use the `omp_get_num_devices()` function in Fortran?

### Assistant: The final answer is that you can use the `omp_get_num_devices()` function in Fortran by including the `omp_lib` module and calling the function as shown above.
    "
"
### Context: 
int main( int argv, char** argc ) {

printf( ""Number of devices: %d\n"", omp_get_num_devices() );

#pragma omp target
  {
    if( !omp_is_initial_device() )
      printf( ""Hello world from accelerator.\n"" );
    else
      printf( ""Hello world from host.\n"" );
  }
  return 0;
}

$ cat hello.F90
program  main
  use omp_lib
  implicit none
  integer flag

write(,) ""Number of devices:"", omp_get_num_devices()

!$omp target map(from:flag)
    if( .not. omp_is_initial_device() ) then
      flag = 1
    else
      flag = 0
   endif
  !$omp end target

if( flag == 1 ) then
      print , ""Hello world from accelerator""
   else
      print , ""Hello world from host""
   endif

end program main

$ # To compile
$ CC -mp=gpu -gpu=cc80 hello.cpp -o c_test
$ ftn -mp=gpu -gpu=cc80 hello.F90 -o f_test

$ # To run 
$ mpiexec -n 1 ./c_test
Number of devices: 4
Hello world from accelerator.
$ mpiexec -n 1 ./f_test
 Number of devices:            4
 Hello world from accelerator

```

### Human: What is the purpose of the `omp_is_initial_device()` function in OpenMP programming?

### Assistant: The purpose of the `omp_is_initial_device()` function in OpenMP programming is to determine whether the current device is the initial device or not, allowing for execution of different code on the initial device compared to other devices.
    "
