{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.embeddings.ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 136/136 [03:58<00:00,  1.75s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load PDF file\n",
    "loader = PyPDFLoader(\"data/polaris.pdf\")\n",
    "# Break into smaller chunks\n",
    "pages = loader.load_and_split(RecursiveCharacterTextSplitter(chunk_size = 2000, chunk_overlap = 100))\n",
    "# Embedded to local data vector database\n",
    "db  = Chroma.from_documents(pages, OllamaEmbeddings(model=\"mxbai-embed-large\",show_progress=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6}) # Turn VectorStore into a Retriever\n",
    "local_model = \"llama3\" # [Phi 3, Mistral, Gamma]\n",
    "llm = ChatOllama(model=local_model, temperature = 0) # temperature > 1 more creative, random, temperature < 1 deterministic, repetitive\n",
    "\n",
    "# System prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\", \"context\"],\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many nodes does Polaris have?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  9.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, it appears that Polaris has multiple nodes with varying numbers of nodes. The context shows a series of lines with node counts ranging from 273 to 297. Therefore, I can conclude that Polaris has at least 273 and up to 297 nodes. However, without more specific information, I don't know the exact total number of nodes in Polaris.\n"
     ]
    }
   ],
   "source": [
    "question = \"How many nodes does Polaris have?\"\n",
    "print(question)\n",
    "print(rag_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is Gromacs?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, I found that Gromacs is not mentioned explicitly. However, it's possible that GROMACS (not Gromacs) might be related to NVIDIA Nsight tools.\n",
      "\n",
      "GROMACS is a popular molecular dynamics simulation package used in computational chemistry and biochemistry. It's possible that the context refers to using GROMACS with NVIDIA Nsight tools for some specific purpose or application.\n",
      "\n",
      "If you could provide more information or clarify what you mean by \"Gromacs\", I'd be happy to try and help further!\n"
     ]
    }
   ],
   "source": [
    "question = \"What is Gromacs?\"\n",
    "print(question)\n",
    "print(rag_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What type of workflow managers I can use on Polaris?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:01<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, I don't know what type of workflow managers you can use on Polaris. The context appears to be related to NVIDIA Nsight tools and does not mention workflow managers specifically. If you could provide more information or clarify your question, I'd be happy to try and assist you further!\n"
     ]
    }
   ],
   "source": [
    "question = \"What type of workflow managers I can use on Polaris?\"\n",
    "print(question)\n",
    "print(rag_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the default programming environment on Polaris?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know the answer to that question. The provided context does not mention a default programming environment on Polaris. It appears to be a collection of documentation and instructions for using the Polaris system, including information on logging in, compiling applications, submitting jobs, and using Lustre file striping. There is no specific mention of a default programming environment.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the default programming environment on Polaris?\"\n",
    "print(question)\n",
    "print(rag_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I change the programming environment on Polaris?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, I don't know how to change the programming environment on Polaris. The context appears to be related to NVIDIA Nsight tools and oneAPI Math Kernel Library (oneMKL) interfaces, but it does not mention anything about changing the programming environment on Polaris. If you could provide more information or clarify what you mean by \"programming environment\", I may be able to help further.\n"
     ]
    }
   ],
   "source": [
    "question = \"How can I change the programming environment on Polaris?\"\n",
    "print(question)\n",
    "print(rag_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I run a job on Polaris? Write an example job submission script?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To run a job on Polaris, you can use the `qsub` command with various options to specify the job submission script, queue, and other parameters.\n",
      "\n",
      "Here is an example job submission script:\n",
      "```bash\n",
      "#!/bin/bash\n",
      "\n",
      "# Load the Singularity module\n",
      "module load singularity\n",
      "\n",
      "# Set the environment variable for the container image name\n",
      "IMAGE_NAME=pytorch:22.06-py3\n",
      "\n",
      "# Run the command inside the container\n",
      "singularity run --fakeroot=true $IMAGE_NAME python my_script.py\n",
      "```\n",
      "This script loads the Singularity module, sets the `IMAGE_NAME` variable to the desired container image, and then runs a Python script (`my_script.py`) inside the container using the `singularity run` command with the `--fakeroot=true` option.\n",
      "\n",
      "You can modify this script to suit your specific needs and submit it to Polaris using the `qsub` command. For example:\n",
      "```bash\n",
      "qsub -I -A <project_name> -q debug -l select=1 -l walltime=60:00 -l singularity_fakeroot=true -l filesystems=home:eagle:grand my_job_script.sh\n",
      "```\n",
      "This command submits the job script (`my_job_script.sh`) to the `debug` queue, requests a single node with 60 minutes of wall time, and sets the `singularity_fakeroot` option to `true`.\n"
     ]
    }
   ],
   "source": [
    "question = \"How can I run a job on Polaris? Write an example job submission script?\"\n",
    "print(question)\n",
    "print(rag_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I login to Polaris?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, it appears that Polaris is not a login system or a specific application that requires a login process. The context seems to be related to NVIDIA Nsight tools and oneAPI Math Kernel Library (oneMKL) interfaces.\n",
      "\n",
      "To access Polaris, I'm afraid I don't have any information that would allow me to provide instructions on how to log in. It's possible that Polaris is not a publicly accessible system or service, or it may be a proprietary tool specific to your organization or industry.\n",
      "\n",
      "If you could provide more context or clarify what Polaris is and why you need to access it, I'd be happy to try and assist you further.\n"
     ]
    }
   ],
   "source": [
    "question = \"How can I login to Polaris?\"\n",
    "print(question)\n",
    "print(rag_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='6.7 Applications and Libraries6.7.1 ApplicationsGromacs on PolarisWHAT IS GROMACS?GROMACS is a versatile package to perform molecular dynamics, i.e.simulate the Newtonian equations of motion for systems withhundreds to millions of particles. It is primarily designed forbiochemical molecules like proteins, lipids, and nucleic acids thathave a lot of complicated bonded interactions, but since GROMACS isextremely fast at calculating the nonbonded interactions (that usuallydominate simulations) many groups are also using it for research onnon-biological systems, e.g. polymers.USING GROMACS AT ALCFALCF offers assistance with building binaries and compilinginstructions for GROMACS. For questions, contact us atsupport@alcf.anl.gov.BUILDING GROMACSDownload latest source code: http://manual.gromacs.org/documentation/2022.1/download.htmltar -xzf gromacs-2022.1.tar.gzmodule swap PrgEnv-nvhpc PrgEnv-gnumodule load cudatoolkit-standalone/11.2.2module load gcc/10.3.0module load cmakecd gromacs-2022.1mkdir build1. 2. 3. 4. 5. 6. 7. 8. 9. cmake -DCMAKE_C_COMPILER=cc -DCMAKE_CXX_COMPILER=CC \\\\      -DBUILD_SHARED_LIBS=OFF -DGMX_BUILD_OWN_FFTW=ON \\\\6.7 Applications and Libraries\\n- 223/807 -', metadata={'source': 'data/polaris.pdf', 'page': 36})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[38]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "01ba945ee49e95c366f476d9cce5ca2835808bcc4a38e0774c8a102eb12f95c2"
  },
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
